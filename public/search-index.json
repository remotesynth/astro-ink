[{"slug":"a-web-developer-is","category":"blog","title":"A Web Developer Is...","description":"PPK responds to his critics.","tags":["web development"],"body":"\nAs I expected (and mentioned in [my post on Monday](http://www.remotesynthesis.com/blog/its-ok-not-to-be-right)), there was much more to PPK's controversial slide statement than just being incendiary. First, Adrian Holovaty, the attendee who posted the [offending tweet](https://twitter.com/adrianholovaty/status/829777292633194497/photo/1?ref_src=twsrc%5Etfw) that set off the whole controversy, [posted more thorough details](http://www.holovaty.com/writing/ppk-talk/) on what he got out of the presentation and what he thought PPK meant by that slide. However, PPK himself has responded by asking, \"[What is a web developer?](http://www.quirksmode.org/blog/archives/2017/02/what_is_a_web_d.html)\"\n\nThe truth is that he clearly was aware that the comment would be incendiary (though perhaps unaware that it would get tweeted and shouted down in quite the manner that it did). In fact, his post doubles-down on his statement, though with the additional context that a tweet simply can't provide.\n\n> I’m not saying you should give up your tools and only work in raw CSS and JavaScript. Instead, I’m saying that you should be able to do so. That’s my definition of a web developer, and it’s what I fundamentally believe in and will stand up for — repeatedly, if necessary.\n\nTo give a more specific definition he says:\n\n> To me, a web developer is a programmer who is not only able to write HTML, CSS, and JavaScript by hand, but also has a deep understanding of what browsers can do to that code.\n> \n> That means that you have to understand the basics of how browsers work, how CSS works, how JavaScript works, and general browser compatibility patterns for the code you’re about to use.\n\nAfter which, he acknowledges that it is a \"tall order,\" especially since he also thinks you need a basic understanding of a number of other web-development-related topics.\n\nNow, I have spoken and written many times about the overabundance of tools in web development. Mostly, I focus on not reinventing the wheel rather than judging what dependence on these tools means about you as a developer. However, I'd say that I generally agree with PPK that his definition is what you should _aspire to_.\n\nThat being said, I'd argue that _being a real web developer_ is a journey not a destination. It took me nearly a decade to get to a point where I would have said I felt comfortable meeting PPK's definition. And guess what? After about 6 years of focusing on slightly different career roles, I believe that I no longer fit the definition - despite continuing to develop to varying degrees over those years.\n\nThe web development world is rapidly changing, thus the real-world definition of a _real web developer_ is constantly changing even if the words themselves remain the same. It is a journey of constant learning. Thus, PPK's focus on tools, I believe, comes from decades of experience. Tools come and go. You cannot rely on your knowledge of the tools in fashion today to carry you through your career as a web developer. Your knowledge will eventually need to be deeper than that to be flexible and survive in this industry.\n\nHowever, just because you may not be there today, doesn't make you _not a real web developer_. To me, being a real web developer is simply embracing that journey."},{"slug":"ad-block-apocalypse","category":"blog","title":"Did We Avoid the Ad Block Apocalypse?","description":"We may have averted disaster for content publishers, but the experience isn't improving.","tags":["content strategy"],"body":"\nThis morning, I read an [interesting article by Patrick Kulp on Mashable](http://mashable.com/2017/01/05/ad-blocking-slowing-possibly/#ndN0Cb86Haqs). It discusses the so called \"ad block apocalypse\" that many people were concerned about when Safari on iOS enabled ad blockers. The gist of this concern was that content-focused sites were already having difficulty surviving due to declining ad rates (which desktop ad blockers certainly didn't help). If ad-blocking took off on mobile, the entire business model could collapse.\n\nAs the article notes though, ad blocking rates have leveled off or are on the decline in many parts of the world, and usage, overall still remains relatively small. So...crisis averted?\n\nWell, not entirely. First off, the [entire model still remains broken](http://www.remotesynthesis.com/blog/broken-content). In fact, it is almost exemplified by the very site that this article is published on, as I reference in the Twitter conversation below.\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Have we averted the &quot;ad block apocalypse&quot;? Perhaps. Ironically, this is on a site overrun with autoplaying video ads <a href=\"https://t.co/ZiXvlCARvX\">https://t.co/ZiXvlCARvX</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/817393091573411841\">January 6, 2017</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nMashable has some quality content. Sure, it has more than it's share of junk, but if you're business is based on impressions and new posts drive impressions, than the more new posts the better (quality is secondary to volume). Nonetheless, it does have some solid articles.\n\nHowever, every aspect of the site is about maximizing advertising effectiveness rather than serving the reader - from the enormous banner ads that often come down and cover the page or much of the content, to the auto-playing video ads in the right hand column, to the completely useless \"continue reading\" button when viewed on mobile. It's like the site literally begs you to install an ad blocker.\n\nNow, as a content creator and publisher, I refuse to use an ad blocker. In my opinion, if you feel that the cost of entry is too high, don't enter. Everyone has a right to charge what they feel their work deserves - in Mashable's case their entrance fee is a level of advertising that makes the site damn near unusable. Occassionally, this is a price I am willing to pay to read something interesting. More frequently, it isn't, and I simply avoid the site - even when I might otherwise have read an article.\n\nThe point is, the situation for publishers is that they seem to believe that they still need to create tons of crap content and bloat their site up to make money. Given what I know about ad rates, that may very well be true. The situation for readers is that the experience sucks - but not enough for most of us to, apparently, be willing to pay for content (via a subscription, for instance).\n\nJust because a situation isn't getting worse, doesn't mean it's getting better."},{"slug":"ad-blocking-increase","category":"blog","title":"Ad Blocking on the Rise?","description":"In other news...perhaps the ad-block apocalypse is still on","tags":["content strategy"],"body":"\nRecently, I [discussed an article](http://www.remotesynthesis.com/blog/ad-block-apocalypse) that argued that we may have avoided the so-called \"ad block apocalypse.\" Today, a new study may signal quite the opposite. This new study by PageFair [says that ad-blocking increased 30% worldwide year-over-year](https://www.nytimes.com/2017/01/31/technology/ad-blocking-internet.html). I was dubious at the time of the prior article, and this confirms my suspicions that the situation is getting worse.\n\nThe interesting thing in this study is that it gets at the difference in behavior between Asia-Pacififc users versus US/Europe users. It seems that users in the US and Europe are, for the moment, primarily concerned with malware.\n\n> In contrast, the vast majority of ad-blocking on traditional computers, whose use similarly jumped 17 percent last year, to 236 million devices, is still restricted mainly to the United States and Europe. In those regions, people’s efforts to block malware disguised as online advertising has been the main motivation for downloading ad blockers.\n\nThus, their usage (for the moment) is limited mostly to the desktop.\n\nOn the other hand, users in Asia-Pacific, who represent the vast majority of mobile ad-block usage, are doing so because of costly mobile data plans.\n\n> Across the developing world, ad-blocking software is primarily used by people to save on often costly data packages by removing video and other data-hungry advertisements from mobile websites.\n\nI guess that this may be important to you depending on which markets that your content is targeting. However, the experts cited seem to believe that behavior in the US and Europe will change and mobile usage will increase.\n\nA common refrain we see as a solution is:\n\n> “The best way for the industry to tackle this problem is to deliver compelling ad experiences that consumers won’t want to block.”\n\nExcept, that's the thing about ad-blockers, they are the nuclear option from a user standpoint. It's not like on my TV where I can mute or fast-forward (with a DVR of course) ads that I don't want to see. In this case, I see no ads - so how exactly would I ever know that there is an ad that I don't want to block if I am already blocking it. That's simply a recipe for maintaining the status quo at best rather than moving towards a viable solution for content creators/publishers. Given that the content model of the web is currently broken (as I've said [many](http://www.remotesynthesis.com/blog/broken-content), [many](http://www.remotesynthesis.com/blog/content-model-of-web-is-broken), [many](http://www.remotesynthesis.com/blog/twitter-failure), [many](http://www.remotesynthesis.com/blog/the-webs-failure-as-information-platform) times before), that is not a strategy for success.\n\nWhat is? If I only knew, I'd be doing it."},{"slug":"advanced-jekyll-templates","category":"blog","title":"Some Advanced Jekyll/Liquid Template Techniques","description":"This stuff was hard - for me at least!","tags":["web development","Jamstack"],"body":"\nGenerally speaking, Liquid templates for Jekyll are pretty easy to create - Liquid is a powerful templating tool and offers a large number of helpers and formatters to get complex tasks done. However, recently I had the opportunity to build a site that required me to use some techniques I'd never needed before with Liquid and Jekyll.\n\nThe home page had a number of repeating sections that listed the content for each category of content. If there was no content, the section shouldn't show. More importantly, each section was essentially the same except for some category metadata and styling. Rather than repeat the same code for each section, I decided to use includes - but this required some creative workarounds to make the styling show.\n\nIn this post, I'll show some of the techniques I used. I am not entirely certain that these are necessarily \"best practices,\" but since there wasn't a lot of information I could find around the web on this, I thought it might be worth sharing. (And if you have better ways of solving these problems, please share.)<!--more-->\n\n## Determining If a Category Has Posts (and How Many)\n\nThis one is actually pretty straightforward. Each category has a size property which you can use.\n\n```liquid\n{% if site.categories.categoryname.size%}\n <!-- do something -->\n{% endif%}\n```\n\nObviously, replace `categoryname` with the actual category you used for your posts. Don't worry, it won't error if the category doesn't exist. Now, I suppose you could leave the `.size` off assuming that if the category doesn't exist, that is because it contains no posts, but this works just as well (and reads easier perhaps).\n\n## Assign the Value of a Variable\n\nIn this scenario, I had a variable that would have the current category. Assigning a variable is easy. Liquid has an `assign` keyword for this purpose.\n\n```liquid\n{% assign categoryname = 'foobar'%}\n```\n\nSome examples claimed that you could not reassign the value of a variable once initially assigned. I didn't find this to be the case. However, you can, alternatively, assign a variable with `capture`.\n\n```liquid\n{% capture categoryname %}foobar{% endcapture %}\n```\n\n## Using a Variable with an Include\n\nThere's really nothing special to do here. If the variable is assigned, you can simply use it within any include thereafter. (Note: I tried using the `with` keyword to pass the variable in the include rather than assigning it each time, but couldn't get this to work properly.)\n\nThe fun part here is that the include was always the same, just the value of the variable changed. Let's look at a small portion.\n\n```liquid\n{% if site.categories.foobar.size %}\n  {% assign categoryname = \"foobar\" %}\n  <section>\n    {% include index_article.html %}\n  </section>\n{% endif %}\n\n{% if site.categories.barbar.size %}\n  {% assign categoryname = \"barbar\" %}\n  <section>\n    {% include index_article.html %}\n  </section>\n{% endif %}\n```\n\nWithin that include (which I poorly named `index_article.html`), I can loop over the posts within that category by using the variable.\n\n```liquid\n{% include banner.html %}\n<ul class=\"ArticleList\">\n  {% for post in site.categories[categoryname] %}\n\t<li>\n        <h4><a href=\"{{ post.url | prepend: site.baseurl }}\">{{ post.title }}</a></h4>\n        <p>{{ post.description }}</p>\n        <p><span class=\"Author\">{{ post.author }}</span>\n        <span class=\"PublishDate\">{{ post.date | date: \"%b %-d, %Y\" }}</span></p>\n    </li>\n  {% endfor %}\n</ul>\n```\n\n## Dynamically Load Data\n\nSo, remember I said that the banner changed based upon some category metadata? Well, in order to do that, I decided to place the necessary metadata items in a YAML data file under `_data`. Each category had the same key name as the actual post category so that I could easily look it up. (Yes, this is probably a little brittle, but remember we are talking a static site - it's not like I'm going to push something broken live.)\n\nLet's look at a sample of the YAML.\n\n```yaml\nfoobar:\n  name: \"Foo Bar\"\n  description: \"Foo is the best kind of bar around\"\n  logo: \"foobar.png\"\n  color: \"Purple\"\nbarbar:\n  name: \"Bar Bar\"\n  description: \"There's no doubt that bar is the original kind of bar\"\n  color: \"Orange\"\n```\n\nNotice that they don't all contain the exact same metadata - the first has a logo but the second doesn't. In the `index_article.html` code sample above I included `banner.html`. Let's take a look at that.\n\n```html\n<div class=\"SectionHead {{ site.data.categories[categoryname].color }}Box }}\">\n<div class=\"LogoSpot\">\n  {% if site.data.categories[categoryname].logo %}\n    <img src=\"{{ site.baseurl }}/images/{{ site.data.categories[categoryname].logo }}\"\n      alt=\"{{ site.data.categories[categoryname].name }}\"/>\n  {% elsif site.data.categories[categoryname].subtitle %}\n    {{ site.data.categories[categoryname].subtitle }}\n  {% else %}\n    {{ site.data.categories[categoryname].name }}\n  {% endif %}\n</div>\n<h2>{{ site.data.categories[categoryname].name }}</h2>\n<h3>{{ site.data.categories[categoryname].description }}</h3>\n</div>\n```\n\nNotice that I am able to dynamically pull the category name via the variable (and even though this is an include within an include after the variable was set). Also notice that I can test if particular properties exist on the category - for example I show the logo if it exists, if not the subtitle (if it exists) and else just the category name.\n\n## Conclusion\n\nHopefully these examples are useful - I know they would have helped me. If anyone has suggestions on how I could have achieved the same results in a better fashion, please share.\n\nAlso, be sure to check out my free ebook from O'Reilly - [Static Site Generators - Modern Tools for Static Website Development](http://www.oreilly.com/web-platform/free/static-site-generators.csp)\n"},{"slug":"becoming-a-developer","category":"blog","title":"There's More Than One Way to Become a Developer","description":"An overview of the pros and cons of the different education options to become a developer","tags":["general","web development"],"body":"\nI've come across a lot of discussion lately about the best path to becoming a developer. Unfortunately, often this is focused on disparaging one path over another. For instance, I've seen comments that bootcamps are a waste of time and money and I've seen similar talk about obtaining a CS degree from a university.\n\nThis fits an unfortunate pattern common in the developer community whereby some people deem that there is one \"right\" solution to a problem. Each of these paths has pros and cons and which one is right for you depends largely on your goals (both short and long term), your finances, your time and your interests. There is no wrong way, in my opinion, but there may be options that better meet your specific needs.\n\nIt's important to consider that each individual's motivations for becoming a developer are not the same. For example, [Evans Data](https://evansdata.com/press/viewRelease.php?pressID=277) found that, on average, women are more likely to be motivated to \"develop my skills and challenge myself\" while men are more likely to cite wanting the skills to support a startup or new business. Both are legitimate motivations, but can impact an individual approach to education.\n\nIn this post, I'm going to lay out the three most common educational paths to becoming a developer in a broad sense and try to give an even-handed look at the pros and cons of each, from my point of view.\n\n## College Degree\n\nA college degree with a major in computer science or a similar topic of study is the most traditional path to becoming a developer.\n\n### Pros\n\n* **Many jobs require a degree** - Do you have to have a degree to become a developer? No. But there are still many positions at companies that have a baseline requirement that you have a degree - often specifying a BS in computer science or related field of study. Many [notable companies have dropped this requirement](https://www.glassdoor.com/blog/no-degree-required/), but even when it isn't a requirement, it is often listed as \"preferred.\"\n* **A well-rounded education** - The thing about a college degree is that it is about more than just coding. This may seem like a waste of time when you are young, but, in my opinion, has benefits that last well into your career. Speaking from experience, you may not know where your career will lend you and some of the skills you'll learn and interests you may develop in college can be beneficial in the long run (for example, studying history and creative writing in college built up my writing skills that have led to career opportunities later in my career).\n\n### Cons\n\n* **It's the most expensive option** - According to the [College Board](https://trends.collegeboard.org/college-pricing/figures-tables/average-published-undergraduate-charges-sector-2018-19), the average yearly tuition in the US for 2018-19 was $10,230, meaning a degree will cost over $40k over 4 years. It's important to note that about 3/4 of students receive grants and scholarships that mean that they don't pay the full tuition, but it is still likely to be very expensive and this cost may be out of the range of possibility for you.\n* **It takes a long time** - Sure, you can finish in less than 4 years, but 4 years is the norm. If you are working already to support yourself or your family, this will only extend the amount of time it will take to complete a degree as a part-time student.\n\nKeep in mind that an alternative path here is to study an unrelated field but still get a job as a developer - I have met many developers with non-CS degrees in the industry (myself included). However, you'll likely have to combine your degree with one of the other paths below.\n\n## Bootcamp\n\nBootcamps are a relatively new concept in developer education, with some of the first ones being [founded in 2011-2012](https://venturebeat.com/2015/11/08/coding-bootcamps-are-replacing-computer-science-degrees/). While there is no accepted definition of a bootcamp, they generally last anywhere between 2 and 6 months (the average is [about 14 weeks](https://www.coursereport.com/reports/2018-coding-bootcamp-market-size-research)).\n\n### Pros\n\n* **They are the quickest option** - Even a lengthy bootcamp at six-months would be significantly shorter than a college degree. It is also very likely shorter than the amount of time you'd have to invest in a self-taught program, if only because you follow a designed curriculum and generally attend full-time, plus you leave with some form of certificate while being self-taught will require you invest time in proving your qualifications in other ways (building a portfolio perhaps).\n* **The focus on code** - Because they are designed to move quickly, bootcamps are very focused on getting you hands-on coding early and often. Most programs work on projects that students can then present as portfolio items when they leave complete the program.\n\n### Cons\n\n* **They are expensive** - According to the [2018 Coding Bootcamp Market Size Study](https://www.coursereport.com/reports/2018-coding-bootcamp-market-size-research), the average price of a bootcamp is $11,906 (with the average length being 14.3 weeks, that's well over $800 per week). While significantly cheaper than a college degree in terms of overall cost, a bootcamp certificate arguably has significantly less value, especially over the longer term.\n* **Job placement can be difficult** - [Recent surveys](https://www.switchup.org/rankings/coding-bootcamp-survey#employment-outcomes) indicate that, while a majority or graduates (56.8%) have employment within 12 weeks, only about 75% of those without a college degree end up employed in the end (while other numbers are higher, I use that as a point of comparison since we are speaking of Bootcamps as college degree replacement). I will note that most major bootcamp programs offer job placement assistance of some kind.\n\nThere are over 100 different bootcamp programs around the country. Given the cost and time investment, it is worth doing your research on each program's success rate in terms of job placement and curriculum.\n\n## Self-taught\n\nSelf-taught is a broad category since it covers everything from online classes to books to any number of alternative learning methods one can find.\n\n### Pros\n\n* **This is the least expensive option** - The cost obviously depends on your choice of learning path. It can be anywhere from $0 if you take advantage of a variety of free online learning options to several hundred dollars to subscribe to courses at [Udemy](https://www.udemy.com/), [CodeAcademy](https://www.codecademy.com) or [Pluralsight](https://www.pluralsight.com), to name a few popular options (based on a yearly subscription or multiple courses).\n* **You are in control** - If you are the dedicated, self-motivated type of person, then the lack of a specific curriculum or time to completion can actually be a big benefit. The \"curriculum\" is up to you and can focus on your specific areas of interest. How long it takes is really just a matter of your time and dedication, which can be made to fit into a schedule that still accommodates work and/or family.\n\n### Cons\n\n* **No placement assistance** - What does it take to meet the qualifications necessary to get a job as a developer when you are self-taught? There are no clear guidelines and they are likely to change depending on the company. This is complicated by the fact that you are on your own in terms of job placement while colleges/universities and bootcamps have resources and recruiting partnerships to help you in your job search.\n* **You are in control** - As much as this is a pro, it can also be a con. What's the curriculum? Up to you. How much time do you need to spend? Up to you. How long will it take? That's unclear. If you struggle with motivation or finding the time to complete training and courses independently, you may never gain the momentum necessary to get you to the point that you are ready to start your career.\n\nIt's probably worth mentioning that the self-taught option is something that can be combined with any of the other options, especially as the costs are low. In fact, it should become part of any developers continuing education throughout there career, regardless of how many years you spend in development.\n\n## Share Your Experiences\n\nWhile I did share some research, much of this is based upon my own opinion and experiences and are purposefully generalized. Your own perspective and experience may be different. I'd love to hear about your education journey towards becoming a developer - share in the comments!"},{"slug":"best-developer-posts-of-2016","category":"blog","title":"Top 10 Developer Posts of 2016","description":"Shout-outs to some great content over the past year!","tags":["general"],"body":"\nI read _a lot!_ Part of this is the nature of my job as, essentially, the Editor in Chief of the [Telerik Developer Network](http://developer.telerik.com) and even as co-editor of [Mobile Web Weekly](http://mobilewebweekly.co). But I also love to read and read a lot of technical articles for developers as part of my daily routine.\n\nIn taking a look back at this year, I wanted to recognize what I thought were some of the absolute best blog posts and articles written for developers this year. (And, of course, I am biased, so some TDN articles will make it in.)\n\nP.S. These are in no particular order (actually, that's not true...they're basically in reverse chronological order...but not in order or favoritism).<!--more-->\n\n### [Dear JavaScript,](https://medium.com/@thejameskyle/dear-javascript-7e14ffcae36c#.zc4fwntwm) by James Kyle\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A thoughtful article by <a href=\"https://twitter.com/thejameskyle\">@thejameskyle</a> about importance of developers thinking about the impact their words can have. <a href=\"https://t.co/AQVKLLRfGo\">https://t.co/AQVKLLRfGo</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/805862812274802689\">December 5, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n### [Down with the tool fetish](http://www.quirksmode.org/blog/archives/2016/10/down_with_the_t.html) by PPK\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The web community has gone off the rails with the tool fetish says <a href=\"https://twitter.com/ppk\">@ppk</a> <a href=\"https://t.co/IjSD2f33Sc\">https://t.co/IjSD2f33Sc</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/784112491018289160\">October 6, 2016</a></blockquote>\n\n### [Oh shit, git!](http://ohshitgit.com/) by Katie Sylor-Miller\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I made a website to explain how to get yourself out of your git messes in plain english <a href=\"https://t.co/6Rc6YTPM3o\">https://t.co/6Rc6YTPM3o</a></p>&mdash; Katie Sylor-Miller (@ksylor) <a href=\"https://twitter.com/ksylor/status/774053678575607808\">September 9, 2016</a></blockquote>\n\n### [Five tips for improving your technical writing and documentation.](https://medium.com/@limedaring/five-tips-for-improving-your-technical-writing-and-documentation-47353723c8a7#.bra2r3402) by Tracy Osborn\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I wrote some tips on how to improve your technical writing and documentation: <a href=\"https://t.co/4Lh38cvx0B\">https://t.co/4Lh38cvx0B</a></p>&mdash; Tracy Osborn (@limedaring) <a href=\"https://twitter.com/limedaring/status/770302846939955200\">August 29, 2016</a></blockquote>\n\n### [How to Successfully Contribute to Large Open Source Projects](http://developer.telerik.com/featured/successfully-contribute-large-open-source-projects/) by TJ VanToll\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The steps developers should follow to become contributors to large and popular open source projects by <a href=\"https://twitter.com/tjvantoll\">@tjvantoll</a> <a href=\"https://t.co/LBBwLOMPTh\">https://t.co/LBBwLOMPTh</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/763044419293605889\">August 9, 2016</a></blockquote>\n\n### [Where The Web Is Going In 2016](http://developer.telerik.com/featured/web-going-2016/) by Jared Faris\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">An overview of important new features in web standards/JavaScript that you should watch carefully by <a href=\"https://twitter.com/JaredTheNerd\">@JaredTheNerd</a> <a href=\"https://t.co/jXIpqwiFMa\">https://t.co/jXIpqwiFMa</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/742701155935981568\">June 14, 2016</a></blockquote>\n\n### [To Write Better Code, Read Virginia Woolf](http://www.nytimes.com/2016/05/22/opinion/sunday/to-write-software-read-novels.html?_r=0) by J. Bradford Hipps\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A great piece on how an engineering degree is not the only path to becoming a great programmer.  <a href=\"https://t.co/Jalx70o9Up\">https://t.co/Jalx70o9Up</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/734511069683650561\">May 22, 2016</a></blockquote>\n\n### [The Uncanny Valley is Uncanny](http://www.uxbooth.com/articles/the-uncanny-valley-is-uncanny/) by Nicholas Bowman\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A look at the uncanny valley in UX, particularly with the growth of non-keyboard-based human-computer interactions. <a href=\"https://t.co/lu5Rwj4bvi\">https://t.co/lu5Rwj4bvi</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/720957891335884802\">April 15, 2016</a></blockquote>\n\n### [Looking at JavaScript with “new” eyes: Digging into the specs to learn more about the new operator](https://bocoup.com/weblog/looking-at-javascript-with-new-eyes) by Leo Balter\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A deep and interesting look into the new JavaScript new operator and the specs for it by <a href=\"https://twitter.com/leobalter\">@leobalter</a> <a href=\"https://t.co/CV650A9rvI\">https://t.co/CV650A9rvI</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/713003188253810688\">March 24, 2016</a></blockquote>\n\n### [Common Misconceptions About Inheritance in JavaScript](https://medium.com/javascript-scene/common-misconceptions-about-inheritance-in-javascript-d5d9bab29b0a#.gphvu15x9) by Eric Elliott\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Common misconceptions about classical inheritance and prototypal inheritence in JavaScript by <a href=\"https://twitter.com/_ericelliott\">@_ericelliott</a> <a href=\"https://t.co/hzXzCbeLBs\">https://t.co/hzXzCbeLBs</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/684831915053084672\">January 6, 2016</a></blockquote>"},{"slug":"best-features-es6","category":"blog","title":"The Best Features in ECMAScript 6?","description":"I interview Axel Rauschmayer at QCon NY.","tags":["web development","javascript"],"body":"\nRecently I had the chance to attend [QCon NY](https://www.qconnewyork.com/). Actually, I was fortunate enough to be on the programming committee and to lead a track there. My track was called \"Beyond JavaScript\" and one of my featured speakers was [Dr. Axel Rauchsmayer](http://www.2ality.com/) speaking on ECMAScript 6 (i.e. the next version of JavaScript).<!--more--> I was very excited that Axel was able to attend all the way from Munich, as he is well known expert on ES6 (and author of the new book [\"Speaking JavaScript\"](http://speakingjs.com/)).\n\nDuring my time at the conference I was able to [interview Axel](http://www.infoq.com/interviews/axel-rauschmayer-ecmascript-6). We mostly discussed the process whereby new features are added to the ES6 spec, using JavaScript for enterprise development and which features Axel is most excited about in ES6.\n\nSo what two features did Axel choose as his favorites in ES6? I think you may be surprised, but you'll have to [watch or read the interview on InfoQ](http://www.infoq.com/interviews/axel-rauschmayer-ecmascript-6) to find out."},{"slug":"best-kept-secret-developer-education","category":"blog","title":"The Best Kept Secret for Free Developer Education","description":"CFE.dev has hundreds of hours of free sessions for developers.","tags":["general"],"body":"\nJust about 3 years ago, before the pandemic forced us all to go virtual, I launched a [site with the goal of hosting free, virtual meetups](https://cfe.dev) (and occassional virtual workshops). Since then, thousands of developers have attended one of the almost 70 sessions I've hosted. However, despite the hundreds of hours of free recordings available featuring some of the [best speakers](https://cfe.dev/speakers/) in the industry, most developers have never heard of the site.\n\nPart of that was that I'd never really invested the time and effort into making the site look worthy of the content it contained. I joked that the original site simply \"barfed up images\" on the home page and didn't make it clear what the site was about. Today I am excited to share the completely revamped [cfe.dev](https://cfe.dev) that I believe solves these issues and, hopefully, helps developers find the valuable resources it contains.\n\n![New CFE Home Page](/images/posts/screenshot.png)\n\n## Free, Live Virtual Meetups\n\nNowadays the site typically hosts two free virtual meetups every month on a wide range of tech and tech culture topics. There are talks for anyone from beginners to advanced developers. These are typically held live at noon Eastern Time. \n\nThe new launch includes 5 new meetups newly announced between now and November including [Getting Started with the DOM](https://cfe.dev/events/getting-started-with-the-dom/) featuring Edidiong Asikpo on September 18, at noon ET.\n\n[![Getting Started with the DOM](/images/posts/DOM-getting-started.jpg)](https://cfe.dev/events/getting-started-with-the-dom/)\n\nAdditional topics include:\n\n* A Jamstack 101 series of events featuring Joel Varty:\n\t* [Jamstack 101: Using Gatsby with Netlify](https://cfe.dev/events/jamstack-101-gatsby-netlify/) on October 1 at noon ET\n\t* [Jamstack 101: Using Next.js with Vercel](https://cfe.dev/events/jamstack-101-nextjs-vercel/) on October 22 at noon ET\n\t* [Jamstack 101: Getting Started with Eleventy](https://cfe.dev/events/jamstack-101-eleventy/) on November 12 at noon ET\n* Two hands-on events featuring Dave Nugent:\n\t* [Build a Virtual Agent in JavaScript](https://cfe.dev/events/build-a-virtual-agent/) on September 24 at noon ET\n\t* [Build a Smart Slack Bot in Node.js](https://cfe.dev/events/build-a-slack-bot/) on October 15 at noon ET\n\nMore virtual meetups to be announced soon!\n\n## Almost 70 Recorded Sessions and Workshops\n\nThe site also features over 3 years worth of session recordings which are edited recordings of every session (the full Crowdcast recording is also available). Previously therse weren't very easy to find and navigate, but the new site has completely revamped the categories to make finding sessions in your area of interest easier to find (on top of a revamped search). Topics are:\n\n* [Web Development](https://cfe.dev/categories/webdev/) - Stay up on standards, accessibility, and best practices.\n* [JavaScript](https://cfe.dev/categories/javascript/) - Sessions on React, Vue, JAMSTACK, and everything in-between.\n* [Career and Culture](https://cfe.dev/categories/culture/) - Learn to lead with empathy and master soft skills.\n* [DevOps](https://cfe.dev/categories/devops/) -How to launch and scale high performance apps like a pro.\n* [Software Engineering](https://cfe.dev/categories/software/) - New languages and tools to take your code to the next level.\n* [Cool Stuff](https://cfe.dev/categories/stuff/) - Check out VR, IoT, and fun experiments.\n\nYou can also find your sessions by [your favorite speaker](https://cfe.dev/speakers/).\n\n## A Virtual Meetup Community\n\nMy goal for [CFE.dev](https://cfe.dev) is to build a welcoming online community where developers can learn, network and interact. I'm working on new features like favorites/save-for-later, custom playlists of sessions (like a \"build your own virtual conference\"), badges, discussions that extend beyond the meetup itself, interviews, live coding and much more.\n\nI hope that you find the site useful and find sessions or workshops that teach you something you've been wanting to learn. If you enjoy the site, please consider [voting it up on ProductHunt](https://www.producthunt.com/posts/cfe-dev). I appreciate any feedback. Or, if you'd like to speak, please reach out."},{"slug":"best-music-2014","category":"blog","title":"Best Music of 2014","description":"Some great music was released over the past year.","tags":["music"],"body":"\nOne of my New Year's resolutions was to write and blog more - and that doesn't mean just on technical topics but also on topics I am generally interested in. I just need to get in the habit of writing more, generally speaking.\n\nAnyway, any of you who know me know that I am a big fan of music. In fact, until about mid-2013 I was doing a bi-weekly Internet radio show (called Vitamin Sweet) focused only on new music. If you'd listened to that show you might Charli XCX in Februrary of 2013, Foxes in May 2013 and Lorde in July 2013, among others who later became famous.\n\nAlong those lines, before 2015 got too far along, I wanted to share my favorite music from 2014.\n<!--more-->\n\n## Magic by Paperwhite\n\nI have a habit of following bands I like on Facebook, and it has often led to fun discoveries. In this case, one of the two members of [Paperwhite](https://www.facebook.com/paperwhitemusic) is also in a band named Savoir Adore, which is how I learned of them. \"Magic\" is just an EP but there really isn't a bad song on the entire album. If you love catchy, 80's infused pop, this is a total winner, with the standout song being \"Take Me Back.\" Outstanding stuff.\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/160653287&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## Haerts by Haerts\n\n\"Wings\" by [Haerts](https://www.facebook.com/haertsmusic) was probably one of my favorite songs of 2013. It was released as a single, all by itself (as in, no B-sides or even remixes). The band slowly released new music, including their 4 song Hemiplegia EP in 2013, but 2014 finally got a full album. Sure, if you had the EP, all those songs are back again, but there's plenty more here and every one is a winner. \"Wings\" is still the best song on the album, though \"Call My Name\" is my favorite of the songs that had not previously appeared.\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/140704426&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## Siren by Young Summer\n\nI don't even recall how I heard of [Young Summer](https://www.facebook.com/Youngsummermusic). I tend to go searching for new music here and there and have been known to download albums that I proceed to forget about without even a listen. Young Summer nearly fell into this trap for me. I was browsing my iPod and could not even recall downloading the album - boy would I have missed out. Young Summer is electronic alt-pop (if that's a thing) that is insanely catchy - many mornings I have woken up with one of the songs in my head. My favorite is \"Blood Love,\" but will admit that the one that sticks in my head most often is \"Taken.\" If this woman doesn't become a star soon, I will be very surprised.\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/161685891&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## There for U by Astronomyy\n\nIf you are a fan of chill out, \"date night\" music along the lines of Rhye (or Milosh), then you will love [Astronomyy](https://www.facebook.com/Astr0nomyy). As of yet, there's no full album available, but the \"There For U\" EP features 4 superb songs. He also recently released a new single called \"Not Into U.\" Hopefully a full album is on the way. Nonetheless, I highly recommend getting everything he's made available so far. You won't regret it. My personal favorite is \"Pack of Wolves.\"\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/playlists/44973422&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## Days of Abandon by The Pains of Being Pure at Heart\n\nI fell in love with [The Pains of Being Pure at Heart](https://www.facebook.com/ThePainsofBeingPureatHeart) way back in 2009 when their debut album was my favorite album of that year. Much of the composition of the band apparently changed between 20011's \"Belong\" album and this one (basically, only the band's founder remained the same from what I recall). You could expect this to mean that the music might suffer, but \"Days of Abandon\" sounds like what you'd expect from the band - and that's a great thing in my opinion. If anything, they got more accessible. You may actually recognize \"Simple and Sure\" (which is one of the standouts) as it was featured in some commercial, but my favorite is \"Beautiful You\" (though, unfortunately, this isn't available in their SoundCloud stream).\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/136713202&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## PocketKnife by Mr. Little Jeans\n\nI love [Mr. Little Jeans](https://www.facebook.com/mrlittlejeans) so much that my wife (who loves her too) and I bought tickets to go see Lilly Allen just because Mr. Little Jeans was the opener (not that their is anything wrong with Lilly Allen, but we very rarely go to concerts). I'd paid too much for upper floor, standing room only tickets where we had to stand with our backs against the wall the entire time to allow people to cross in front. Somehow though, Mr. Little Jeans wasn't there (perhaps a mistake on the [SongKick](http://www.songkick.com/) listing, though I did end up discovering [Samsaya](http://www.samsaya.com/), who is not bad). Needless to say, we were willing to put up with a lot just because Mr. Little Jeans is great and this album is fantastic. If you've heard a song from it, it is \"Oh Sailor,\" which is a fabulous song, but my personal favorite is \"Mercy\" (which, unfortunately, is not embeddable on her SoundCloud stream).\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/83458007&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>\n\n## Voices by Phantogram\n\n\"Voices\" is the fifth album, EP or single that I've bought from [Phantogram](https://www.facebook.com/Phantogram/info) since \"Eyelid Moves\" in 2010. I liked every single one, but rarely loved them. Voices changed that by being much more consistently good and much more accessible (in my opinion) than their prior releases. It's a great album and \"Nothing But Trouble\" is an especially great song. If you've enjoyed Phantogram before or even if you haven't, you should give this album a try.\n\n<iframe width=\"100%\" height=\"450\" scrolling=\"no\" frameborder=\"no\" src=\"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/135848748&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;visual=true\"></iframe>"},{"slug":"best-music-2016","category":"blog","title":"My Top 10 Songs of 2016","description":"Ten great songs released this year.","tags":["music"],"body":"\nI'm a big music lover, and while 2016 was probably light on my music purchases compared to prior years, it still featured some great music. So, here's my sort of traditional top songs of the year post (in case you're curious, [here's last year's post](http://www.remotesynthesis.com/general/2015/12/16/best-music-of-2015/)).<!--more-->\n\n### 1. On Hold - The XX\n\nThis song is from the upcoming album by the XX called 'I See You', which is due later this month. If the rest of the album is as incredible as this song, this album could be better than their debut album (which was fantastic). Plus, they sample Hall and Oates! You gotta love that.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/blJKoXWlqJk\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 2. Not Today - Annabel Jones\n\nI'd never heard of Annabel Jones before but I'm glad I have now. Her EP, ':Libelle', is really good, but this song is, by far, the standout. And, strangely, even though the song isn't openly political in anyw way, it fit my mood perfectly around this year's US election (particularly the lyrics, \"I tore out the first page, hatted every word that I said. I can't smile, not today).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/u5yrLnCzsi0\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 3. A Love Song - Ladyhawke\n\nLadyhawke has always been consistently good. Her latest album, 'Wild Things', is full of fantastic songs with her typical 80s vibe (though slightly less hard-edged than prior albums imo), but Love Song is just so damn catchy and good! Honestly, I can't stop listening to this song...plus it has a totally fun and cheesy video.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/gUwAnVX2ylc\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 4. Haelos - Seperate Lives\n\nAfter releasing singles over the past couple of years, Haelos finally released a full-length album called 'Full Circle'. It's worth a listen! I love this particular song in part because it has a killer beat.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IY0JVKORfR4\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 5. You Don't Get Me High Anymore - Phantogram\n\nPhantogram are another band that I've been a fan of for quite some time. The first time I heard this song, I _had to have_ the whole album...ASAP (named 'Three'). Unfortunately, the rest of the album doesn't quite live up to those high expectations imo (not saying it's bad), but this song is still well-worth the entrance fee.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jryzEU7WAlg\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 6. Chairlift - Show U Off\n\nChairlift have been a favorite of mine for a while. Their recent (and [apparently last](http://pitchfork.com/news/70470-chairlift-break-up/)) almbum together is as excellent as always - great retro-tinged pop. Show U Off was my favorite and what I listened to all this past summer while on Cape Cod.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RerYp7Y4Y3E\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 7. What's It Gonna Be? - Shura\n\nShura's debut full-length album is fantastic and features a number of great songs (on of which, 2Shy, I [featured last year](http://www.remotesynthesis.com/general/2015/12/16/best-music-of-2015/)). This one is my favorite because it is upbeat, catchy and great to run to.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nJ4uBdmnKds\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 8. Oh Wonder - Without You\n\nFemale/male vocal duos are hot lately (see The XX and Haelos above). Unlike those others, though, Oh Wonder offers a light, folky style of pop. Their debut album is great with a number of notable songs, but this one is my favorite, if only because it makes me think of my wife every single time.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/zLAhRiUeJ8E\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 9. Miike Snow - Genghis Khan\n\nNot only is this a great and incredibly catchy song, but it also features my favorite video of the year.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/P_SlAzsXa7E\" frameborder=\"0\" allowfullscreen></iframe>\n\n### 10. The Range - Florida\n\nI don't buy a lot of straight electronica without vocals anymore, but this song is too damn good (and apparently features an Ariana Grande sample, though I don't recognize it). I bought the whole album, but, unfortunately, it far less accessible than this song imo.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/4aqb7MFivis\" frameborder=\"0\" allowfullscreen></iframe>"},{"slug":"best-music-of-2015","category":"blog","title":"Best Music of 2015","description":"Lots of great music released during the year.","tags":["music"],"body":"\nThere was a ton of great music this year - almost too much for me to cover. Here are six of my personal favorite songs of the year (yeah, it's a well known fact that I am a sucker for a female vocalist...and this list is proof).<!--more-->\n\n## Shura - 2Shy\n\nShura is the stage name for British singer, songwriter, producer Aleksandra Denton. I discovered her only recently via a song she released last year called [Touch](https://www.youtube.com/watch?v=x2AOjb9HW2E). While that song is excellent, 2Shy, which was released in April this year and is part of her \"White Light\" EP, is even better. It's not just her voice that is fantastic, but the lyrics are very touching as well.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8gtREooYQ9w\" frameborder=\"0\" allowfullscreen></iframe>\n\n## POLIÇA - Lime Habit\n\nI've listened on and off to POLIÇA for some years, but, honestly, I was only a moderate fan. Then I heard this song and I was like, \"I have to have this, now!\" Unfortunately, it's  part of their \"[United Crushers](https://www.amazon.com/dp/B0177BQZ9O/ref=wl_it_dp_o_pC_nS_ttl?_encoding=UTF8&colid=1BL8G2FZM978&coliid=I5BA2QSGOV3XI)\" album that isn't set to release until March 2016. The good news, if you're impatient like me, you can get the song if you preorder the album.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ICruF30bCEI\" frameborder=\"0\" allowfullscreen></iframe>\n\n## Made in Heights - Ghosts\n\nI first came across Made in Heights via their song [Forgiveness](https://www.youtube.com/watch?v=uRFmmwbNqRg) which was featured on a list of unsigned artists in the iTunes store I believe. Both songs are part of their excellent \"[Without My Enemy What Would I Do](https://madeinheights.bandcamp.com/album/without-my-enemy-what-would-i-do)\" album, which, if you like this song (and you should), you really should go buy right now.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yX9SEkpJ-VQ\" frameborder=\"0\" allowfullscreen></iframe>\n\n## The Bird and the Bee - Will You Dance?\n\nI've loved the Bird and the Bee since their first album way back in 2007 (remember \"F--king Boyfriend\"?). I've owned every album they released - and they don't release too many to be honest. [Recreational Love](https://www.amazon.com/Recreational-Love-Bird-Bee/dp/B010ELPDHE/ref=sr_1_1?s=dmusic&ie=UTF8&qid=1450301254&sr=1-1-mp3-albums-bar-strip-0&keywords=recreational+love) is only their fourth studio album, and first in about five years. But it was worth the wait if only for this gem of a song. From here on out, this song will always bring me back to the summer of 2015.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/flbce8yaBao\" frameborder=\"0\" allowfullscreen></iframe>\n\n## School of Seven Bells - Open Your Eyes\n\nSchool of Seven Bells (or SVIIB) is another group that I have followed since their first release, Alipinisms, in 2008. They were very prolific for a time during their early years - and pretty much every single or album was worth owning. Sadly, in 2013, one of the founding members, Benjamin Curtis died of T-cell lymphoblastic lymphoma. Knowing that story is part of what makes this song so touching. It's beautiful anyway, but even more so because I feel that the message speaks to pain of trying to get over a major loss. The new SVIIB album, recorded before Curtis' death, is set to be released later this year and is intended to be a love letter by Alejandra de la Deheza to her friend and co-band member Curtis.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hemIjEd9CYk\" frameborder=\"0\" allowfullscreen></iframe>\n\n## Yumi Zouma - Song For Zoe & Gwen\n\nIt's really hard to pick the best song from Yumi Zouma's [EPII](https://www.amazon.com/EP-II-Yumi-Zouma/dp/B00SCIBXTE/ref=sr_1_1?s=dmusic&ie=UTF8&qid=1450302144&sr=1-1-mp3-albums-bar-strip-0&keywords=yumi+zouma) EP. All of the songs are excellent and feature the same ethereal (and, yes, hard to understand) singing - reminds me of the days of the Cocteau Twins a bit. Anyway, I don't know much about the band, other than that I think they deserve your attention.\n\n<iframe width=\"420\" height=\"315\" src=\"https://www.youtube.com/embed/xxf6zVMzrXg\" frameborder=\"0\" allowfullscreen></iframe>\n\n## Honorable Mentions\n\n### Priest - Lying on Your Grave\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jfQXL6UOoto\" frameborder=\"0\" allowfullscreen></iframe>\n\n### Andrew McMahon In The Wilderness - High Dive\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/C6MtBDWR8jk\" frameborder=\"0\" allowfullscreen></iframe>\n"},{"slug":"best-music-of-2017","category":"blog","title":"Best Music of 2017","description":"A yearly tradition featuring my favorite songs of the year.","tags":["music"],"body":"\nThose who know me well know that I listen to (and actually _purchase_!) a crazy amount of music. I've also been publishing these lists of my favorite songs for probably as long as I've been blogging (though the current iteration of my blog only has [archives back to 2014](https://www.remotesynthesis.com/categories/#music)). My tastes tend to lean towards alternative and electronic. Most of the time, I favor unknown artists, though from time to time I pick a winner (like when I featured artists like Lorde and Tove Lo on my internet radio show years ago with Bob Silverberg or more recently when I picked Portugal. The Man's \"Feel It Still\" as one of my [favorite songs of 2017 so far](https://www.remotesynthesis.com/blog/best-songs-of-2017-so-far) back in April). This year's list features a lot of new artists and, honestly, I think at least one of them here will make it big one day - if winners and losers in the music biz were based on talent, they certainly all deserve to.\n\nSo, here's my favorite songs of 2017.\n\n### Don't Delete the Kisses - Wolf Alice\n\nIf you were to take the essence of 80s teen movies like 16 Candles or Pretty in Pink and then distill them into a song 30 years in the future, I think you'd get \"Don't Delete the Kisses\" by Wolf Alice. The song even seems to recognize this with lyrics like the following (sung in a sort of melodical whisper rap by Ellie Rowsell):\n\n> How awful's that? I'm like a teenage girl\n>\n> I might as well write all over my notebook\n>\n> That you 'rock my world!'\n\nI love the mixture of barely hidden rage with sorrow and silliness that this song has - and it's what made it my favorite song of 2017. But I recommend checking out the entire album \"Visions of a Life\" (for instance, \"[Planet Hunter](https://www.youtube.com/watch?v=vukOYr8yegg)\" which evokes memories of the Sundays).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/WqxE-zppu30\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n### Television Romance - Pale Waves\n\nGiven that Pale Waves have yet to release a full album (their debut is due in January of 2018), I expect them to be in my favorites at the end of next year as well. Every one of their 4 released songs to date manages to stick in my head so much that I even had a hard time picking a favorite this year (it was a tough call between this song and \"[There's a Honey](https://www.youtube.com/watch?v=zfPZ6hukcw8)\"). I love the fact that the band looks like a modern-day, female-led Cure (\"There's a Honey\" has a clear Cure influence) but creates these upbeat, infectious pop tunes (with, ironically, less than upbeat lyrics).\n\nMy guess is that you'll have a hard time getting the chorus of this song out of your head. Can't wait for the full album!\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ot1j5M5PTC4\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n### Bedroom - Litany\n\n2017 was a terrible year for many things, but it truly introduced me to some new bands I am certain to follow for years to come (see above) - Litany being one of the best. Their \"4 Track EP,\" which actually has 8 songs but only 4 full songs plus interludes, is almost flawless - a funny thing for an album in which one of the best songs is called \"[Flaws](https://www.youtube.com/watch?v=xrcaQjYsXic).\"\n\nThe duo features the singing of Beth Cornell, whose voice has this beautiful, sweet airiness that reminds me of [Mandalay](https://www.youtube.com/watch?v=0p0THcQiAx8) for any of you who remember them. While all the songs are fantastic, that sweetness in her voice plays off the lyrics of \"Bedroom\" just enough to put it over the top as my favorite song by one of my favorite new artists on one of my favorite EPs of 2017.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-2uTSxFpyWQ\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n### Hard to Be Still - Annie Hart\n\nSome of you may know of Annie Hart from her days with [Au Revoir Simone](https://www.youtube.com/watch?v=kwvvlTKi5cE). Her new solo album, \"Impossible Accomplice,\" doesn't depart far from the kind of minimalist, synth-pop sound of her prior band - and that's a good thing. One of the things that she does so well, to me, is manage to make music that has a rough enough edge that you could imagine someone just screwing around in their basement recording these songs - and yet they are too polished and too good for that.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qMza1y1dD98\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n### Persephone - Yumi Zouma\n\nYumi Zouma's \"[Yoncalla](https://www.youtube.com/watch?v=xxf6zVMzrXg)\" was one of my favorite albums of last year (and their \"Song for Zoe & Gwen\" was on my [list from 2015](https://www.remotesynthesis.com/blog/best-music-of-2015)). Their new album sticks with their airy, dream-pop sound but tightens everything up a bit - the vocals aren't as lost in reverb, the melodies are catchier and the production overall seems just more mature. For some bands that might mean they lose their edge but for Yumi Zouma it seems to have perfected a recipe.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/U9cXWCJl5jg\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>\n\n### Freaking Out - Juiceboxxx\n\nJuiceboxxx is another artist who I've been following for years since his amazing \"[Like a Renegade](https://www.youtube.com/watch?v=nt7fnLcn3sw)\" from 2012 that evoked classic Beastie Boys - it managed to be both laced with nostalgia while feeling new. The rest of that album (\"I Don't Wanna Go Into Darkness\") was very hit and miss. The same thing goes for his new album, \"Freaked Out American Loser,\" but once again he still somehowhas one, near-perfect song. It's not quite as \"Licensed to Ill\" but still mixes nostaligia with a modern sound. One day I think Juiceboxxx will actually create an entire album on par with his best songs.\n\nOh, and just to warn, the lyrics are very NSFW.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DR71L6NPBPI\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>"},{"slug":"best-songs-of-2017-so-far","category":"blog","title":"Best Songs of 2017 So Far","description":"My favorite music from the first quarter of the year.","tags":["music"],"body":"\n2017 is already more the 25% gone and if ever there was a year in need of some good music to help soothe your mind (or even channel your rage), it's this year. So, here are my favorite songs of the year so far.\n\n## New in 2017\n\n### Feel It Still - Portugal. The Man\n\nPortugal. The Man has been around for a while apparently, but this song is my first introdution to them - and it's fantastic!\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pBkHHoOIIn8\" frameborder=\"0\" allowfullscreen></iframe>\n\n### Pure Luck - Ninajirachi  (feat. Freya Staer)\n\nThis is such a quirky little song that I can't stop listening to from an artist that appears to be quite new.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ceJyAsk6Rvs\" frameborder=\"0\" allowfullscreen></iframe>\n\n### Something - A O S O O N\n\nThis song actually came out at the very end of 2016, but seems to be flying completely under the radar - which is a shame, it's a really great song.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V0GsxWuo6DY\" frameborder=\"0\" allowfullscreen></iframe>\n\n## New To Me in 2017\n\n### Deeper - AT/ALL\n\nAT/ALL are an experimental electronic band from Melbourne, Australia. I caught this song (which came out in August 2016) on WPRK (i.e. the Rollins College station) and it has shades of Cocteau Twins (who I love) but more electronic. If you're curious about them, their [album](https://atall.bandcamp.com/releases) appears to only be available through BandCamp.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-gL0WNicpq8\" frameborder=\"0\" allowfullscreen></iframe>\n\n### Drive - Britta Phillips\n\nAnother one I heard on WPRK first...this is a remake of the classic song by The Cars. I'm not a fan of remakes that simply tread the same ground However, this version has a very different take, making the song very ethereal.\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/G7vyQKZP4y4\" frameborder=\"0\" allowfullscreen></iframe>\n\nThat's it for now...if you have any recommendations for songs, please send them my way!"},{"slug":"best-time-to-be-a-developer","category":"blog","title":"Is Today the Best Time to be a Developer? No...but We're Getting Better.","description":"While working as a developer certainly has its rewards, there are some major issues we need to address.","tags":["general"],"body":"\nI have been a developer for over 20 years. Over the course of those 20+ years, I have often heard statements along the lines of \"there's never been a better time to be a developer\" or \"now is the best time to be a [technology name here] developer.\" But, let's be honest, this wasn't always accurate. Or, perhaps like the article touting that \"there's never been a better time to be a Blackberry developer\" from 2009, it was accurate for all the wrong reasons (as in, things deteriorated relatively quickly thereafter).\n\n![blackberry developer article](/images/posts/state-of-devs/blackberry.png)\n\n_How much irony can you fit into one article subhead?_\n\nSo, if we were to ask ourselves honestly, is today the best time to be a developer? My personal answer is no, but with a caveat that we are doing a lot of things well and many of the things that we don't do well, we are actively trying to improve. Let me explain.\n\n_Note: I am aware that, for the most part, the data and information presented in portions of this article is US-centric. This is where my own experience is and where I feel I am qualified to honestly discuss the developer experience and workplace._\n\n## The Bad\n\nOk. Let's get the bad news out of the way first...and unfortunately, there is quite a bit of it facing today's developers.\n\n### The Image of the Industry\n\nThe past couple years have seen the reputations of some of the biggest (and, previously, most respected) names in the industry fall from grace. Whether it is sexism and misogyny at Uber, to fake news and exposing of personal information at Facebook, to the failure of Twitter to prevent rampant abuse and misuse of their service, to sexism (and sexist memos) at Google. For instance, [here's a timeline of significant scandals from just last year](https://instamotor.com/blog/biggest-tech-scandals-2017). Even today, as I post this, [Google employees are walking out](https://www.nytimes.com/2018/11/01/technology/google-walkout-sexual-harassment.html) over how the company handles sexual harassment.\n\nI would go on, but it is depressing. Suffice it to say, the industry's once (perhaps undeservedly) glowing reputation is now deeply tarnished. The industry-wide problem is largely an ethical one rather than a technical one. It obviously impacts the businesses and industry, but it also directly involves developers. Developers in today's tech industry are often becoming an important line of defense - they are forced to look past \"Can we build it?\" and also answer \"Should we build it, even if we can?\" New technologies like big data, artificial intelligence and machine learning only further complicate this conundrum and place developers at the heart of projects that have the potential for future scandal.\n\nDespite these scandals, the [industry keeps growing](http://www.wbur.org/hereandnow/2018/04/24/google-alphabet-growth-ad-business).\n\n### Diversity\n\nThe tech industry has a well-earned, bad reputation when it comes to diversity. While the diversity issue in tech is broader than just developers, it definitely applies.\n\nOn a positive note, data cited in this [Wired article](https://www.wired.com/story/computer-science-graduates-diversity/) on the topic shows that the percentage of non-whites seeking computer science degrees as a share of the whole population has increased significantly.\n\n![computer science college enrollment](/images/posts/state-of-devs/college-enrollment.jpg)\n\n_Image Source: [https://www.wired.com/story/computer-science-graduates-diversity/](https://www.wired.com/story/computer-science-graduates-diversity/)_\n\nBlacks and hispanics are still underrepresented in relation to their share of the US population, but the situation has improved. However, the data also shows that most of the increased representation has been taken by men:\n\n> And the irony is, today, more women than men earn college degrees, even as the number of women studying computer science is falling.\n> \n> Blanca Myers, [Women and Minorities in Tech, By the Numbers](https://www.wired.com/story/computer-science-graduates-diversity/)\n\nThis is reinforced by [other research](https://nscresearchcenter.org/snapshotreport-degreeattainment15/) that shows that \"from 2004 to 2014, the share of bachelor’s degrees earned by women decreased in all seven [Science and Engineering] disciplines.\" A degree is often the first step towards a career as a developer (though there are other non-degree paths). Thus a [recent study by Girls Who Code and Accenture](https://www.accenture.com/t20161018T094638__w__/us-en/_acnmedia/Accenture/next-gen-3/girls-who-code/Accenture-Cracking-The-Gender-Code-Report.pdf) describes women's declining share of developers in the workforce as well:\n\n> Research by Accenture and Girls Who Code shows that women’s share of the U.S. computing workforce is declining. On current trends, women will hold only one in five computing jobs in the U.S. by 2025.\n> \n> [Cracking the Gender Code](https://www.accenture.com/t20161018T094638__w__/us-en/_acnmedia/Accenture/next-gen-3/girls-who-code/Accenture-Cracking-The-Gender-Code-Report.pdf)\n\nAnd anyone who follows social media or who has simply talked to a female colleague knows that women frequently face a hostile work and professional environment - the stories of harassment or just plain inappropriateness at conferences or in the workplace are seemingly endless and depressing. I can't honestly say if the situation is improving, but I do know that more and more women seem to be bravely sharing and often confronting this issue directly, and I think that has and will continue to have an impact.\n\n### The Interview Process\n\nI'll start this section by saying that I am fully aware of how difficult it can be to judge the quality of candidates for developer jobs. And when your business depends on code, the quality of your software engineers is especially critical. Some qualifications such as a computer science degree or relevant experience are a good indicator, but often don't get at some of the specific skills companies need. As an industry, we have also tried certifications and so far found them lacking in usefulness - perhaps because the nature of our work is constantly changing.\n\nStill, the solution that we've largely ended up with has its flaws.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Sweet - but still be ready to pass an obscure code test for Google that has little to nothing to do with your actual work. <br><br>(OK OK Ray shut up about the damn test you failed...) <a href=\"https://t.co/kHUsDdb29C\">https://t.co/kHUsDdb29C</a></p>&mdash; Raymond Camden (@raymondcamden) <a href=\"https://twitter.com/raymondcamden/status/1032620254650937344?ref_src=twsrc%5Etfw\">August 23, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nIt is almost an industry-wide standard now to include things like white-boarding and complex code tests or puzzles as part of the interview process for a developer job. These are almost always included regardless of the person's background or experience level, leading to weird situations, such as a published author with decades of experience being rejected over a single test, as above. Or a widely respected JavaScript expert being denied a position over a lack of JavaScript knowledge:\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I was rejected for a job by <a href=\"https://twitter.com/TwitterEng?ref_src=twsrc%5Etfw\">@TwitterEng</a> years ago, even tho I knew several people on the team who liked me &amp; wanted me to join. I was later told by HR that one of the interviewers said I &quot;didn&#39;t know JS&quot; very well. That was part of the motivation for <a href=\"https://twitter.com/YDKJS?ref_src=twsrc%5Etfw\">@YDKJS</a>. <a href=\"https://twitter.com/hashtag/ShareYourRejections?src=hash&amp;ref_src=twsrc%5Etfw\">#ShareYourRejections</a></p>&mdash; getify (@getify) <a href=\"https://twitter.com/getify/status/1032445705204449281?ref_src=twsrc%5Etfw\">August 23, 2018</a></blockquote>\n\nIt is a process that emphasizes sometimes unnecessary coding knowledge in favor of traits that often, in my opinion, make a developer more successful - things like a willingness to learn, an ability to work with others and collaborate and the ability to creatively problem solve.\n\nIt also tends to favor the hiring of individuals who devote their life to code, which brings us to the final negative I want to talk about.\n\n### Burnout\n\nIt may be fair to say that every type of job comes with the potential for burnout, but I also think it is fair to say that certain characteristics of being a professional developer lead to a high levels of burnout. A quick Google search produces endless posts and threads on the topic of [developer](https://www.google.com/search?q=burnout+developers&oq=burnout+developers) or [programmer burnout](https://www.google.com/search?q=burnout+programmer&oq=burnout+programmer).\n\nPart of this is related to the type of people we are hiring through the interview process. We are an industry that often celebrates those who live and breath code. It's a work ethic that is perfectly parodied by the \"Silicon Valley\" television show where the programmers literally live at work (and, no, that's not even the joke). Many tech companies even push this sort of work ethic by offering services that encourage people to stay at work and even to build social lives around work. These are for all the employees, of course, but developers frequently have the added expectation that they are supposed to go home and work on passion projects or open source to keep their resumes competitive.\n\nThis kind of work ethic puts pressure on every developer to compete on that level. When mixed with the natural demands of a job that requires continuous adaptation and learning, it can be a toxic combination.\n\n## The Good\n\nHopefully I haven't gotten you fully discouraged at this point in either your potential or current developer career. As you can see, the items above are generally related to the jobs and industry that developers have to work in. The good news is that when it comes to actually coding, things are really quite good. And, there are good aspects to the jobs and industry developers work in. \n\nLet's improve our mood and take a look at these.\n\n### Free and Open Source Developer Tooling and Libraries\n\nWe live in an age of widely available and generally high-quality free and open source software for developers. It is so ubiquitous for today's developers that it can be hard to imagine that we ever debated the value and viability of open source software. And this ubiquitousness also causes us to sometimes be inured to the huge benefits.\n\nFirst, let's look at some numbers. Github had [25 million public repositories](https://octoverse.github.com/) as of 2017. Ruby Gems [almost 150,000](http://www.modulecounts.com/) modules. npm has [close to 700,000](http://www.modulecounts.com/) packages, making it the single largest package registry in the world. And these are just a few of the resources that host projects used by developers.\n\nBut the other important point is that the quality of the projects developers rely upon is high. In many cases, these projects are created by or, on some level, are supported by some of the biggest companies in the technology industry.\n\nWhile all this tooling does make for some complex workflows and architectures, it also makes available resources that, once upon a time, were extremely costly or didn't exist. For instance, when I started in web development over 20 years ago, I recall spending hundreds of dollars (1997 dollars no less) on Dreamweaver, Flash and ColdFusion Studio...each!\n\n![Dreamweaver Ultradev](/images/posts/state-of-devs/ultradev.jpg)\n\n_Yes, once upon a time software came in shrink-wrapped boxes!_\n\n\nThat is a huge barrier to entry for the prospective developers. I also remember, years later, searching through directories filled with commercial solutions for projects (things like shopping carts or bulletin boards for example). This made it difficult to find the right solution and, I speak from experience, the quality was no better for the cost.\n\n### Availability of Learning Material\n\nContinuing on that theme (which is apparently that I am getting old), when I began my career, nearly all of the learning resources available were in the form of books. These either came in the form of manuals provided along with the expensive software or books sold by publishers, which were anywhere from &dollar;60-100 (again, in 1997 dollars).\n\nNowadays, learning materials come in a variety of formats: books, tutorials, videos, interactive training. Those provided by the software companies are all online and, for the most part, freely available (even for commercial software). While book publishers still publish, many have moved away from print to digital formats that are generally less expensive and even allow for shorter form formats - meaning topics that might not ever get a full book now get covered. Companies like [Pluralsight](https://www.pluralsight.com/), [LinkedIn Learning](https://www.linkedin.com/premium/plan/learning), [Udemy](https://www.udemy.com/) and others provide broad learning platforms covering a huge range of topics including programming and development.\n\nThere are honestly far too many resources for me even to list. Even for those who may not have the budget for some of these services can find sites like [FreeCodeCamp](https://www.freecodecamp.org/) or the endless free tutorials on [The Practical Developer](https://dev.to/) or [CSS Tricks](https://css-tricks.com/), to name a couple of my favorites.\n\nThen of course you have a multitude of conferences (ranging in price, of course), local programming-focused [meetups](https://www.meetup.com), or even online meetups and conferences.\n\nI could go on, but I think you see the point.\n\n### Demand\n\nWe live in a world where some of the most powerful companies are run by developers. A world where everything from our cars to our smarthome lightbulbs require some degree of code. So it should be no surprise that demand for developers continues to increase.\n\nAccording to the [US Bureau of Labor Statistics occupational outlook handbook](https://www.bls.gov/ooh/computer-and-information-technology/home.htm), demand for developers through 2026 is supposed to increase 24%, which is much faster than the average. For web developers, it is supposed to increase 15%, also much faster than the average.\n\nThe news is not all rosy. The outlook for computer programmers is supposed to decline 7%. Confused? So am I. I thought software developers and web developers were computer programmers, and the official definitions don't do much to disavow me of that opinion. Then again, I don't work for the government.\n\n### Pay\n\nSolid demand usually leads to good pay and, generally, developers, both in the USA and globally, earn a good living. For example, the [Stack Overflow developer survey](https://insights.stackoverflow.com/survey/2018#salary) shows developers globally earning between &dollar;40-90k a year. In just the USA, the numbers are significantly higher, ranging from &dollar;80-140k a year (the official US Bureau of Labor statistics puts the median pay for software developers at &dollar;103k but for web developers at far less, &dollar;67k, in 2017). While the global numbers are significantly below the US numbers, they are all well above the median individual income in the US, which is &dollar;31,099.\n\nThe one caveat to this is that much of the higher pay seems to be concentrated in specific geographic regions. Taking the US for instance, [PayScale data](https://www.payscale.com/research/US/Job=Software_Developer/Salary) shows a national average salary of $70,169, coming in well below the StackOverflow data but still far above the median individual income. However, much of the higher end of the pay range is concentrated in a few locations: San Francisco, New York and Seattle.\n\n![Payscale average salary](/images/posts/state-of-devs/payscale.png)\n\n## Tomorrow is the Best Time to be a Developer - So Start Today!\n\nIn looking at this issue, I tried to be fair and honest. Admittedly, there were a lot of important cons, but I am not negative or pessimistic. I am grateful to have worked as a developer for so many years and to count myself as part of the developer community. I also truly believe that we are working towards getting better in each of these areas that we currently fall short. This means that - even though today may not be the best day to be a developer - tomorrow is. And there is no better day to get started building tomorrow than today!"},{"slug":"boston-festival-indie-games","category":"blog","title":"Boston Festival of Indie Games 2014","description":"My favorite demos from this years Boston Festival of Indie Games.","tags":["general"],"body":"\nThis past weekend I had the pleasure of attending the latest [Boston Festival of Indie Games](http://bostonfig.com) at MIT. This was the third year of the event and my second attending. This year, as last, I attended with my two boys (ages 8 and 12). Here are some thoughts on the event and some of the games that I, personally, found interesting.<!--more-->\n\n## The Venue\n\nThis year, as last, the event was held in the athletic center at MIT. However, the event outgrew the downstairs room that it was held in last year and actually took up both floors - the table top games were downstairs and the digital games upstairs (sessions were elsewhere but I didn't attend any). While I am happy that the event has grown (and plenty happy to pay the small $10 fee to attend), it did come with a major drawback: the upstairs room was hot and humid - uncomfortably so. This even on a day when Boston itself was unusually cool for mid-September. Honestly, we might have spent more time there if it weren't for the unpleasant conditions.\n\n## My Favorite Games\n\nHere are my favorites from what I was able to try at the [showcase](http://bostonfig.com/digital-game-showcase).\n\n### Bōru mo\n\n<img src=\"/images/posts/BoruMo-1024x576.png\" alt=\"Bōru mo\" width=\"600\">\n\nThis was probably my favorite game of the day. It's a fun 2 to 4 player game where the point of the game is to jump on the other players until they run out of lives and, hopefully, you are the last one standing. The way you do this is that your little creature turns into a ball when he jumps and can smash the opponent. It sounds simple but is harder than you'd think. The multi-level platforms and a variety of power-ups adds some extra fun to the game, which, as I understand it, will be PC only for the moment with other platforms hopefully soon.\n\nOne of the best aspects of this game is the design. It's colorful and cute, which somehow adds to the sense of fun. This shouldn't come as a huge surprise given that the developer is a graphic designer during his day job and this was built over nights and weekends.\n\n### Shock Jocks\n\n<img src=\"/images/posts/ShockJocks-768x1024.jpg\" alt=\"Shock Jocks\" width=\"400\">\n\nThis is a clever iPad game from [@BigMikeTheDev](https://twitter.com/BigMikeTheDev). It's basically a two-player \"air hockey\" with a bit of a twist. Your paddle is electric and needs to maintain a charge. Every time you bounce the ball back, depending on a number of factors, it eats into your charge. The strategy is keeping your paddles charged (by placing your fingers along the sides of the game board) but not missing the shot.\n\nThere's no site just yet, so follow [@BigMikeTheDev](https://twitter.com/BigMikeTheDev) for updates.\n\n### Swimsanity\n\n<iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/9jh9vg87an0\" frameborder=\"0\" allowfullscreen></iframe>\n\nA Kickstarter project being developed by [Decoy Games](http://decoygames.com), Swimsantity is a 4 player underwater brawler with a variety of game modes. Each player comes with different weapons and different abilities, the later of which charge up as you compete. In one game mode, it was simply a Super Smash Brothers type brawl with the winner being the one who gets knocked out the least. In the latter, it was a cooperative mode where you needed to help each other to get through the level without being caught by the creature following your team.\n\nThe artwork and controls were all nicely done and my boys and I enjoyed playing together.\n\n### World Zombination\n\n<iframe src=\"//player.vimeo.com/video/99045157\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> <p><a href=\"http://vimeo.com/99045157\">World Zombination Teaser Trailer</a> from <a href=\"http://vimeo.com/proletariat\">Proletariat Inc</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p>\n\nYes, the zombie thing is getting old, as made clear by the number of zombie games even at this festival, but this one from [Proletariat](http://proletariat.com/) stood out. There are two modes. In one you control the heroes trying to defend cities against the hordes of zombies. This mode works much like a tower defense game. In the other (and the mode I got to play), you are the zombie hordes trying to destroy the city. In this mode, you use different \"mutations\" to give members of your zombie horde different powers. Some powers work better than others to defeat certain heroes (for instance, a stealth zombie is good against the snipers).\n\nWhile both modes are takes on existing games, the combination of the two modes, along with nice artwork and easy to understand gameplay, made this one a winner in my mind."},{"slug":"broken-content","category":"blog","title":"The Content Model of the Web is Broken - Part 2","description":"Things are not getting any better.","tags":["content strategy"],"body":"\nAlmost exactly two years ago, I wrote a post on this blog called \"[The Content Model of the Web is Broken](http://www.remotesynthesis.com/general/2015/01/16/content-model-of-web-is-broken/)\". My basic argument was that there it had become very difficult to make a viable business out of content anymore. Advertising is not a workable revenue generator - the only real solutions were to produce content that either had ulterior motives (i.e. my content is designed to market some other product or service) or relied entirely on unpaid authors, which devalued writing to a point that the quality is potentially suspect.\n\nNow even that second model seems potentially broken. Don't take my word for it - take the word of Medium CEO Evan Willams. He effectively repeats much of what I argued two years ago (so forgive me for quoting it in full here):\n\n> Medium CEO Ev Williams says his company’s ad-based business model isn’t working, and the startup is laying off 50 employees and closing its offices in New York and Washington, D.C., as a result.\n>\n> That’s about one third of the company’s employees.\n>\n> In a blog post shared on Wednesday, Williams said he wants to move away from ad-supported content, which is how most stuff on the internet generates revenue. Williams described that business model, which is almost entirely dependent on clicks and views, as a **\"broken system**.\"\n>\n> \"The vast majority of articles, videos, and other ‘content’ we all consume on a daily basis is paid for  —  directly or indirectly —  by corporations who are funding it in order to advance their goals,\" Williams wrote. \"And it is measured, amplified, and rewarded based on its ability to do that. Period. As a result, we get … well, what we get. And it’s getting worse.\"<br>- Source: [ReCode](http://www.recode.net/2017/1/4/14169348/medium-layoffs-ad-business-model-change) (emphasis mine)\n\nKeep in mind that Medium had a level of traffic that most any other content site could only dream of (according to [this site](https://www.similarweb.com/website/medium.com#overview), it's about 84.5 million visits per month).\n\nThe point here is that the situation is worsening. If you care about quality content, as I do, you should be concerned."},{"slug":"building-static-sites-jekyll","category":"blog","title":"A Guide to Building Static Sites with Jekyll","description":"A walkthrough on building our first static site with Jekyll.","tags":["web development","Jamstack"],"body":"\nAs I've [posted about recently](http://remotesynthesis.com/general/2015/03/04/comparing-static-site-engines/), I've been speaking a lot about comparing static site engines. There are a *ton* of options out there (389 as of today, according to [this site](https://staticsitegenerators.net/)). However, based on my personal experience, I always recommend [Jekyll](http://jekyllrb.com) - granted, that's based on having used 5 of the 389 so far.\n\nI already have a [GitHub project](https://github.com/remotesynth/Static-Site-Samples) where I have built the same project multiple times with different engines as a means of comparison. The readme will guide you with installing and running each of these should you choose.\n\nNow, if you wanted to learn how to use Jekyll using this sample, I have written a [detailed guide to getting started with Jekyll](http://developer.telerik.com/featured/getting-started-with-jekyll/) for the Telerik Developer Network. It walks through the most common things you need to know about Liquid templating as well as how to create and build your Jekyll site.\n\nI hope you enjoy it!\n\nP.S. One common questions I get whenever I recommend Jekyll is from people who don't know Ruby and would prefer a solution written in JavaScript/Node.js and, preferably, available via npm. The [GitHub project](https://github.com/remotesynth/Static-Site-Samples) includes two, Harp and Wintersmith. I have a follow up article that should be published any day now that walks through the same steps laid out in the Jekyll tutorial, but for Wintersmith. I'll post about that as soon as it is out."},{"slug":"building-static-sites-wintersmith","category":"blog","title":"Building Static Sites with Node.js and Wintersmith","description":"How to build your first static site with the Wintersmith generator.","tags":["web development","Jamstack"],"body":"\nWhen I've spoken on the topic or even when I posted my recent [guide to getting started with Jekyll](http://developer.telerik.com/featured/getting-started-with-jekyll/),  the question I always get is if there is a comparable static site generator to Jekyll that is built with JavaScript and available on npm. The reason people cite is that they aren't comfortable with Ruby and thus have trouble when they encounter problems with Jekyll or are unable to customize it completely to their needs. Well, there's good and bad news.\n\nFirst, the bad news... I have found nothing comparable to Jekyll in terms of overall features, documentation and community. Now I don't know every engine out there, but, so far, there's nothing that even comes close to fully matching Jekyll.\n\nThe good news, however, is that I found [Wintersmith](http://wintersmith.io/) to be a viable Jekyll replacement. It has a lot of the key features and is extensible. Plus, there are a reasonable amount of extensions out there for it already. On the other hand, the documentation is awful (let's be honest) and the community is small. So, if you run into a problem, you're stuck reviewing the source code. On the upside, I found the source code is pretty self-explanatory when I needed to rely on it.\n\nGiven the lack of a good getting started guide in the Wintersmith documentation, I wrote a two-part series for Sitepoint that walks you through the entire process of building a site. It follows the same exact format of my [Jekyll guide](http://developer.telerik.com/featured/getting-started-with-jekyll/) covering everything from installation to templating, creating posts, custom metadata and custom data.\n\n* [Getting Started with Wintersmith: A Node.js-based Static Site Generator](http://www.sitepoint.com/getting-started-wintersmith-nodejs-static-site-generator/) - Part 1\n* [Creating Posts, Custom Metadata, and Data in Wintersmith](http://www.sitepoint.com/creating-posts-custom-metadata-data-wintersmith/) - Part 2\n\nThe source code for the example is part of my [Static Site Samples GitHub project](https://github.com/remotesynth/Static-Site-Samples) which also includes the aforementioned Jekyll sample as well as examples for Harp and Middleman."},{"slug":"can-machine-learning-stop-internet-trolls","category":"blog","title":"Can Machine Learning Potentially Stop Internet Trolls?","description":"A Google company has been working on an anti-trolling API.","tags":["general"],"body":"\nLast week, a new project named the [Perspective API](https://www.perspectiveapi.com/) was opened to the public by Jigsaw (which is apparently supported by Google). Perspective uses a toxicity scale to try to determine how similar any given text is to other text that people rated as toxic. Details on exactly how they recruited people to help perform these initial ratings isn't completely clear (according to [this article](http://www.theverge.com/2017/2/23/14713496/google-jigsaw-perspective-software-ai-machine-learning-developers), they presented them to panels of 10 people at a time for feedback), but there is a built-in learning aspect to the ratings (at least as demoed in the writing experiment on the site).\n\nPerspective is currently beginning to roll out API access over the course of the year to developers who submit a request.\n\nIn simple tests conducted by [The Verge](http://www.theverge.com/2017/2/23/14713496/google-jigsaw-perspective-software-ai-machine-learning-developers) and [Mashable](http://mashable.com/2017/02/23/google-jigsaw-moderation-tool/), the results seemed mixed. These anecdotal tests combined with the experiments made available on the site, seem to indicate that the algorithm is very good at identifying obviously trollish behavior (especially when profanity is involved), but less effective against text that is less blatant.\n\nHere's an example:\n\n![](/images/posts/perspective.png)\n\nThe items in each column are ranked by toxicity, with items showing a square having moderate to moderately-high toxicity (I am filtering out the more highly toxic items in this image).  On the left hand column, it seems odd that \"Dreadful: I'm a Remainer\" is considered slightly more toxic than \"left wing wimps\" for instance. On the right hand column, the comment about xenophobia and racism seems to be strangely overrated. Even the comment above doesn't truly seem (to my eyes) much more toxic than the last comment on the bottom of the right-hand column, which the algorithm rated as not toxic (sure, the word cowards could have been a trigger of sorts, but isn't necessarily toxic depending on the context, which is obviously not entirely clear here).\n\nSo clearly, this isn't ready to be a fully automated tool yet, but it could help companies at least begin to identify and intervene with potentially abusive online behavior. Even if that would still require manual intevention, perhaps, with some refinement this tool integrated into some sites (hello, Twitter, Reddit and Hacker News!) could help raise red flags for moderators to intervene. However, if this is to be more widely used, I think there would have to be more openness as to how scores are calculated and the makeup of the panels (perhaps this is being done already and it's simply not obvious to me or open to only those with API access) - the last thing we need is to create a means of easy censorship.\n\n"},{"slug":"can-web-audio-be-useful","category":"blog","title":"Can Web Audio be Useful?","description":"Tl;dr - yes, it can, if used thoughtfully.","tags":["web development"],"body":"\nNext month, I will be presenting at the [Fluent Conference](http://fluentconf.com) in San Francisco on the topic of \"Practical Web Audio.\" The idea here is that most every demo or presentation about web audio (including my own) have been fun and cool but not practical unless you build games or music software.\n\nSo, are there useful purposes for web audio in a standard web app? I wrote an article called [Adding Audio to Web Apps](http://developer.telerik.com/featured/adding-audio-to-web-apps/) that begins to explore some ideas. In almost every case, the demo uses very brief portions of audio to try to add context to some form of input. Notifications seemed obvious - but, admittedly, others are harder to make a strong case for except in very specific circumstances. These were just some of my initial ideas - I have a few others and some variations to the ones I showed already that I am working on.\n\nHave you used web audio in your web app for something useful? If so, please share (and maybe I can even show it at Fluent)."},{"slug":"certified-fresh-2017","category":"blog","title":"Resolve to catch up on some great presentations in 2018! 🎆","description":"Some great session recordings from last year's events.","tags":["general"],"body":"\n2017 was a busy year! Since launching in August, I hosted 6 free online events with 13 speakers and 11 different presentations via [Certified Fresh Events](https://certifiedfreshevents.com) - covering everything from JavaScript to serverless to bots and tech culture. If you missed any of these, they are all recorded and available for free!\n\nHere's some of what you may have missed this year...\n \n## Learn about ES6 and TypeScript\n\n[![JavaScript in 2017](/images/posts/javascript2017.jpg)](https://certifiedfreshevents.com/events/javascript-2017/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/javascript-2017/)\n\n## All about the Internet of Things & Smart Homes\n\n[![IoT for Fun and Profit](/images/posts/IoT-For-Fun-And-Profit 2.jpg)](https://certifiedfreshevents.com/events/iot-for-fun-and-profit/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/iot-for-fun-and-profit/)\n\n## Dive into Vue.js & Preact\n\n[![Exploring JavaScript Frameworks](/images/posts/jsframeworks2017.jpg)](https://certifiedfreshevents.com/events/exploring-javascript-frameworks/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/exploring-javascript-frameworks/)\n\n## Serverless with JS & the Serverless Framework\n\n[![Going Serverless](/images/posts/serverless2017.jpg)](https://certifiedfreshevents.com/events/going-serverless/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/going-serverless/)\n\n## Improving the Culture of the Tech Workplace\n\n[![\nOh No You Didn’t: Conflict Management in Today’s Tech Industry](/images/posts/Banner_Oh_No_You_Didnt 2.jpg)](https://certifiedfreshevents.com/events/conflict-management/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/conflict-management/)\n\n## Deploy Serverless Apps & Build Bots\n\n[![The Future of Development](/images/posts/Banner_The-Future-Of-Development.jpg)](https://certifiedfreshevents.com/events/future-of-development/)\n\n[View the Crowdcast recording](https://certifiedfreshevents.com/events/future-of-development/)"},{"slug":"changing-directions-in-development","category":"blog","title":"Changing Roles as a Developer Can Be Scary","description":"There's so much to learn - where do I even start?","tags":["general"],"body":"\nAs a developer, I love learning new things! As a developer, learning new things scares me! Although perhaps seemingly contradictory, both these things are true about me.\n\nNo developer can remain stagnant and succeed. The industry changes too much and too quickly for that. However, in most cases, these can be _small_ shifts that build upon a foundation of expertise. These small shifts can add up to be significant over the course of years, but the underlying foundations were never threatened.\n\nThat is the course I set out in the first half of my career. I started out as a ColdFusion developer. I added database expertise. Worked to improve my front-end coding skills (being a relatively early adopter of things like CSS and jQuery), and eventually expanded those into Flash and Flex.\n\nFor me, the shift over the course of those years was dramatic enough that by the end of the first half of my career, I'd basically left behind many of the back-end ColdFusion and database skills that I'd started my career with, but each change had gradually built upon those early skills so that it felt like a natural extension of my knowledge.\n\nOther parts of a developer's career can often take dramatic turns, where you are forced to or choose to leave behind much of what you know to embark on an entirely new set of technologies and tools. Often times these shifts come with a new role at your company or a new job.\n\nThat's been the story of the second half of my career from the moment I was forced to leave Flash and become focused on front-end development (in a community management/developer relations role) at Adobe. I was suddenly dropped in a world of development that I once knew, if imperfectly, but which had changed so dramatically in the years that had passed that I was left feeling like an aspiring junior developer working in my first coding assignment. _There's so much to learn - where do I even start?_\n\nSince then I've rarely felt comfortable in my development skills. I've done a lot - written articles, written books, spoken at a ton of conferences, but I've also dabbled in a little bit of everything. I used to descibe myself as being the developer equivalent of the [Boston Common Frog Pond](https://bostonfrogpond.com/), covering a lot of ground but never deep in a single spot.\n\nAnd yet there was a certain kind of comfort in that. I could be building a site in Wordpress and PHP one day and whipping up a command-line app in Node another. I knew enough to get by but no one expected me to have deep expertise in any one thing.\n\nNow, I am - by choice - embarking on a new role and remembering that awful discomfort of that  dramatic break from my past knowledge. I once again feel like a noob not knowing what I should know or where to start to find out.\n\nIt's exiting and I can't wait to get started!\n\nAnd it's incredibly scary and I am anxious about taking my first steps!\n\nIt makes no sense to have both these feelings at once and, yet, it also makes complete sense.\n\n_(For the few of you who read this whole thing - thanks for listening. I hope this wasn't too personal. I will share more about my new role in the coming weeks and months, but, for now, if you are curious, just know that I am staying on the same team at the same company, just in a very different capacity)_"},{"slug":"common-problems-with-technical-articles","category":"blog","title":"5 Common Problems with Technical Articles","description":"Common mistakes most developers tend to make in their writing.","tags":["content strategy"],"body":"\nI read and edit a lot of technical articles - generally written by developers for developers. In the past, I wrote up some guidelines for [making your technical content better](http://remotesynthesis.com/general/2015/05/18/writing-for-tech-audience/). This time, I want to take the opposite angle and focus on some mistakes I see all too frequently.<!--more-->\n\n## The Intent Isn't Clear\n\nThe background to whatever you are covering can be important. But make sure the intent of your article is clear _before_ diving into a long background explanation. In fact, I'd say you should have a clear, one-sentence (preferably) explanation of what the article intends to explain/show within the first paragraph of your intro. The background can come after this.\n\nMake the intent crystal clear too. A typical feature tutorial might have something like:\n\n> In this article I intend to demonstrate what the new arrow functions in ES6 are, why they are useful and how to incorporate them into your application.\n\nOr an opinion article might say:\n\n> I'm going to discuss why I believe ES6 arrow functions are a useless feature that you'll probably never use, but first, let's discuss what they are.\n\n\\* To be clear, I'm making these up as examples.\n\n**Why?** Because most readers won't get through paragraphs worth of background before clearly understanding what you intend to discuss. You may feel that the background leads into the intent and doing it this way comes out \"backwards,\" but your reader just wants to know what they will get out of it before committing their time to the rest (and titles are generally too short to make the scope of the article perfectly clear).\n\n## The Context is Too Narrow\n\nOftentimes, the actual code we're sharing shows how to do something very narrow. This is usually because we are sharing code from a problem we were solving in a specific application for a speific purpose. However, the concepts we cover can be much more broadly applicable.\n\nFor example, perhaps you are writing an article that walks through the code of a Jekyll plugin you created to generate multiple output pages for a single post Markdown (again, making this up). Rather than fixating on the specifics around what the plugin does, you should show how it illustrates building a Jekyll plugin and how you learned about and used some of the internals of Jekyll to figure out how to build it.\n\n**Why?** Because the specifics of your code may only really be applicable to a handful of people (if anyone, depending on the nature of what you are working on) but the concepts are likely useful to a much broader audience. If you are taking the time to write this up, I assume you want people to actually read it.\n\n## Unexplained Code\n\nDevelopers tend to believe that code is, for the most part, self explanatory. I've seen many articles take a sample and simply paste large chunks of code with little to no explanation. The truth is, even with some inline comments in the code, this not only makes for a rather uninteresting read, but can confuse many readers.\n\nFor example, let's imagine I am using the following code sample:\n\n```liquid\n<!-- offset 2 -->\n{{ range $index, $element := .Site.Pages }}\n    {{ if gt $index 1 }}\n    <li>\n        <span class=\"date\">{{ .Date.Format \"Jan\" }}\n        <strong>{{ .Date.Format \"2\"}}</strong></span>\n        <h3><a href=\"link\">{{ .Title }}</a></h3>\n        <p>{{.Description}}</p>\n    </li>\n    {{ end }}\n{{ end }}\n```\n\nI might say:\n\n> In the above example, we are looping through a list of posts in Hugo, starting with the 3rd most recent post. We do this within our `range` loop by checking the index (which, in Go, starts at 0). Within this loop, we output the month and day of the post, each formatted for the constraints of our layout, as well as the full title and description.\n\nOf course, this is a very simple and slightly contrived example, but hopefully you get the idea. Some people prefer to go line by line, which, in code that isn't as markup focused as this one, can work well as well. The point is, don't treat your readers like idiots, but don't assume they know what's going on just by looking at your code.\n\n**Why?** I'd argue there are three good reasons to fully explain your code samples. The first is that you cannot know the experience level of all of your readers, and what seems obvious to you, may not be obvious to them. Second, unexplained code often leads to improperly copied code - the reader thinks the code solves their issue but doesn't understand everything it is doing (which, you'll probably end up explaining via a response to a frustrated comment anyway). Third, it makes the article more interesting as it often leads to discussion of why you chose a particular solution or how some feature of what you are writing about works internally.\n\n## Lack of a Consistent Voice\n\nThis is less of a major issue then a nitpicky one on my part perhaps (and one I am occassionally guilty of myself), but when writing a tutorial, choose I, we or you and stick to it. So many articles move from \"next we'll do this\" to \"once you edit this line\" to \"I chose to use x.\" Oftentimes, this is compounded by switching between present and past tense. It's distracting as a reader.\n\nPersonally, I prefer to use \"we\" because I find it friendlier (you sounds too commanding and I can make it sound like too impersonal). Of course, opinion articles will be a lot of I (in fact, as a sidenote, if you are writing an opinion, you should not intentionally or unintentionally assume you are speaking for your audience by using we). I also prefer present tense because it gives a sense that we are actively working together in the moment.\n\nFor example:\n\n> In the above code, I'm looping through a list of posts in Hugo, starting with the 3rd most recent post. You can do this within our `range` loop by checking the index. Within this loop, we will output the month and day of the post. We also displayed the title and the description.\n\nShould be:\n\n> In the above code, we're looping through a list of posts in Hugo, starting with the 3rd most recent post. We're doing this within our `range` loop by checking the index. Within this loop, we're outputting the month and day of the post. We are also displaying the title and the description.\n\nAgain, the example is intentionally simple and contrived but hopefully it illustrates the point.\n\n**Why?** The lack of a consistent voice or tense can be distracting and even potentially confusing for your reader - they may even find themselves reading and rereading a line without even realizing why it is confusing. Plus, it simply makes your content lack a level of polish that can be the difference between an ok article and a great article that I want to share.\n\n\n## No Conclusion\n\nIn conclusion, always include a conclusion. Even if your conclusion is short summary of the article restating the key points - add it. It should, preferably, offer other resources to continue learning or some sort of call to action, even if it's just to share their thoughts in the comments.\n\nFor example:\n\n> Hopefully this article helps you avoid some common pitfalls that have been holding your content back. While there are no hard and fast rules for what makes a good technical article (and you should always feel free to express your own style), the issues discussed here are ones that I've found can detract from otherwise excellent technical details. Let me know if you agree or disagree with any of my suggestions - or have some additional ones of your own - cia the comments or on [Twitter](https://twitter.com/remotesynth)."},{"slug":"comparing-static-site-engines","category":"blog","title":"Comparing Static Site Engines","description":"A presentation and project for comparing static site generators.","tags":["web development","Jamstack"],"body":"\nOn February 18, I had the pleasure of gaving a [talk](http://www.meetup.com/sfhtml5/events/219180801/) to the San Francisco HTML5 User Group. The topic was static site engines, covering the basics of what they are and what they are good for (or what they are not good for). The latter half of the session focused on comparing three popular static site engines: [Jekyll](http://jekyllrb.com/), [Middleman](https://middlemanapp.com/) and [Harp](http://harpjs.com/).\n\nYou can view the presentation below (I am also giving an updated version of this presentation at [DevNexus](https://www.devnexus.com/s/index) in Atlanta later this month).\n\n## Sample Application\n\nIn order to compare the engines, I created a simple sample site, using data from the [Adventure Time Wiki](http://adventuretime.wikia.com/wiki/Adventure_Time_with_Finn_and_Jake_Wiki). The site is intentionally simple, but uses things like custom post attributes, custom global attributes, data and, of course, posts.\n\nYou can get the samples as well as the slide deck [on GitHub](https://github.com/remotesynth/Static-Site-Samples). I am hoping to add additional samples in the coming weeks.\n\n## Recording\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/R-fJWOO1bjE\" frameborder=\"0\" allowfullscreen></iframe>"},{"slug":"conference-cfpadvice","category":"blog","title":"How to Write a Great Conference Talk Proposal from Conference Organizers","description":"Advice and resources from conference organizers on how to create a compelling talk proposal","tags":["general"],"body":"\nWriting your a CFP proposal to speak at a tech conference can be intimidating. I want everyone who wants to speak at a conference to have that opportunity. Sometimes, though, a little help and advice can help open the door.\n\nI already offer free CFP advice via [Twitter dm](https://twitter.com/remotesynth) as well as by participating in [Help Me Abstract](http://helpmeabstract.com/). In this post, however, I reached out to some conference organizers and asked them for advice or resources that they'd offer to potential speakers when creating a talk proposal. Keep in mind that what each specific conference is looking for is subjective, so it is always best (as Dawn points out below) to read the details of each specific CFP, but understanding what conference organizers are looking for can be incredibly useful.\n\n## [Pratik Patel](https://twitter.com/prpatel), Organizer of [Connect.Tech](http://connect.tech/),  [VueConf US](https://us.vuejs.org/) and more\n\nPratik offered the following advice:\n\n> Fundamentals are a great conference topic!\n> \n> Everyone wants to talk about the latest shiny feature in `${NEW_THING}`. Perhaps only one of these will get picked, so your chances for getting accepted are low. Think about a topic that you would consider fundamental: function scoping in JavaScript, Objects in Python, or lambdas in Java, etc. Find out the latest on this topic, and craft an interesting proposal around it! There will likely be others who would enjoy a refresher on the topic and also new developers who can benefit from your presentation.\n\n## [Shawn Pucknell](https://twitter.com/Pucknell), Organizer of [FITC](https://fitc.ca/event/to20/), [Web Unleashed](https://fitc.ca/event/webu19/) and more\n\nShawn recommended you highlight the following:\n\n> **Experience**\n> \n> Be sure to list any relevant speaking experience, including teaching, lecturing, meetup groups, in addition to of course event speaking.\n> \n> **Travel**\n> \n> If your work does cover flight/hotel for you speaking, be sure to mention it as it opens up more speaking opportunities.\n> \n> **Topics**\n> \n> Depending on the CFP, include a list of other topics you would be up for speaking on.\n \n## [Dawn Parzych](https://twitter.com/dparzych), organizer of [Write/Speak/Code](https://www.writespeakcode.com/)\n\nDawn said:\n\n> Here's what we sent in the rejection letter on common reasons talks were rejected:\n> \n> - The talk was focused on a specific technology or programming language. Write/Speak/Code is language agnostic.\n> - A short (one or two sentence) abstract. The selection committee uses the abstract to understand what you will be saying to the audience. This is also what gets published in the program guide to entice participants to attend your talk. While there is no hard and fast rule on how long an abstract should be most talks that were accepted were in the 8-10 sentence range.\n> - Abstracts were missing clear audience takeaways. The attendees are coming to the event to learn. If the selection committee can’t see what the audience will learn, your submission is less likely to be successful. Including a sentence as simple as “Key takeaways from this talk... “ or “Come learn…” can help. You don’t need to give all the details away but a high-level summary is helpful. Also remember that you can provide more detail in the reviewer notes.\n> - The abstract read like the speaker’s bio. While it’s great for the speakers’ experience to inform their talk, we want to center the audience & how the talk can help them. [Aja Hammerly](https://twitter.com/the_thagomizer) offers some good examples on how to write an abstract with the attendee at the center.\n\n## [Floyd Marinescu](https://twitter.com/floydmarinescu), Organizer of [QCon](https://qconferences.com/) around the world\n\nFloyd offered some advice along with an example:\n\n> I think the most important thing is to give detail as to what will be in the talk rather than talk ‘about’ the talk. So more of an outline than an ad. For example below is what Javascript inventor Brendan Eich provided for at talk at a past QCon which we accepted.\n>\n> **The Present and Future of the Web Platform**\n> \n> In this talk I will survey interesting developments in the Web platform, analyze emergent trends, and make some predictions. I'll cover:\n> \n> * The evolution of web technologies and APIs in the github era.\n> * JavaScript in the Harmony era:\n> \t* as the ubiquitous, high-level web programming language;\n> \t* as safe assembly language for compilers such as Emscripten.\n> * HTML, CSS, and DOM beyond \"HTML5\" into the version-free future.\n> * Device, System, and Web APIs for portable, power web apps.\n> * WebRTC for real-time n-way video, audio, and data communications.\n> * Better network protocols, fewer round trips, more piggybacking.\n> * Privacy, security, and user agency in the mobile+cloud era.\n>\n> I will demonstrate some of these points with live code demos.\n\n## [Phil Hawksworth](https://twitter.com/philhawksworth), organizer of [JAMStackConf](https://jamstackconf.com/)\n\nPhil focused on the value of mentoring by a conference that can help you create your proposal:\n\n> At a very high level, we're doing things a little differently this year at the conference in SF. All with a view to ensuring that we improve diversity and inclusivity, and keep on finding great speakers beyond the folks I've been able to beg borrow and steal so far!\n> \n> We're officially running a CFP this time for some of the main slots and also some lightning slots at the conference. While I'm leading the curation of content, there is a small panel of us who will review the submissions to the CFP together.\n> \n> I'm very keen to help people be successful with their proposals, so I've been running regular office hours for real-time feedback, or async feedback all via a #cfp-assistance slack channel. Some of it occurs in private in DMs but there is also an open channel. You can find it in a new slack that we created for the JAMstack conferences and meetups.\n> \n> https://jamstackconf.com/slack\n\n## [Matty Stratton](https://twitter.com/mattstratton) organizer of [DevOps Days](https://devopsdays.org/)\n\nMatty had some simple suggestions:\n\n> - Don’t worry about “spoilers”\n> - “Bullets vs. Prose” is the “Tabs vs. Spaces” of the abstract world\n> - Read the requirements\n> - Don’t skip parts of the form\n\nHe also suggested [Conference Proposals that Don’t Suck](https://alistapart.com/article/conference-proposals-that-dont-suck/) by Russ Unger and [Give Actionable Takeaways](https://bridgetkromhout.com/blog/give-actionable-takeaways/) by Bridget Kromhout as useful resources.\n\n## Additional Resources\n\n* [Alyss Noland](https://twitter.com/PreciselyAlyss), Developer Advocate at Box shared a [Twitter moment](https://twitter.com/i/moments/854466209433010176) filled with tweets and links related to working on your next conference proposal.\n* [Robin Moffatt](https://twitter.com/rmoff), Developer Advocate at Confluent, shared a couple posts of his including [Quick Thoughts on Not Writing a Crap Abstract](https://rmoff.net/2018/12/19/quick-thoughts-on-not-writing-a-crap-abstract/) and a useful [Collection of Articles on How to Write a Good Conference Abstract](https://rmoff.net/2016/05/05/collection-of-articles-on-how-to-write-a-good-conference-abstract/)."},{"slug":"content-model-of-web-is-broken","category":"blog","title":"The Content Model of the Web is Broken","description":"You can't make money off content anymore.","tags":["content strategy"],"body":"\nPrint is dead. This is one of those supposed truisms we're all lead to believe. It may or may not actually be true, but if print isn't dead, it's not healthy. This is especially true when it comes to news and information. Magazines and newspapers are failing all over the place.\n\nHowever, what you may not realize is that this same type of information is dying on the web as well. Sites are disappearing and the ones that aren't, in large part, don't make money off their content. Basically, as of right now, the content model of the web is thoroughly broken, and you are paying the price.\n\nIn this post, I'll speak mostly about sites that focus on content around technology and development, but I think much of this could apply to most any topic area. Keep in mind this is, obviously, all just my personal opinion and some of the information is based on speculation about certain business models.<!--more-->\n\n## The Symptoms\n\nSome popular developer and technology sites have begun to close such as [Dr. Dobb's](http://www.drdobbs.com/architecture-and-design/farewell-dr-dobbs/240169421) and [The H](http://www.h-online.com/news/item/The-H-is-closing-down-1920027.html), to name a couple of recent ones. While these may not seem like horrible losses, I think they are essentially the canary in the coal mine.\n\nIn fact, other sites you may care about more, such as [MacWorld](http://blog.sfgate.com/techchron/2014/09/10/macworld-kills-print-edition-amid-layoffs-at-idg/), InfoQ (run by C4Media) and SD Times (run by BZ Media) have also had to adjust their online businesses to adjust to changing times.\n\nThese are just a few examples, and by no means a comprehensive list.\n\n## What changed?\n\nThere's simply no money in advertising for content sites. Ad networks, most notably Google, don't pay what they once did. Direct advertising dollars are now very hard to come by.\n\nI used to run a site called Flippin' Awesome (now called [Modern Web](http://modernweb.com)), and I can tell you first-hand that the amount of money available for ads was paltry - especially when placed against the amount of space they occupy (and the nuisance they are). Sure, I only got a couple hundred thousand page views a month, but that netted me generally less than $300/mo. Once you factor in the costs of hosting/running the site, plus my time, this was not a profitable venture by any means.\n\n## The Three Types of Surviving Sites\n\nOf course, many sites still survive, but mostly because of trade offs that you may or may not be aware of.\n\n### 1. No Longer Really About Written Content\n\nMany sites survive because their content is really simply a means of promoting their actual revenue generating side of the business. For example, sites like Smashing Magazine, A List Apart and InfoQ (to name a few off the top of my head), primarily serve as promotional vehicles for their conferences, which make money (I know no financial details - I'm purely speculating).\n\nWhile this doesn't mean that their content isn't still for the most part very good, it does mean that it isn't the driving force of their business. This can mean they cut down on publishing, cut down on paying writers, cut down on other things (editorial, technical editing) or some combination of all three. \n\nIn the end, however, if you're site is just promotion expense for some other part of the business, cutting either quality or quantity helps keep the costs manageable.\n\n### 2. Corporate Sponsored\n\nI have some experience in this area as I used to run part of the Adobe Developer Connection (ADC) and now run the Telerik Developer Network. This type of site is similar to the first in that its primary purpose is actually as a promotional vehicle for something else - in this case, to sell you the products and/or services of the company that runs it.\n\nThis also doesn't mean the content is bad. In fact, these types of sites often have the budget to properly compensate authors (or compensate them at all). Paying authors makes it easier to get good authors.\n\nNonetheless, these sites have a clear cut agenda which is to benefit the company footing the bill (that makes sense - it's not a criticism). The content is only as independent as the company behind it chooses (I've been lucky in this sense to have always had freedom). In addition, the site is at the whims of the company - thus, one day the ADC was growing and healthy, the next day it was effectively dead. Running these sorts of sites is not cheap and its impact on sales is tenuous to track (I think they are important, but it can be hard to find a direct link to actual sales).\n\n### 3. They Rely on Free Content\n\nThis type of site doesn't always even exist to be profitable would include most blogs but also sites like my old site (at least when I ran it) and even sites like Huffington Post, who often rely on free or reprinted content, especially outside their main areas.\n\nThe problem with free content is that it isn't always the best quality. I spent a lot of time working on articles and with authors to make sure the content on Flippin' Awesome was worthy of printing. I also had to reject countless submissions, many of which were the article equivalent of spam. Many sites don't have the time, money or interest to do this.\n\nOther sites, like most blogs, rely on the generosity of their authors. However, this means that a) their's usually no one reviewing what they wite and b) it's rarely a top priority, and often die.\n\n## We've Thoroughly Devalued Content and Writers\n\nI hate to say it, but the reason behind all this is that we, the consumers, want our content to be free. Not only that, we also think it should be free of obnoxious ads. This means that, even the sites of types 1 and 2 above, pay authors crap. Let's be honest, no author is making a living on writing articles at $200-300 a pop (which is more or less the going rate). Sure, it's better than nothing, but other motivations have to come into play.\n\nPersonally, I worry that this model is only going to further deteriorate. If you want to make money on content given the money there is on advertising, you either have to produce gobs of content (and raise your page views based on volume) or you use link-bait (and raise your page views based on trickery). Often, it is a combination of both.\n\nIn either case, the quality is what suffers and you pay the price. So the next time you do a Google search and the top 10 articles are filled with link-bait junk written by content farms, just think that this may only get worse.\n"},{"slug":"conversational-interactions","category":"blog","title":"The Future of Interaction?","description":"Will conversational input become the norm?","tags":["general"],"body":"Over the past couple years, we've become more accustomed to different sorts of interactions with devices. While both Android and iOS had their voice assistants and the XBox One Kinect had voice control for the television, it seemed that it wasn't until Amazon's Alexa came around that many people really latched onto voice commands.\n\nThese new types of interactions go beyond voice or other conversational inputs (like bots). There are simple button-interactions like Amazon's Dash and other devices that opt for gesture controlled interactions. However, none of these seem to have gone mainstream.\n\nThis week, Ashley Carman wrote an interesting [article for the Verge](http://www.theverge.com/circuitbreaker/2017/1/26/14390234/gadget-interactions-touchscreen-voice-gesture-control) that talks a bit about these different types of interactions and why so many companies seem intent on pursuing them. She seems skeptical of their ability to go beyond niche uses in the near term, and I generally agree with her. Heck, I would be willing to bet that, for most people, even the Echo is a glorified speaker and timer. This isn't revolutionary.\n\nI've spent some time writing a skill for Alexa and, more recently, exploring building a conversational bot using [SuperScriptJS](https://github.com/superscriptjs/superscript) (I hope to have more about that in the near future). On the one hand, I think the uses for this type of interaction is limited today (for example, when it is unsafe or inconvenient to type), but I do believe that, somehow, this will change and interacting with devices via voice or standard conversational inputs will become the norm (I am _way_ more skeptical about gestures, which have always seemed clunky).\n\nPart of the problem is that, most any voice input or conversational interaction today involves very specific voice commands or extremely well-thought out planning for handling most potential variations of what a user might naturally say or respond. Things can break down quickly once simplistic rules are broken - dumb things like, for example, determining that Brian Rinaldi is my first and last name, but in the case of someone named Mary Anne, Anne is not her last name. Thus the user ends up being limited to very constrictive interactions that are not truly \"conversational,\" making them less natural and comfortable.\n\nBut...this is likely to change. Once it does, I believe we'll see a far clearer path forward on these types of voice and chat interactions."},{"slug":"corporate-culture","category":"blog","title":"Corporate Culture is Pervasive and Resilient","description":"And sometimes that's a terrible thing.","tags":["general"],"body":"\nThere isn't a lot to say that hasn't already been said about [Susan Fowler's recount of her time at Uber](https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber). On the one hand. I am heartened by the [growing backlash](http://mashable.com/2017/02/21/uber-app-store-reviews-plummet/#vc0NJXPA7Oqw) that is well-deserved. I am disheartened that it took so many years for us to realize what a horribly immoral company Uber appears to be.\n\nI was never an Uber customer. Sure, I've taken rides that friends have ordered, but I have never paid for an Uber ride myself. The early stories of Uber's behavior as a company made me not want to be supportive. There were marketing dirty tricks and very poor reactions to incidents involving their drivers.\n\nEach thing that occurred made it clear, at least to me, that this was a company that was very comfortable living in a moral gray area (to put it nicely). All of this followed on the lead of the [behavior of the company CEO](http://mashable.com/2017/02/21/uber-disgusting-examples/#VH5ilj68gmqY). Note how many years back the behavior went (at least in terms of public \"scandals\"). Even the blatant sexism that Fowler endured is obvious in so many of his early comments.\n\nIn my experience, corporate culture is built from the top down and eventually infects everyone in the company - particularly when it is dysfunctional. That is not to say that everyone at Uber is as morally compromised as their CEO, but they are surviving in a dysfunctional system that is defined, in part, by its acceptance of questionable morality (encouraged by a win at any costs mentality) and open sexism.\n\nOne way of surviving in a system like this is (as Susan notes in her story), keeping your head down and focusing on work - avoiding any conflict or interaction that might embroil you in the dysfunction around you. The other way is by thriving on the dysfunction. This is why a dysfunctional corporate culture can be so resilient. Potential allies have been chastened or frightened into inaction and silence and the remaining people have a vested interest in maintaining the status quo.\n\nThat's why I personally have no faith in Uber's stated intent to root out this issue. Especially when the person most responsible for creating it (as noted above) is the one managing the cleaning.\n\nThe good news, in my experience anyway, is that healthy and supportive corporate cultures are resilient as well. Speaking up is promoted and everyone tends to have a vested interest in maintaining (or improving) the status quo. When problems arise, they are usually handled properly and expediently to prevent issues spreading. This is why, _who_ I work with has become as important to me when choosing a role as _where_ I work (or even how much I am paid). I am never going to face the sexism that Susan had to face, but I want to work with people who support and care for each other."},{"slug":"current-state-of-development","category":"blog","title":"The Current State of Development","description":"Mapping the hype cycle of development technologies","tags":["general"],"body":"\n[Yvo Schaap](https://twitter.com/yvoschaap) has created an interesting new tool he's called [State.Of.Dev](https://stateofdev.com/). The idea behind the tool is that it maps out the state of various web, mobile and general development technologies and languages on something like the Gartner Hype Cycle. Yvo explains the basics behind the idea in [an article on dev.to](https://dev.to/yvoschaap/stateofdev-visualization-of-the-current-state-of-development).\n\nThis is an interesting idea with the caveat that right now, as the article states, the charts are based solely upon Yvo's own opinions and expertise. For example, here is the chart for the [current state of web standards](https://stateofdev.com/c/javascript).\n\n![](/images/posts/web-standards-state-of-dev.svg)\n\nMy own view may be that many of the items on that chart are a little further along in the cycle than I'd expect. PWA, for example, seems to be not yet at full \"peak expectation.\" It's so early in its life that I'd probably put it just over the start of peak expectation. Heck, at this point, it's hype exceeds its ability in that it is still a Google/Android thing with no iOS support in sight.\n\nWhich gets at another weakness of the project so far, and that is clear definitions of the various stages. For instance, Gartner gives a basic [definition of each hype cycle and how their methodology works](http://www.gartner.com/technology/research/methodologies/hype-cycle.jsp). Even accounting for this currently only representing one person's opinion, it doesn't make it clear how he defined each segment of the cycle or how each item was evaluated.\n\nDespite my criticism here, I want to make clear that I think this is a potentially worthwhile idea - and Yvo himself made it clear that this is a very early version and will evolve. Hopefully as it evolves, it addresses some of these concerns, and I am hopeful that it will."},{"slug":"dealing-with-unhappy-communities","category":"blog","title":"Dealing with an Unhappy Community","description":"What happens when your community pushes back?","tags":["general"],"body":"\nMost of us deal with the \"community\" in our jobs on some level or another. Perhaps we are an engineer on a product that has a community of users, or work for a company that has a community of customers, or, perhaps, are in a position to be part of the public face of a company, product or service who is tasked with communicating with the community as part of your job duties.\n\nRecently, I wrote an article about a [bit of a dust up in the AngularJS community](http://developer.telerik.com/featured/can-angularjs-maintain-dominance/) about the plans for Angular 2.0 and it got me thinking about how we deal with the community - specifically when there is a widespread community backlash.\n<!--more-->\n\n## We're Not Talking About Trolls\n\nThere's a big difference between trolls, whose complaints are almost always singular in nature (and agressive in tone). In my experience, trolls complain alone and specifically target an issue that is very specific to them. In this case, I'm talking about a decision that caused widespread unhappiness in your customer base or users and is being expressed, sometimes angrily but rarely aggressively, by a large swath of your community.\n\n## I Have Some Experience in This\n\nI've been on both sides of community backlashes. Professionally, I was the Flash and Flex community manager at Adobe around the time of the infamous \"Thoughts on Flash\" essay by Steve Jobs. At the time and understandably, any actions Adobe took around Flash and Flex were heavily scrutinized. I was still a public face for the products (even if I had technically just been reorged) around the time that Adobe decided to end of life...errr...open source Flex. As you can imagine, I caught a fair share of flak.\n\nNonetheless, I think it taught me a lot of great lessons that I've carried into my positions since, both for and after Adobe.\n\n## The Different Kinds of Decisions that Cause Backlash\n\nIn my experience there are three core types of decisions (by a product team, company, open source project, etc.) that can often lead to a backlash. The first two are relatively easy to handle.\n\n### Necessary Decisions\n\nLet's face it - sometimes there are decisions that you, your company, or your product team may make that simply have to be made, but will, nonetheless, make your community unhappy. Sometimes, you, personally, don't even like the decision. However, there's a big difference betwen liking a decision and understanding and supporting why it was made.\n\nTo me this is easy to handle as your options are very limited. You can and should be understanding of your communities right to be upset about the decision. You can communicate why the decision was necessary and, if applicable, explain that you aren't happy either, even if you support its necessity.\n\nThe last thing you can do in this case is simply develop a thick skin. You're gonna get some lumps and that's ok. Keep in mind that these things pass and often seem much worse in the moment than they do in retrospect.\n\n### Poorly Communicated Decisions\n\nSometimes it isn't really what changed that upset your community but how you, your company or others communicated that decision to them. In my experience, sometimes companies spend so much time wordsmithing their communications that they remove all humanity from them - they sound like they are coming from a committee who is more concerned with protecting the company than with the impact of decisions on their customers. This (and other things) can lead to communicating a the impact of a change poorly.\n\nIn this case, I also think the response is simple, if not easy, which is to clear up the miscommunication (and soften any hard feelings it may have caused). For instance, you could draft a clear and personal message expressing concern for the misunderstanding and clarifying the impact. Make this the opposite of the company-type PR response - make sure they understand that you are a part of that community and care personally about it.\n\nOf course, if you can smooth some hurt feelings with free stuff of some sort, that always helps too.\n\n### \"Best Intention\" Decisions\n\nWhat the heck do I mean by this? Well, this is kind of where AngularJS was. Sometimes decisions are made that impact our customers, users, or whatever that are made with the best intentions, but, in the end, we misread the needs of our customers/users/etc. It wasn't that we miscommunicated. They understood - they just didn't like what they heard.\n\nYou may think these would actually be the easiest decisions to deal with - simply walk back the choice that made them unhappy. However, assuming this is the best response isn't correct.\n\nSometimes, as it turns out, the decision you made is the right decision for the future of the product, service, company, etc. This can get lost in the fog of loud and unhappy users. However, if you let the dust settle, it turns out that it wasn't as big a deal as it sounded and the \"mob\" seemed much larger because it was loud.\n\nSometimes, the decision was in the right direction, but it's now up to you to translate your customer anger into adjustments to the choice (this appears to be [what AngularJS is doing by the way](https://github.com/angular/angular/issues/133)). You were headed down the right path, you just went a little too far or veered slightly off course. Now you just need to take a few steps back or to the right/left, and your community will be happy again.\n\nSometimes, the decision was a poor one made with the best of intentions and should, in fact, be walked back entirely.\n\nThe point is, there are many options to choose from in this case, and knowing which is the right one isn't always easy when you are receiving a barrage of unhappy tweets, blog posts, comments and more coming your way.\n\n## Whatever You Do, Don't Assume Your Community Is Wrong\n\nHere's the thing to recognize - in none of these cases is the community wrong. Remember, these aren't trolls - they are community members we care about with a legitimate complaint. In case 1, they have every right to be unhappy even if there's little we can do about it. In case 2, we communicated poorly and this led to them being unhappy. In case 3, we probably just need to adjust a little - even if the reaction may have seemed overly harsh. The single biggest mistake you can make in any of these cases is thinking you are somehow better or more enlightened than your commmunity and plowing ahead with your decisions accordingly.\n\nI'd love to hear thoughts."},{"slug":"decline-of-email","category":"blog","title":"The Slow Decline of Email","description":"You hate it but you can't get rid of it yet.","tags":["general"],"body":"\nWalt Mossberg has an [interesting post about the way email is changing](http://www.theverge.com/2017/3/29/15099510/walt-mossberg-email-growing-changing-vs-slack-snapchat-chat). From once dominating electronic communication, it is now becoming more like traditional mail, in that it's most junk and marketing with the occassional official communications mixed in with a newsletter subscription or two. It's not just generally unpleasant, but it's also the easiest route for scammers.\n\n> By and large, email is now a generally unpleasant, often untrustworthy, and sometimes literally perilous experience that deserves less and less of our time and attention. But it’s not dead, and I don’t expect it to disappear anytime soon. Just be wary of it.\n\nRather than die, email is now supplemented with Slack, Twitter, Facebook, SnapChat, etc. However, none of these things has _replaced_ email, so we're stuck, for the moment, with a multitude of communication channels."},{"slug":"developer-career-journey","category":"blog","title":"A Developer Career Doesn't Have to Be Linear","description":"Tips for finding your unique path in your career development as a developer.","tags":["general"],"body":"\nI found myself in a rut about 10 years ago. I'd been working as a developer already for some time and I wanted to move forward in my career. However, the only path that I could see was one from developer to team lead to development manager. There is nothing wrong with this path, but it wasn't an appealing one to me.\n\nThe truth is, as I've since learned, that just as there is [more than one way to become a developer](https://dev.to/remotesynth/there-s-more-than-one-way-to-become-a-developer-3h09), there are also multiple career paths open to you as your career develops. The key, for me, was to change my own mindset. In this post, I want to share what worked for me in the hopes that it might help those of you for whom the traditional career path for a developer also isn't appealing.\n\n## Don't Rely On Your Job to Teach You What You Want to Learn\n\n> There are certainly more engaging jobs out there, but the reality is a lot of us do work on little fragments, work that is often tedious and devoid of any kind of creativity. As a developer I’ve often had trouble figuring out if a job would be Snow Crashy or not, and been seduced by promises of engaging work only to find myself ferreting out bugs on some enterprise CMS.\n> \"[I just don’t want to be a software developer anymore](https://medium.com/@melissamcewen/i-just-dont-want-to-be-a-software-developer-anymore-a371422069a1) by Melissa McEwen\n\nThe reality is that, while a career as a developer is a great one and the work can often be exciting and challenging, the day-to-day of a traditional developer role can be tedious. Younger me thought this was a problem that my job should solve by offering me more interesting challenges and pushing me forward, and if it couldn't then I needed to find the next job that could. However, the truth was that it was up to me, and realizing this was the biggest revelation for my career.\n\nFor instance, if there was some new tool or framework or type of development that I was interested in learning, I needed to find the time to learn it rather than wait for my employer to come up with a reason for me to do so. If you are learning the things you want to learn at work, all the better! But if you cannot, don't let your job stop you.\n\nIf you are thinking, \"I want to learn X but work won't let me use it,\" then find a way to learn it outside of work. This doesn't mean you should live and breath code and spend all your free time on side projects, but it does mean that you shouldn't let the needs of your current job limit you - follow your interests and make it happen!\n\n## Find Ways to Explore Your Creativity Beyond Code\n\nWhile it is important to not let your job limit the skills you want to learn when it comes to coding, if you aren't looking to follow a traditional career path, then it is important to explore your creative skills beyond just code. These can help illuminate a different path for you.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">To be a good developer you don’t have to spend 99% of your time writing, reading about coding. Do other activities. it helps to be more creative and to enrich your knowledge.<br><br>What other activities do you engage in aside coding 🤔🤔</p>&mdash; Amycruz 👩‍💻 👩‍💻 👩‍💻 (@AmarachiAmaechi) <a href=\"https://twitter.com/AmarachiAmaechi/status/1132018328988454912?ref_src=twsrc%5Etfw\">May 24, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nFor example, I had always loved writing. My college studies were not even in computer science but in areas that focused heavily on writing skills. So I started writing for journals and blogging. Sure, my writing was about coding, but it was allowing me to explore skills and interests that I'd let atrophy somewhat. As it turned out, my alternative career path would be heavily focused on writing, so exploring this skill was the first step in opening up that path.\n\nWhatever your interests are beyond code, explore them. You may think that they are too far unrelated to your job as a developer to be relevant, but  you never know where they may lead. Coding skills are relevant in so many creative fields nowadays that you may be surprised what doors this opens up for you.\n\n## Don't Take No For an Answer\n\nThis follows on the first two tips - don't let yourself be limited. Some of the best things I have done in my career have been when I was told no. Following the things that I was passionate about was a key to changing my career path - and there was no better way to realize I was passionate about something than when someone told me it couldn't be done.\n\nFor example, I really wanted to attend some developer conferences. My employer at the time didn't cover attending conferences and I couldn't afford to attend on my own (especially since I'd have to take vacation days to do so). I decided that, since I couldn't leave to attend a conference, I'd start one! That conference sold out nearly all five years I ran it and, in fact, I eventually had to sell it because it helped lead to that career change that I was looking for all along (it still runs under a slightly different name, in fact).\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The biggest motivator for me sometimes is just proving people wrong, makes me want to do it 1000x bigger and better just to prove I can <a href=\"https://t.co/qzuo5R9HEc\">pic.twitter.com/qzuo5R9HEc</a></p>&mdash; jessie frazelle 👩🏼‍🚀 (@jessfraz) <a href=\"https://twitter.com/jessfraz/status/1132703874194771968?ref_src=twsrc%5Etfw\">May 26, 2019</a></blockquote>\n\nThat's just one example, but I could list a number more. The point is to follow your passion and don't let it be dictated by other people.\n\n## There Are a Lot of Paths You Can Follow!\n\nWhat I've learned in the ten or so years since that rut I was in is that there are a ton of paths open beyond the traditional one - I just needed to broaden my horizons a bit. There are some more obvious paths such as developer relations, community management, product management, product marketing and even marketing. Many companies see developer skills as something useful beyond the straightforward developer roles.\n\nThere are also less obvious paths that many developers I've met have followed, often through paths involving entrepreneurship or even philanthropy (such as starting a non-profit). Honestly, the more developers I talk with, the more amazing stories I come across, and the more I realize that a developer career isn't really like a path but more like a wide open field with countless destinations...I hope you find yours!\n\n"},{"slug":"developer-communities","category":"blog","title":"Developer Communities You Need to Join Today!","description":"Learn and share with other developers in these communities!","tags":["general"],"body":"\nCoding is hard. And there is so much to learn, no one person can really know it all. I think that's why developers tend to rely on the developer community so much (more than other types of jobs I think). It's why welcoming community hubs like [dev.to](https//dev.to) have exploded.\n\nIn this post, I wanted to share three communities that offer the opportunity to learn from and connect with your fellow developers. They are communities that I participate in actively and have gained a lot from. Even when they cater to new or aspiring developers (as a couple of them tend to do), I've found amazing opportunities to learn, even as someone with decades of experience as a developer.\n\n## [CFE.dev](https://cfe.dev)\n\n![CFE.dev](/images/posts/cfe.png)\n\nI am totally biased about this one as I created it and run it, but I do that as a way to give back to the developer community and share my love for learning about code and technology. This month is actually the anniversary of 4 years of running CFE.\n\n**What is it?**\n\n[CFE.dev](cfe.dev) runs live, virtual meetups pretty much every two weeks on a wide range of developer topics – everything from JavaScript or IoT to career and culture. We also run occasional conferences or workshops like [TheJam.dev](https://thejam.dev) in January and [Moar Serverless](https://moarserverless.com) (which is this week!). These are paid, which is how I am able to keep the lights on. However, all of the 4 years worth of prior recordings (including from our past events and workshops) are [available for free](https://cfe.dev/sessions/)!\n\n## [Virtual Coffee](https://virtualcoffee.io)\n\n![Virtual Coffee](/images/posts/VirtualCoffee.png)\n\nVirtual Coffee was created by [Bekah Hawrot Weigel](https://twitter.com/BekahHW) and [Dan Ott](https://twitter.com/danieltott). It was inspired to build connections and networking opportunities for developers, especially new and aspiring developers, during the pandemic. Virtual Coffee has grown enormously because it offers a laid-back and welcoming place for you to meet and talk about important developer topics.\n\n**What is it?**\n\n[Virtual Coffee](https://virtualcoffee.io/) offers numerous opportunities to meet and connect via Zoom every week. They generally host two \"morning crowd\" get togethers each week at 9am ET and two \"afternoon crowd\" get togethers at noon ET. They also have a \"brownbag session\" most Friday's at noon ET. The brownbag sessions are for members only and are more focused on learning a particular topic, taught by a member of the Virtual Coffee community. Membership is completely free but does require that you've attended at least one morning/afternoon crowd get together. This also gives you access to their private Slack community, which is very active and extremely helpful.\n\n## [MintBean](https://mintbean.io/)\n\n![Mintbean](/images/posts/mintbean.png)\n\nMintbean was created by [Monarch Wadia](https://twitter.com/monarchwadia) and [Navi Mann](https://twitter.com/Navi1Mann). Inspired by their own experiences in tech, they created it as a community aiming to help new and aspiring developers gain the knowledge and experience they need to land a job and be successful as developers. In particular, they help devs bridge the gap between a boot camp and a successful career.\n\n**What is it?**\n\n[MintBean](https://mintbean.io/) hosts regular virtual meets every week with speakers on a variety of topics as well as virtual hackathons. This gives you the opportunity not just to learn from the community, but also to team up with your fellow developers and build something fun and useful that you can add to your portfolio. Mintbean also hosts a very active Discord server where you can communicate in between meets and hackathons.\n\n## Be a Part of the Developer Community!\n\nEach of these communities emphasizes different learning styles and opportunities. You can, of course, join all of them (I did), but you can also find the one that fits you the best. I hope to see you there!"},{"slug":"developer-events-fall-2017","category":"blog","title":"Developer Events in Fall 2017","description":"I'm running a ton of events this Fall.","tags":["general"],"body":"\n2017 has been very quiet for me on the speaking front, but, as it turns out, busier than ever on the event front. I am organizing a lot of events this Fall - online, in NYC and in Sofia, Bulgaria (with more in the works too). All of the events are either free or incredibly inexpensive. Here's an overview:<!--more-->\n\n[![JavaScript in 2017](/images/posts/events2017/JavaScript2017.jpg)](http://certifiedfreshevents.com/events/javascript-2017/)\n\n## [Developing JavaScript in 2017](http://certifiedfreshevents.com/events/javascript-2017/)\n### Online\n### August 23\n#### Cost: Free\n\nJavaScript development has seen a lot of changes in recent years, between new specifications like ES6 and ES7 to new tooling like TypeScript. This free event featuring Raymond Camden and TJ VanToll takes a look at some of these advancements and how developers can realistically start taking advantage of them today.\n\n[![NativeScript Developer Day](/images/posts/events2017/NativeScriptDay.jpg)](http://developerday.nativescript.org/)\n\n## [NativeScript Developer Day](http://developerday.nativescript.org/)\n### New York City\n### September 18-19\n#### Cost: $100\n\nNativeScript Developer Day is an annual event dedicated to the free and open-source NativeScript platform for building native mobile apps with JavaScript, TypeScript and/or Angular. Whether you’re a beginner curious about NativeScript or a seasoned mobile developer, NativeScript Developer Day has speakers and sessions for you.\n\n[![Exploring JavaScript Frameworks](/images/posts/events2017/JSFrameworks.jpg)](http://certifiedfreshevents.com/events/exploring-javascript-frameworks/)\n\n## [Exploring JavaScript Frameworks](http://certifiedfreshevents.com/events/exploring-javascript-frameworks/)\n### Online\n### October 5\n#### Cost: Free\n\nIt seems that there are few guarantees in life, but two of them are that the sun will rise in the morning and, with it, will come at least two new JavaScript frameworks. So how is a developer supposed to keep up? How can you tell the contenders from the pretenders? In this free online event, Jen Looper and Holly Schinsky will take a look at some of the more prominent new frameworks to help you decide if they are worth exploring further.\n\n[![Going Serverless](/images/posts/events2017/Serverless.jpg)](http://certifiedfreshevents.com/events/going-serverless/)\n\n## [Going Serverless](http://certifiedfreshevents.com/events/going-serverless/)\n### Online\n### October 20\n#### Cost: Free\n\nLately the term serverless is everywhere, which naturally makes developers skeptical that it is a marketing buzzword. However, behind the term is a useful concept of tools and architecture that takes the need to worry about servers (if not actual servers themselves) out of the equation. In this free online event, Burke Holland and James Thomas will explore what serverless is, why it is an important new development, and where it will haev the most impact.\n\n[![DevReach](/images/posts/events2017/DevReach.jpg)](http://devreach.com/)\n\n## [DevReach](http://devreach.com/)\n### Sofia, Bulgaria\n### November 13-14\n#### Cost: €120 (early bird price - ends 8/31)\n\nDevReach was once one of the premier developer conference in Central and Eastern Europe, founded back in 2006. After a 3 year hiatus, DevReach is back! The conference is intended for anyone interested in application development. Topics include .NET Development, front-end development and JavaScript, mobile application development and tools and best practices for developers."},{"slug":"developer-resources","category":"blog","title":"What are the Must Follow Resources for Developers?","description":"The sites and newsletters for developers that I follow.","tags":["web development","javascript"],"body":"\nThe other day, the Node.js Twitter account asked what resources developers use to learn about JavaScript, web development and app development.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Where do you go to find news or resources around JavaScript, web development, app development?</p>&mdash; Node.js (@nodejs) <a href=\"https://twitter.com/nodejs/status/954023843156414465?ref_src=twsrc%5Etfw\">January 18, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThis is a topic that I have revisited from time, but the list tends to change regularly as sites and newsletters come and go or they change in ways that make them more or less useful (to me). Today I will focus specifically on two types of developers resources:\n\n* [Link Aggregators](#aggregators)\n* [Newsletters](#newsletters)\n\nI have organized these into the resources that I, personally, always check/read (i.e. daily for sites or every issue for newsletters), frequently do (i.e. weekly or about every other issue), occasionally (i.e. less than once a week for sites or less than once a month for newsletters) and rarely (i.e. I still check it or subscribe but only read infrequently).\n\n### Don't Get Insulted\n\nSome things I should note before anyone gets upset.\n\nFirst, this is *my personal preference*. It depends heavily on what I do for a living. So, for instance, I don't do a lot of design or CSS for example, so even if I do still subscribe or check a site, a design-focused site will tend to be lower on my own list in terms of its usefulness.\n\nSecond (and this is especially relevant to newsletters), if I really find a site or newsletter not useful at all - I don't even bother checking it - ever. This means it won't make the list. And if I found a newsletter useless, I unsubscribe. The sites and newsletters I've included (even in the \"rarely\" section) are there because you may find them useful in *your* work or interests. \n\n<a name=\"aggregators\"></a>\n## Aggregators\n\nPersonally, I still rely on RSS for much of my reading, but even then aggregation sites can be a useful tool to keep up with sources that I may not be aware of.\n\n### Always\n\n[EchoJS](http://www.echojs.com/)<br>\nEchoJS is, as the name implies, focused on JavaScript and other related articles. It allows community submission, voting and commenting. It is very open about this, which means that some garbage sometimes makes it through, but these are usually obvious and get voted down fairly quickly. The commenting is usually fairly empty or light (though infrequently it can get intense).\n\n[Front-End Front](https://frontendfront.com/)<br>\nFront-End Front is focused on front-end development, so it includes some similar topics as EchoJS, but also tends to have more general web design and development articles, while EchoJS is more focused specifically on JavaScript programming. It also allows community submissions, voting and commenting, though I rarely see any comments and it seems to keep the front-page clear of spammy posts.s\n\n[Collective by CoDrops](https://tympanus.net/codrops/collective/)<br>\nUnlike the above sites, Collective is a twice-weekly post that is manually curated. It does include some sponsored content, but these are generally on-topic and clearly indicated. The links tend to lean more towards web design, but cover a wide-range of topics including programming, design, work culture and more.\n\n### Frequently\n\n[JavaScript Live](https://jslive.com/)<br>\nJavaScript Live is part of Cooper Press, that publishes JavaScript Weekly. If you want your post considered for JavaScript Weekly, this is the place to post it. Anyone can post a link or comment but there aren't any voting features, so it can be prone to spam from time to time.\n\n[Lobsters](https://lobste.rs/)<br>\nLobsters is like Hacker News if it were specific to programming. Lobsters tends to surface up very deep technical articles. You must be invited to join the community and, in my experience, it can be a little harsh and unwelcoming at times.\n\n[Hacker News](http://news.ycombinator.com/)<br>\nI probably don't even need to explain Hacker News to you. You know what it is and that it can be a bit overwhelming in terms of the pace of content, the broad range of topics and the comments thread, which has well-deserved infamy.\n\n### Occasionally\n\n[Crater.io](https://crater.io/)<br>\nThis site functions in a similar fashion to most of the other aggregators, but the voting and commenting from the community seems rare.\n\n[WebDesignerNews](http://www.webdesignernews.com/)<br>\nThe usual features (posting recommendations, commenting and voting), though the posts are not automatic but manually curated. It is, as the name implies, much more web design rather than web development focused - thus why I don't visit as often.\n\n[JavaScriptKicks](https://javascriptkicks.com/)<br>\nAnyone can sign up to submit a feed to be monitored or post a URL, though there is no commenting or voting and the activity seems light.\n\n### Rarely\n\n[DZone](http://www.dzone.com/links/index.html)<br>\nYes, DZone allows links but they seem to be more focused on their own content rather than serving as a useful aggregator (which is fine, just not what I'm looking for - plus, they tend to be ad-heavy).\n\n[Reddit](http://www.reddit.com/)<br>\nPersonally, I find the Reddit community to be unwelcoming to the point of being unhelpful. Sorry for you Reddit fans.\n\n<a name=\"newsletters\"></a>\n## Newsletters\n\nWant your content pushed to you rather than having to go look for it? Well, the good news is that there are tons of useful newsletters. The bad news is that there are so many nowadays, you could inundate your inbox.\n\n### Always\n\n[JavaScript Weekly](http://javascriptweekly.com/)<br>\nThe most popular of the newsletters listed here is still, in my opinion, the best. The Cooper Press crew knows how to curate a newsletter (I mean, they have a ton of them) and has always kept this one relevant.\n\n[Frontend Focus](https://frontendfoc.us/)<br>\nAnother Cooper Press newsletter, but with more web standards, HTML, CSS and related technologies (it used to be HTML5 Weekly).\n\n[Mobile Dev Weekly](https://mobilewebweekly.com/)<br>\nCurated by yours truly, along with my good friend Holly Schinsky and the Cooper Press crew. We focus on anything mobile development (mobile web, hybrid, JavaScript native solutions and native development). We used to be purely mobile web focused but have broadened the topics a bit.\n\n[History of the Web](https://thehistoryoftheweb.com/)<br>\nI think having an understanding of history gives us insight into the present. And if you want to be a web developer, it can be useful to look at the (short) history of the web. Plus, this newsletter, on top of being useful, is always fun to read.\n\n[Web Design Weekly](https://web-design-weekly.com/)<br>\nAs the name implies, this is much more design-focused, but tends to include a lot of front-end development topics and is very-well curated.\n\n### Frequently\n\n[ES.Next News](http://esnextnews.com/)<br>\nThis is a relatively recent newsletter being curated by Dr. Axel Rauschmayer. It is usually very tidy (by that I mean, very focused on its topic and includes a limited set of links). If you are especially interested in the JavaScript language, it is recommended.\n\n[Responsive Web Design Weekly](https://responsivedesign.is/)<br>\nWhile RWD and just regular web design may be indistinguishable nowadays, this newsletter still offers some solid links. It's web with a mobile tilt and some design.\n\n[CSS Weekly](http://css-weekly.com/)<br>\nAnother very good newsletter, which I would read more if CSS and design were my focus. Zoran keeps the links to no more than ten, making it quick and easy to find those relevant to you.\n\n### Occasionally\n\n[Serverless Status](https://serverless.email/)<br>\nThis is partly curated by my friend Raymond Camden along with Cooper Press. Even if it isn't a primary resource for me personally, as I delve into the serverless space, I am relying on it more.\n\n[WDRL](https://wdrl.info/)<br>\nThe Web Design Reading List by Anselm Hannemann is good in that it has a limited number of links but also tries to offer context to them. It covers a wide-range of topics, so there's not always information that is pertinent to me, but still worth checking out.\n\n[HeyDesigner](https://heydesigner.com/newsletter/)<br>\nHeyDesigner's weekly newsletter is worth subscribing to if you are more design focused, even though it does include some more general web development related topics each week. \n\n[O'Reilly Web Newsletter](http://www.oreilly.com/web-platform/newsletter.html)<br>\nO'Reilly's web newsletter is good in that it offers a longer form summary of the limited list of links included. I think it might be more useful to me, personally, if I didn't already subscribe to the above because, by the time it arrives, I've often seen the articles I care about that it includes.\n\n### Rarely\n\nNote that all of these are actually good newsletters, or else I would have unsubscribed. As I note below, it's just that they generally cover topics that aren't always as relevant to me specifically.\n\n[O'Reilly Programming News](http://www.oreilly.com/programming/newsletter.html)<br>\nNot a bad newsletter, just a very broad range of topics that aren't always relevant to me personally.\n\n[PonyFoo](https://ponyfoo.com/weekly)<br>\nThis is curated by Nicolás Bevacqua. The links are usually very deep technical articles that tend to be a bit over my head or above my skill level (or both). If you are smarter than I am though, it's worth a read.\n\n[Vue.js Radar](https://www.vuejsradar.com/)<br>\nThis is a well done newsletter with a very singular focus. I don't tend to subscribe to framework-specific newsletters, but if you are heavily focused on Vue, this could be worth a read.\n\n[CSS Animation Weekly](https://cssanimation.rocks/weekly/)<br>\nI actually enjoy perusing this article as I wish that I had time, energy and enough artistic ability to do animation. If you do, I definitely recommend it."},{"slug":"developer-tools","category":"blog","title":"Don't Let Your Tools Define You as a Developer","description":"Developers are defining themselves into ever smaller niches and that concerns me.","tags":["web development"],"body":"\nOne of the changes I've been able to witness over the course of my career involves the way web developers refer to themselves. In the early days, when nothing web was considered real development, you were a \"webmaster\". For those of you unfamiliar with the term, a webmaster is like a beastmaster with more clothes but fewer beasts.\n\n![beastmaster](/images/posts/tools/beastmaster.jpg)\n\nEventually we all became \"web developers\", which meant that we built everything from the frontend to the backend. As web development became more complex, however, these split to where many web developers became frontend developers.\n\nHere's where I believe things started to change. Suddenly you'd meet people who wouldn't identify either as a web developer or frontend developer, but as things like an Angular developer or React developer.\n\n## What's Changed?\n\nWe've had web frameworks since the early days. While it may be more prevalent today than before, as you can see by the below timeline, it's not a new phenomenon.\n\n[![history of web frameworks](/images/posts/tools/history-of-web-frameworks-timeline.png)](https://github.com/mraible/history-of-web-frameworks-timeline/blob/master/history-of-web-frameworks-timeline.png)<br>\n_Source: [The History of Web Frameworks Timeline](https://github.com/mraible/history-of-web-frameworks-timeline) by Matt Raible_\n\nBack between 2006 and 2012 though, you'd likely never hear a web developer refer to themselves as a jQuery developer or Dojo developer. It really wasn't until the rise of modern frameworks like React, Angular, Ember and Vue that developers (and even their employers) started referring to themselves in relation to their chosen framework.\n\n## Why It's Problematic to Tie Your Tool to Your Identity\n\nDevelopers have always had issues with a semi-religious affiliation with their favorite tools. Historically, this took the form of \"my language is better than your language\" debates. Part of this is because being a Java developer or a Ruby developer or a .NET developer becomes infused in a sense of identity.\n\nThese aren't healthy debates, but today we've taken them many steps further by narrowing those into smaller niches defined by frameworks within a given community.\n\n![isolation](/images/posts/tools/isolation.jpg) \n\nIf I'm an Angular developer, for instance, I might be in Angular groups, read Angular blogs and go to Angular developer conferences. The same goes for other communities - and this isn't even specific to Angular or web frameworks.\n\nI believe that becoming too entrenched in your specific tool and defining yourself by it is problematic for a number of reasons:\n* You limit your own career flexibility and opportunities by tying yourself to a specific tool. The tools we use to build the web come and go, but web development is here to stay.\n* It limits your perspective to viewing things as a threat or an aid depending solely on its impact to your chosen tool. An Angular developer may view things that benefit Vue adoption as a threat to their own livelihood or even identity.\n* It can tie your career success to the fortunes of a specific company or project.\n* It can lead to judging people's value based upon their affiliation to your tool of choice.\n\nDevelopers put a lot of time and effort into learning tools and the ecosystems that sometimes exist around them, so it is understandable that they feel invested in them. But let's be honest - we have enough problems we need to address in the developer community right now than to let one's choice of web framework get between people. Let's focus on the things that bind us together - a love for the web and building great experiences on it!"},{"slug":"developers-and-licenses","category":"blog","title":"Developers Need to Start Paying Attention to Licenses","description":"Ignoring licenses can be dangerous. Let's try to understand them.","tags":["general"],"body":"\nAnyone who claims to be a fan of mashups (which, admittedly, had their moment that seems to have passed) knows [Girl Talk](http://illegal-art.net/girltalk/). Girl Talk (aka Gregg Michael Gillis) had a crazy style of mashup made up of short, somewhat chaotic samples, usually blended together into one full \"album\"-worth of music.\n\nHe was also fearless, sampling from artists that others dared not - both recent hits and classic artists. Looking at the [samples in his \"Feed the Animals\"](http://www.illegal-tracklist.net/Tracklists/FeedTheAnimals) album from 2008, you'll see literally hundreds of samples making up the 14 tracks.\n\n>  Girl Talk (real name Gregg Gillis) has also won critical praise but is not likely to land a big-time contract, commercial radio play, a spot in an iPod ad or even distribution on iTunes. This is because “Feed the Animals” is composed almost entirely of more than 200 samples of other artists’ music, ranging from Lil Wayne to Kenny Loggins — none of which Gillis has obtained permission to use.\n> \n> Rob Walker, [Mash Up Model](http://www.nytimes.com/2008/07/20/magazine/20wwln-consumed-t.html), New York Magazine\n\nThankfully Girl Talk survived without a lawsuit by citing the [fair use](https://en.wikipedia.org/wiki/Fair_use) doctrine, probably aided by the fact that he frequently just gave away the music for free.\n\nSo what does Girl Talk have to do with coding?\n\n## Applications Today are Code Mashups\n\nToday's applications are arguably the equivalent of a Girl Talk album in code. They are made up of code that comes from a variety of sources. For instance, they may use one or more frameworks and libraries each of which may also may rely on hundreds of modules (ex. npm, Ruby gems). Even portions the \"original\" code in a project may have originally been copy/pasted from documentation, a tutorial or \\*gasp\\* StackOverflow.\n\nIf Girl Talk's music mashups were \"[a lawsuit waiting to happen](http://www.nytimes.com/2008/07/20/magazine/20wwln-consumed-t.html)\", why aren't our applications?\n\n## Licenses\n\nPretty much every bit of code we use (even the copy/pasted code) is covered by some form of license (in effect, even code with [no license](https://choosealicense.com/no-license/)). The license determines what you, the developer, can legally do with the code. Can we sell our software that uses the code? Can we redistribute it? Can we use a different license on our code than the code we included? Check the license.\n\nThe thing is developers (myself included) rarely ever look at the license. I'm fairly sure the current process is:\n\n1. Google the problem I am trying to solve\n1. Find a Github project, blog post, etc. that solves this\n1. `npm install` or `gem install` or fork or copy/paste this code into my project.\n\nRarely do those steps include looking at the license. This gets complicated further by the fact that many of these projects have dependencies that each have their own licenses - all of which my project now needs to abide by. Even if I actually read the license, I'd have to trust that the developer of this project was careful about the licenses of their dependencies. (And what if those dependencies have dependencies?)\n\nAssuming I were to read any or all of these licenses. I am not a lawyer. I may have no real clue what any of them mean.\n\n> I should repeat - _I am not a lawyer_. This post will talk a lot about licenses but it is aimed at giving a rough overview of their meaning. To assess the specific requirements and risks for you or your company, you should probably seek proper legal counsel.\n\nNot paying attention to licensing could open you and your company up to lawsuits and other legal consequences. In order to help you avoid those situations, this article aims to give you an overview of the various types of licenses typically associated with the software and code you may use in a given project. Hopefully this can help you stay aware and navigate the complexities.\n\n## Open Source vs. Closed Source\n\nWhen we talk licenses, most developers immediately assume \"open source.\" However, there are lots of companies that sell code libraries (including my current employer among many others).\n\nThe first mistake I've seen many developers make is to use a commercially licensed library as if it was free and open source. Just because a piece of code is publicly available, whether on a CDN, npm or elsewhere, doesn't mean that you are free to use it.\n\nHere's an example. You can include the entire Kendo UI library (not just the open-source portion of Kendo UI core) via a [CDN](http://kendo.cdn.telerik.com/2017.2.621/js/kendo.all.min.js) and your project will work just fine. However, taking a look at the contents, you'll see this:\n\n```javascript\n/** \n * Kendo UI v2017.2.621 (http://www.telerik.com/kendo-ui)                                                                                                                                               \n * Copyright 2017 Telerik AD. All rights reserved.                                                                                                                                                      \n *                                                                                                                                                                                                      \n * Kendo UI commercial licenses may be obtained at                                                                                                                                                      \n * http://www.telerik.com/purchase/license-agreement/kendo-ui-complete                                                                                                                                  \n * If you do not own a commercial license, this file shall be governed by the trial license terms.       \n```\nAs this makes clear, this is a commercially licensed piece of code. The actual license can be found [here](http://www.telerik.com/purchase/license-agreement/kendo-ui-complete). Because you would be using this software without a purchased license, you fall into the trial license which is defined as:\n\n> 1.1.1 License Grant. If You download the free Trial License, then, subject to the terms and conditions set forth in this agreement, Licensor hereby grants to Licensee and Licensee hereby accepts a license to use the Software for the sole purpose of evaluating its functionality and performance. You are not allowed to integrate the Software into end products or use it for any commercial, productive or training purpose. You may not redistribute the Software. The term of the Trial License shall be 30 days. If You wish to continue using the Software beyond expiration of the Trial License, You must purchase the applicable commercial license.\n\nThe important things to note are that you cannot use this \"into end products or use it for any commercial, productive or training purpose\" - basically, nothing that goes into production. Also, the \"term of the Trial License shall be 30 days\" - after your 30 days are up, if you don't purchase a license, you are in violation. Note that it doesn't say that you are free to keep using it in non-production apps - the only two options of the license after 30 days are purchase or don't use the product.\n\nThe point here is not to single out Kendo UI in any way - there are lots of vendors selling software via similar means with similar licenses (though I don't believe that there is any specific requirements that a commercial license must abide by) - but just to reiterate that just because the code is available does not mean that you can use it.\n\n### What Types of Licenses Qualify as Open Source?\n\nThe Open Source Initiative (OSI) is the \"stewards of the Open Source Definition (OSD) and the community-recognized body for reviewing and approving licenses as OSD-conformant\" according to their [open source definition](https://opensource.org/osd). They have a review process for approving new licenses and maintain a [list of their approved licenses](https://opensource.org/licenses/category) that qualify as open source.\n\nHowever, it's worth noting that just because OSI has approved a license doesn't mean that the community as a whole agrees that this qualifies as open source. As an example, there has been a lot of talk over the React license recently. React uses a BSD+Patent license (you can see their explanation of the license [here](https://heathermeeker.com/2017/08/19/open-source-community-over-reacts-to-x-rated-code/) and [here](https://code.facebook.com/posts/112130496157735/explaining-react-s-license/)).\n\nNow, technically the [BSD+Patent](https://opensource.org/licenses/BSDplusPatent) is on the OSI compliant list (I am not qualified to speak to whether React's license is implemented fully in accordance with the OSI approved BSD+Patent license). But, the Apache Software Foundation added it to their [category X](https://www.apache.org/legal/resolved.html#category-x) list, which is a list of licenses that cannot be used in an Apache products.\n\nSo is the BSD+Patent license used by React open source? In the eyes of the OSI, it would appear so. However, in the eyes of the Apache Software Foundation and many others who blogged on the topic, perhaps not (or at least not in the true \"spirit\" of open source).\n\nSo, to answer the question asked in the heading of this section (what types of licenses qualify as open source?) - it depends. Seems appropriate when we are talking about software I suppose.\n\n## Types of Open Source Licenses\n\nA key item to recognize is that not all open-source licenses are the same. Some allow you a lot of freedom to do what you want (in fact, for some time I used the [WTFPL](http://www.wtfpl.net/txt/copying/) on my code, which is about as permissive as you can get). Other licenses have restrictions in terms of things like attribution, redistribution or the kind of license you can have on any work using the software.\n\n### Permissive Licenses\n\nI think part of the carelessness of developers like me regarding licenses has been because we took for granted the proliferation of extremely permissive licenses like the [MIT license](https://opensource.org/licenses/MIT).\n\nAside from the WTFPL, which is not an OSI approved license, MIT is probably the most permissive license out there and also one of the shortest in length. Summed up (again, not a lawyer), it gives you permission to basically do anything - \"use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so...\" The only conditions are that you include a copy of license and agree not to hold the software creators liable for anything.\n\n*(Note: [Wikipedia](https://en.wikipedia.org/wiki/MIT_License#Variants) indicates that there are some variants of the MIT license but the differences are fairly minor.)*\n\nPart of the reason for the MIT license's popularity is probably its simplicity. Even the resources like the [Open Source Guide](https://opensource.guide/legal/#which-open-source-license-is-appropriate-for-my-project) created by GitHub lead developers gently towards the license.\n\n> If you’re starting from a blank slate, it’s hard to go wrong with the MIT License. It’s short, very easy to understand, and allows anyone to do anything so long as they keep a copy of the license, including your copyright notice. You’ll be able to release the project under a different license if you ever need to.\n> \n> [The Open Source Guide](https://opensource.guide/legal/#which-open-source-license-is-appropriate-for-my-project)\n\nThere are a number of other permissive licenses however. Another very popular option is the [Apache License, Version 2.0](https://opensource.org/licenses/Apache-2.0). Besides being quite a bit lengthier, the difference in the Apache license, according to [Choose a License](https://choosealicense.com/) (also created by GitHub) is the following:\n\n> The Apache License 2.0 is a permissive license similar to the MIT License, but also provides an express grant of patent rights from contributors to users.\n\nThis grant of patent rights apparently makes the license more appealing to businesses considering using the software. However, from a developer standpoint there are very few restrictions other than retaining the license, patents and attribution as well as document any changes to the software, but you are still free to do things like redistribute, modify, etc.\n\nThe [BSD license](https://opensource.org/licenses/BSD-2-Clause) is another option. It's similar in its requirements to the MIT and Apache licenses (i.e. the software is available \"as is\" and the copyright notice must remain). \n\n*(Note: There is a [3-clause](https://opensource.org/licenses/BSD-3-Clause) version that is similar to the MIT variant mentioned above in its protection of the names of the copyright holders.)*\n\n### Copyleft\n\nThe key distinction about copyleft open source licenses from permissive licenses is that they limit how you can redistribute or modify the software. Essentially, any work that redistributes or modifies software licensed under a copyleft license must itself be open-sourced using a copyleft license, which is why you'll sometimes hear them referred to as viral licenses (that's my _non-lawyer_ explanation anyway).\n\nThe most common copyleft license is the GNU General Public License or more commonly [GPL](https://opensource.org/licenses/GPL-3.0), which is most currently at version 3. Using the GPL v3 license, you _can_ redistribute the code but it must remain open source under the same license in most cases. Essentially, no company can come in and use the code in any closed-source, proprietary applications or even open source, but incompatible licenses. For example, GPLv3 licnesed software cannot be used in an Apache project:\n\n> We avoid GPLv3 software because merely linking to it is considered by the GPLv3 authors to create a derivative work.\n> \n> [GPL Compatibility](https://www.apache.org/licenses/GPL-compatibility.html), Apache Software Foundation\n\nThe [GNU Lesser General Public License version 3](https://opensource.org/licenses/LGPL-3.0) or LGPL is a slightly less strict version of the GPL (as the lesser in the name implies). The key difference here is that, if I am a company creating proprietary software, I can rely on an LGPL licensed project as a shared library without needing to open source my software's code.\n\nOftentimes GPL or LGPL licenses will be found in commercial open source projects where the projects may be dual or multi licensed. The free version may be under a GPL license, limiting its use in proprietary software unless the creator wants to commit to also licensing this work as GPL and making the source publicly available. However, under the dual license, the company can purchase a commercial licensed version of the software that does not have this limitation. A common example of this is the many different editions of MySQL, of which the \"Community Edition\" is the GPL licensed version.\n\n## Other Licenses\n\nOf course, there are a lot of other licenses, both open source and not, available than the ones covered here. If you're an individual or company looking to license your software, you don't even need to use one of the preset licenses - you are free to create your own if you like. That arguably might not be the best use of your resources however.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">File “rolling your own open source license” in the same folder as “rolling your own crypto.” Bad ideas.</p>&mdash; Nicholas C. Zakas (@slicknet) <a href=\"https://twitter.com/slicknet/status/900446297710186498\">August 23, 2017</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nOf course, if you have the right legal resources, this may not be an issue for you. There are also sites like the [http://www.binpress.com/license/generator](http://www.binpress.com/license/generator) that offer to generate a license for you based upon a number of configurable options.\n\n## Copy/Pasted Code\n\nBefore ending this article, I'd be remiss if I didn't cover code copy/pasted from online sources. It's a tough area to cover in great detail not just because their is an endless list of potential sources, but also because the nature of the code you copy may be fuzzy (if you copy one line of commonly used code versus copying the source an entire JS library, for example).\n\nIn these cases, it's important to remember that [no license](https://choosealicense.com/no-license/) does not mean that it is public domain.\n\nLet's just look at some common cases.\n\n### StackOverflow\n\nEven those of you who won't admit it have probably copy/pasted code from StackOverflow (aka StackExchange). To the best of my ability to discern, code and content from StackExchange fall under its [terms of service](https://stackexchange.com/legal/terms-of-service) which states that any user created content is licensed under the [Creative Commons Attribution Share Alike](https://stackexchange.com/legal/terms-of-service) (this is also restated in their global page footer).\n\nWhile this license does [require attribution](https://stackoverflow.blog/2009/06/25/attribution-required/), it is typically used for creative content. Essentially, StackExchange does not want other sites reusing content from their site without attribution.\n\nI did find a post by StackExchange explaining that the [code on their site was MIT licensed](https://meta.stackexchange.com/questions/272956/a-new-code-license-the-mit-this-time-with-attribution-required?cb=1) - however, importantly:\n\n> Attribution now continues to be required when you use code found at Stack Overflow and Stack Exchange.\n\nThat being said, when searching for code on the site, I find no mention on the page of this licensing, which is supposed to have been in effect since March of last year. Attribution of a chunk of code easily attributable to StackOverflow can be just a comment with the URL where the code was originally found.\n\n### Books\n\nThe license of code provided in books (whether digital or hard copy) seems to vary based on the publisher. O'Reilly stood out when I investigated this as they directly state that any code provided is available for use without permission or even attribution (though it does, of course, say attribution is appreciated).\n\nIn reviewing other books in my possession, however, most did not specifically state the license of the code contained within. Others contained some form of liability waiver for the code and content, but no direct license or terms (one such publisher's license could, in my non-lawyerly opinion, be read as both a very restrictive license that applied to the code as well as a liability waiver). In some other cases, where the code is separately downloadable, you should follow any license included within that code (if one is provided).\n\n### Blogs and Documentation\n\nIn searching for examples, I found that it is very hit or miss whether any blogs or documentation is ever explicitly licensed - even in the case of documentation for commercial libraries.\n\nIn the case of documentation, one would argue that this code is being shared _with the intent to be reused_, but it's worth checking the license of any code where you are copying a significant portion that is attributable to a specific documentation source. If no license is provided and you have concern, then contact the owner or company for more details.\n\nWhen it comes to blogs, oftentimes the license for the code is contained in relevant linked repository or code snippet sharing tool (for example, public CodePen's are [automatically MIT licensed](https://blog.codepen.io/legal/licensing/)) being used. Otherwise be cautious when copying significant portions of code from a site that does not provide a license for the content and code.\n\n## Learning More\n\nHopefully this article gave you enough of an overview of licenses that you have a basic understanding of what you are getting into when including a third-party resource into your next development project. The goal here is not to become paralyzed with concern about licenses, but just to make sure that you have a solid sense of what you're getting into and, for sure, don't ignore the license before moving forward.\n\nThere are a ton of useful resources available if you want to delve further, some of which I relied heavily upon for this article.\n\n* GitHub's [Choose a License](https://choosealicense.com/) site is great for both project creators or anyone looking for a relatively clear explanation of existing licenses and their restrictions or requirements. A similar but brief summary is provided by GitHub as well in their [Open Source Guide](https://opensource.guide/legal/#which-open-source-license-is-appropriate-for-my-project)\n* Smashing Magazine published [A Short Guide To Open Source Licenses](https://www.smashingmagazine.com/2010/03/a-short-guide-to-open-source-and-similar-licenses/) by Cameron Chapman that covers a short list of open source licenses (including the Creative Commons, which I didn't cover here since it typically is not used for code).\n* Wikipedia offers a [table comparing open source licenses](https://en.wikipedia.org/wiki/Comparison_of_free_and_open-source_software_licenses) that can give you a quick glance over a long list of licenses and requirements.\n* The [tldrlegal](https://eladnava.com/check-your-dependencies-license-requirements-with-tldrlegal/) library aims to give you a quick overview of any licenses within your project's npm dependencies relying on [tldrlegal.com](https://tldrlegal.com/) for simple license explanations.\n\n*Thanks to [TJ VanToll](https://twitter.com/tjvantoll) and [Jeremy Meiss](https://twitter.com/jerdogxda) for reviewing this article for me*"},{"slug":"developing-javascript-2017","category":"blog","title":"Developing JavaScript in 2017 (Recording)","description":"Watch Ray and TJ talk ES6/7 and TypeScript","tags":["web development"],"body":"\nThe other week I held the first event under the banner of [Certified Fresh Events](http://certifiedfreshevents.com/). The event focused on JavaScript and the way the language and JavaScript development are changing. [Raymond Camden](https://www.raymondcamden.com/) first tried to make sense of all the new language features in ES6 and ES7. Next [TJ VanToll](https://twitter.com/tjvantoll) explained what caused him to get over his initial skepticism of TypeScript.<!--more-->\n\nWhat I felt was the most entertaining part of the event was how both speakers shared their personal stories of learning (and even openly admitted to screwing up). I think this helps make the technology more relatable and less intimidating - I can learn specifics from a tutorial or post, but when I see a speaker I want to learn about their experiences more than just _how tos_.\n\nAnyway, if you missed the event, you can still watch it for free via the embedded Crowdcast on the [event's page](https://certifiedfreshevents.com/events/javascript-2017/). This is the best experience to watch the recording as it still includes the chat and poll history as well as the full speaker video (as opposed to just slides). However, if you prefer, these are both available on YouTube (Ray's is [here](https://www.youtube.com/watch?v=U-JKKm_Kl3w&t=94s) and TJ's is [here](https://www.youtube.com/watch?v=d6q5zIu6nGE&t=23s)), though these primarily display the slides with audio (for some reason the speaker video is largely cut off).\n\nIf you like this session, be sure to sign up for my other upcoming events like [Exploring JavaScript Frameworks](https://certifiedfreshevents.com/events/exploring-javascript-frameworks/) with Holly Shinsky presenting Vue.js and Jen Looper presenting Preact. Or [Going Serverless](https://certifiedfreshevents.com/events/going-serverless/) with Burke Holland and James Thomas discussing what a \"serverless\" architecture means in the real world."},{"slug":"enough-with-the-developer-surveys","category":"blog","title":"Enough with the Developer Surveys Already","description":"Tl;dr - the data is of limited value.","tags":["general"],"body":"\nThe developer survey seems to have become a mainstay of technical blogs lately. I don't mean to pick on anyone in particular, but the problem is, almost every one does not pass the eye test. This isn't surprising when you think about it though. There are several problems with these surveys that prevent them from really being representative of the community they want to represent.\n\nThe main issue is that all of these surveys suffer from major [selection bias](https://en.wikipedia.org/wiki/Selection_bias). Even with thousands of responses, the results this likely represents a very small fraction of the overall community.\n\n> Estimates from 2 years ago said there were [18.5 million software developers](http://www.techrepublic.com/blog/european-technology/there-are-185-million-software-developers-in-the-world-but-which-country-has-the-most/) worldwide, including both professional and hobbyists. It's fairly safe to assume that this number has grown. I could not find estimates on JavaScript developers specifically, however. But given it's ubiquity and growth the past few years, I'd guess the number is significant.\n\nA small but substantial response is fine assuming it is representative. However, in most cases these are promoted through means that would only ever be seen by a specific type of developer - one who reads a certain blog, or follows specific individuals on Twitter or finds articles on sites like [EchoJS](http://www.echojs.com/), for example. Even then, it's merely a subset of developers in these outlets who are willing to fill out a survey. While the overall reach of these avenues of promoting your survey might be large, keep in mind that the type of developer who you'll reach is the type that keeps up with the latest trends, who wants to learn about new tools, who wants to stay on the cutting edge.\n\n*This is not the typical developer.*\n\nMaking matters even wore is that I haven't seen any of these surveys include any sort of demographic information. The opinions and habits of the cutting edge JavaScript developer might be useful if I had information about who exactly these people were or how some of this information might break down along various demographics. For instance, how long have they been a developer? How long in JavaScript? Are they employed? Full-time? Part-time? Self-employed? Hobbyist developer? If employed, how big is the company? How many developers at said company?\n\nThis sort of information, especially when we break down answers along certain demographics. At the very least, it would help us gauge how representative the responses are to the community as a whole or help us determine what specific subset of that audience it is representative for. But we should not be fooled into assuming it is widely representative of the developer community.\n\nLook, if you want to run a survey that helps you determine who reads or is a potential reader of your site and what type of topics they are most interested in, this is a very useful tool. They can be fun too (and generate a lot of debate in the comments). But, please, let's not go off presuming too much off the results of any one of these surveys I've seen so far.\n"},{"slug":"evolution-of-web-content-manaagement","category":"blog","title":"The Evolution of Web Content Management","description":"A look at the evolution of web content management from the early days of the web to the headless, cloud-based CMS systems of today.","tags":["web development","Jamstack"],"body":"\nIf we built this city on rock an' roll (and my sources on this are as incontrovertible as Starship and Mannequin 2: On The Move), then we built this web on content. HTML was one of the foundational technologies behind the web from day one and it is essentially a means of formatting documents to be served on the internet. Documents, of course, are of no more value than the content they contain.\n\nToday, we like to talk a lot about building web applications, but content is still the foundation to the majority of the web. Managing that content in the early days was simple, but, since then, the tools we use to create and manage content across the web have evolved to a degree that they have almost come full circle. In this post, I want to look at the evolution of web content management from the early days of the web to the headless, cloud-based CMS systems of today.\n\n## Early Web Content Management\n\nThe early web was static pages. Editing the content required understanding the markup (HTML) and formatting content for display on the web. For simple documents this wasn't too difficult as early HTML was fairly simple (CSS, while it existed, wasn't broadly adopted by browsers until around 2000).\n\nThis simplicity was powerful, however, as it meant that anyone could create and maintain web content with a minimal amount of training. Obviously, as web sites became larger and with more complex designs and user interfaces, this became more complex. Some tools like Dreamweaver started supporting templates to make it easier to add content within repeatable design elements, but this required a whole level of development expertise that the average content creator did not possess.\n\n![Dreamweaver Templates](/images/posts/webcms/dw_templates.gif)<br>\n_Source: [DWFAQ.com](http://www.dwfaq.com/Tutorials/Basics/dwtemplates1.asp)_\n\n## Welcome the CMS\n\nEarly tools like ColdFusion, Active Server Pages, PHP and server side includes arrived in the mid-to-late 90s and with them came the ability to serve dynamic content from a database. Many companies developed proprietary web content management tools, such as AOL reportedly [as early as 1992](https://www.quora.com/When-was-the-first-web-content-management-system-CMS-released). The late 90s saw the release of some of the first content management systems (CMS) appearing on the market.\n\n[Vignette's StoryServer](https://en.wikipedia.org/wiki/Vignette_Corporation), most commonly cited as the first commercial CMS, was released in 1997. The early goals of these tools was twofold:\n\n* Allow the ability of non-technical content creators to create and edit content across large web sites.\n* Create a content workflow that allowed a typical editing and approval process that existed on other publishing platforms.\n\nThose initial goals may seem simple, but the needs of large sites became increasingly complex, with internationalization, complex navigational structures and very specific length and layout requirements for content blocks. Subsequently, these tools became incredibly complex and expensive.\n\n## Rise of Open Source\n\nExpensive, complex and proprietary enterprise CMS systems were not a workable solution for many sites and businesses. At the same time, in the early 2000s, the open source movement was on the rise. This helped drive the development of open source content management solution like Drupal in 2000, Joomla in 2005 and, of course, Wordpress in 2003.\n\nAll of these are still the most widely used solutions today. All three combined make up about 70% of all CMS usage according [current statistics from 2019](](https://w3techs.com/technologies/history_overview/content_management/all)). Wordpress is used by \"33.6% of the top 10 million websites as of April 2019\" and usage appears to be rising.\n\n![CMS usage statistics](/images/posts/webcms/cms_usage.png)<br>\n_Source: [w3techs.com](https://w3techs.com/technologies/overview/content_management/all/)_\n\nThe problem with these tools for some was that they could be difficult to host and maintain for multiple reasons. First, they required servers or hosting that supported the language (PHP for Wordpress, for instance) and the necessary database servers. Like their enterprise CMS counterparts, customization required required developers with a depth of knowledge of both the language and the tooling and tags required to build front-ends specific to the tool. Plus by their sheer popularity, they became a target and, thus, a potential security risk, especially for companies that didn't have the wherewithal to actively patch or secure their installations. Finally, Wordpress in particular has been accused of growing unwieldy and bloated in the long run due to an overwhelming number of plugins.\n\n![Wordpress Plugins Meme](/images/posts/webcms/wp_plugins.jpg)\n\n## Little Fluffy Clouds\n\nThe late 2000s and early 2010s saw the rise of web-based services like Wordpress.com, Squarespace and Wix that essentially enabled companies to move their site hosting to the \"cloud.\" This eliminated the problems of having to build and maintain servers to host and run their CMS implementation but also effectively outsourced the security concerns. Their install was always the latest version and always patched with any security update.\n\n![You all get a cloud](/images/posts/webcms/youallgetacloud.jpg)\n\nThese are good solutions for any number of sites and, in particular, smaller businesses. They provide an easy solution with minimal setup and no real need for development expertise, while still offering a reasonable amount of customization. What they often lack is the ability for anything beyond basic customization that might make them suitable for more complex sites.\n\nThese web based tools did have a big thing in common with their open source brethren and even most enterprise CMS at the time - a tight coupling of the front end of the site with the back end.\n\n## What the Heck is Headless?\n\nThis tight coupling posed a problem in the early 2010s as smart phones were becoming ubiquitous. This necessitated not only new paradigms of web development like responsive web design but also meant that content may be used for both a web site and a mobile app. Over the subsequent decade (almost) we've seen a continuing proliferation of devices that complicate the thinking around where and how our content is being published.\n\nAt the same time, we were beginning to see the rise of services such softw-are-as-a-service (Saas), platform-as-a-service (PaaS), backend-as-a-service (BaaS)...\n\n![Say x as a service one more time](/images/posts/webcms/as_a_service.jpg)\n\nA headless CMS is essentially the back end of a CMS \"as a service.\" It decouples the front-end display of content from the back-end creation and management of that content. Instead of using proprietary tags to create the front-end, a developer would just have to call the headless CMS API.\n\nMost of the popular examples of this are cloud-based services like [Contentful](https://www.contentful.com/), [Forestry](https://forestry.io/), [Sanity](https://www.sanity.io/) and others. However, many enterprise and open-source CMS solutions have also adopted the headless approach. In theory, even Wordpress is capable of functioning this way using its REST API.\n\n## And the Circle is Complete\n\n![the circle is now complete](/images/posts/webcms/circle_complete.gif)\n\nThe early 2010s also saw the start of tools like [Jekyll](https://jekyllrb.com/), [Middleman](https://middlemanapp.com/), [Hugo](https://gohugo.io/) and other so-called \"static site generators\". These tools took markup (often in Markdown combined with templating tools) along with HTML, JavaScript and CSS (often using preprocessors like Sass) and generated a static web site.\n\nOriginally, these tools were adopted largely by developers for things like blogs or, especially when [GitHub Pages added support for Jekyll](https://help.github.com/en/articles/setting-up-a-github-pages-site-with-jekyll), project sites. The tooling was such that it wasn't easy for a non-developer to use these tools since they required comfort with the command-line, editing raw markup and often complicated deployment. There was also limited support for even simple dynamic elements like a contact form without resorting to third-party embeds.\n\nThings started to change with [Netlify](https://www.netlify.com/) and other services that first simplified the deployment process and then built the tooling and services required to turn these \"static sites\" into something far more dynamic - the [JAMStack](https://jamstack.org/).\n\nBut, tie the JAMStack into a headless CMS and you end up with the best of both worlds. You get the comfort simplicity of the old web in terms of content creation - similar to static templates before enterprise CMS systems complicated front-end development - with the comfort of the content editing experience that non-technical content creators and editors need. Plus you get the usual benefits of JAMStack such as improved speed and security.\n\n## What's Next?\n\nThe next step is simplifying the process of developing JAMStack sites that are tied to content sources (a headless CMS, an API, or any of a number of data sources). Some part of this already started with tools like [NetlifyCMS](https://www.netlifycms.org/) - which has a one click deploy of a CMS-backed JAMStack site - and has continued with services like [Stackbit](https://www.stackbit.com/) - which allows you to deploy a site by choosing a static site generator and a headless CMS and deploy it in minutes with just a few clicks.\n\nJAMStack + headless solves the needs of a majority of the web that is still built on content. And the tooling is nearing a point where there are few, if any, logical reasons not to go with a JAMStack + headless CMS solution for much of the web."},{"slug":"ffline-data-pt1","category":"blog","title":"Getting Started with Offline Data in Web Apps Pt. 1","description":"Different options for determining the user's online/offline status and connection speed.","tags":["javascript","web development"],"body":"\nIt is a growing expectation of a modern web app that it should work offline in one manner or another. In fact, offline availability is a key part of a PWA. If your application relies on some form of data, which most do, this can be complicated.\n\nIn this series of posts, I want to take a look at some options for dealing with data offline. A key part of that will be working with things like [localStorage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage) and [IndexedDb](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API). However, an important step to determining whether to use online or offline data is knowing whether your application is currently online or offline. In this first post in the series, I'll look at some very simple web APIs that help you in this regard.\n\n## Navigator.onLine\n\nThe goal of [Navigator.onLine](https://developer.mozilla.org/en-US/docs/Web/API/NavigatorOnLine/onLine) is very basic - it just returns the online status of the browser as `true` or `false`. It pretty much works as advertised.\n\n![navigator.onLine](/images/posts/navigator_online.gif)\n\nThis will work across browsers on mobile and desktop, except Opera.\n\nThere are two ways to utilize this. The first is simply in a conditional like:\n\n```\nif (navigator.onLine) {\n\t\\\\ call my external API for data\n}\n```\n\nThe second way would be to respond to changes in the online status of the user by adding an event listener.\n\n![navigator.onLine](/images/posts/navigator_online2.gif)\n\n## Network Information API\n\nWhile `Navigator.onLine` works well, it doesn't give you any details about the user's connection other than whether it is online or offline. For instance, what if the user's connection is extremely slow? In this case, you might want to rely first on some sort of local data that is refreshed by remote data as it becomes available or, depending on the nature of the remote data, not even bother with the remote call at all.\n\nIn theory, this is what the [Network Information API](https://developer.mozilla.org/en-US/docs/Web/API/Network_Information_API) provides - not just the connection status, but critical details about the connection. What's the problem then? It only works in Chrome (on desktop and Android) and Opera currently.\n\nTo see how this works, I created a [simple jsFiddle](https://jsfiddle.net/remotesynth/axywLu18/16/). If you are on Chrome, open your Chrome Developer Tools to the \"Network\" tab and then change the throttling drop down (which should read \"no throttling\" to a different preset such as \"Fast 3G\", \"Slow 3G\" or set it as \"offline.\"\n\n<script async src=\"//jsfiddle.net/remotesynth/axywLu18/15/embed/js,result/\"></script>\n\nOne interesting thing to note is that, when \"offline\", the connection type in my tests still read \"4G\" but the `rtt` and `downlink` were all zero. This might lead you to ask, what do each of these values even mean?\n\n* `effectiveType` - The type of connection being one of the four values of 'slow-2g', '2g', '3g', or '4g'.\n* `rtt` - This stands for \"round trip time.\" This is the \"time it takes for a packet to go from the sending endpoint to the receiving endpoint and back.\" ([source](https://www.callstats.io/blog/what-is-round-trip-time-and-how-does-it-relate-to-network-latency))\n* `downlink` - This value is an estimate of the bandwidth in megabits per second.\n* `saveData` - This value indicates whether the user has enabled some kind of reduced data usage option.\n\nThe Network Information API could be potentially useful for determining when to rely upon remote data versus local data if it was more broadly adopted.\n\n## Next Steps\n\nIn this post we took a look at tools to determine whether the user's internet connection allows us to reliably get data from a remote source versus local data. In the next post in this series, I'll start to look at some ways to store data locally using localStorage and then, in a subsequent posts, IndexedDb and tools that can help."},{"slug":"from-jekyll-to-astro","category":"blog","title":"Moving from Jekyll to Astro","description":"After many years it's time to move to a new site generator.","tags":["web development"],"body":"\nI started the last iteration of this blog [back in July of 2014](https://remotesynthesis.com/blog/starting-anew/) when I jettisoned my ColdFusion-based blog (and all of the old content) for Jekyll. It's difficult to imagine, but in 2014, Jekyll felt new and fresh. And, to be honest, it still worked but it was showing it's age. For instance, I had not bothered to go through the pain of getting it running locally in years.\n\nNone of this mattered too much since I rarely posted (it's been a year since my last post). With everything that happened last year though – especially around Twitter – I thought it was finally time to make a change. This time, I chose [Astro](https://astro.build).\n\n## Why Astro?\n\nFor the most part, blogs are simple and should be built for simplicity. Astro is one of a number of new frameworks that aims to deliver less JavaScript to the client. There are only a handful of features that a typical blog requires that might need JavaScript (site search perhaps), and a full framework like React feels like overkill for delivering static content.\n\nSpeaking of static, there's very little reason that I can see for rendering most blog content as static. Luckily, Astro also makes that easy.\n\nUltimately, Astro allows me to make this site as simple as it should be while leaving me room to add more complexity if it becomes necessary in the future.\n\n## Making the Transition\n\nThe toughest part of any new site for me is design. I lack any real design skill, so I tend to search for free or paid templates. This can be a real rabbit hole. Ultimately, I decided to move forward with [Astro Ink](https://github.com/one-aalam/astro-ink). There are a number of things about the design that I would like to change, but I chose to no longer allow the design to prevent me from moving forward.\n\nAstro Ink comes ready for a Markdown-based blog, so the next challenge was converting all of my old posts to work with it. I was fortunate in that I had not used the default Jekyll URLs that placed posts in subdirectories by date (i.e. `:year/:month/:day`). All of my posts were under the `/blog` directory with just the slug. However, the files were still named as `:year-:month-:day-this-is-my-slug.md`. So I needed to fix those.\n\nUltimately, I went with a simple Node script to rename all the files, removing the date. Keep in mind that this script actually does not maintain the original, so I used it on a copy of the files.\n\n```javascript\nconst fs = require(\"fs\");\nconst files = fs.readdirSync(__dirname);\n\nfor (const file of files) {\n  if (file.endsWith(\".md\")) {\n    let newName = file.substring(11, file.length);\n    fs.renameSync(\n      __dirname + \"/\" + file,\n      __dirname + \"/renamed\" + \"/\" + newName,\n      (err) => {\n        console.log(err);\n      }\n    );\n  }\n}\n```\n\nNext I had to convert the code coloring. Jekyll had, many years ago, used a code coloring format that looked like this:\n\n```liquid\n{% highlight html %}\n{%raw%}\n{% include banner.html %}\n<ul class=\"ArticleList\">\n  {% for post in site.categories[categoryname] %}\n\t<li>\n        <h4><a href=\"{{ post.url | prepend: site.baseurl }}\">{{ post.title }}</a></h4>\n    </li>\n  {% endfor %}\n</ul>\n{%endraw%}\n{% endhighlight %}\n```\n\nUnfortuantely, I didn't have an easy way to convert these, so this was a manual process. Fortunately, I didn't have a more than a half-dozen or so pages wit code samples formatted in this manner.\n\nThe next step was to fix the frontmatter. The new template required some additional fields, my date formats needed to be updated, and the tagging needed to be cleaned up. Again, this was a manual process and by far the most painful part of the process.\n\nThe final step was converting the data pages for my publications and presentations. Honestly, those pages need to be improved but for now I just converted the YAML to JSON using an online converter and displayed them more or less as they were on the previous site.\n\nOnce these changes were done, getting a static Astro site up on Netlify was a breeze.\n\n## Current Issues\n\nThere were some issues with the template along the way that were relatively easy to fix (for instance the date sort was not set up properly). There are still some issues with the site. Performance of the site is great, but a lot of the issues are accessibility related.\n\n* The color contrast of certain text and links is super low, which is an accessibility issue.\n* Some text does not change color when dark mode is turned on\n* Some buttons need to have accessibility labels added.\n\nThese seem easier to fix than they are as I am digging through the code to find where some of these things are set (it's not as obvious as it should be). If you notice any other issues, please reach out to me (the best way is [via Mastodon](https://mastodon.xyz/@remotesynth))."},{"slug":"front-end-sites-to-follow","category":"blog","title":"Front-End and Mobile Development Sites to Follow","description":"Sites worth following for web developers.","tags":["web development"],"body":"\nI follow hundreds of sites - using RSS! Yes, RSS. Sure, I use Twitter, but Twitter is just a very inconvenient way to do ensure you find quality content. It's like using a metal detector on the beach - maybe you'll find something worthwhile, after you finish sifting through tons of trash.\n\nI spent a little time today finally cleaning up the sites I subscribe to - removing sites that aren't creating new content or have otherwise disappeared (on a side note, it's sad to see some of the people I was a fan of stop writing) and fixing feeds where the feed URL has changed. I figured it'd be worth sharing an export of the sites that I follow in case anyone else wants to follow as well. You can download the [OPML file](/assets/posts/front-end-feeds.xml) here, which should be easy enough to import into any feed reader you use (I use [NewsBlur](http://www.newsblur.com/) fwiw)."},{"slug":"full-stack-developer","category":"blog","title":"There's No Such Thing as a Full Stack Developer","description":"A rant about defining titles with unachievable standards.","tags":["web development"],"body":"\nLanguage matters. Giving something a label and a definition helps to take something abstract and ill-defined in our minds and make it \"real.\" Once this abstract concept becomes \"real,\" it frames the terms of the debate by forcing even those who oppose it to argue within the construct that is defined.\n\n> \"Language matters because whoever controls the words controls the conversation, because whoever controls the conversation controls its outcome, because whoever frames the debate has already won it...\"\n> \n> Erica Jong\n\nLet's take the concept of a \"full stack developer.\" This is a very recent concept but its use has picked up steam lately. There seems to be a constant stream of posts on sites like Hacker Noon or Medium that try to help junior developers or aspiring developers become a \"full stack developer.\" More and more companies are posting jobs looking for \"full stack developers.\"\n\nHowever, I want to argue that simply by creating the term and using it, we've now solidified \"full stack developer\" into a concept that is reframing how we (and especially the employers who'd hire us) look at the skills required to do the job. What was once a preposterous list of requirements for a job that many of us used to mock gets lumped under the term \"full stack developer\"\n\nLet's look at a (by no means comprehensive) list of what are often listed as the \"essential skills to become full stack developer\":\n\n* HTML/CSS including:\n\t* Front-end frameworks like Bootstrap or Foundation\n\t* CSS preprocessors like Sass\n\t* Responsive and/or adaptive design\n* JavaScript including:\n\t* JavaScript frameworks like Angular, React or Vue\n\t* JavaScript toolchains featuring things like TypeScript, Babel and ESLint, npm\n\t* JavaScript testing with tools like Jasmine and Mocha\n* Back-end development, which depending on the needs of the employer, may potentially including:\n\t* PHP\n\t* Node.JS/JavaScript\n\t* Ruby\n\t* Python\n\t* C# or Java\n* Database development including:\n\t* RDBMS like MS SQL\n\t* NoSQL data stores like MongoDB\n\t* In-memory stores like Redis\n* Web application architecture including:\n\t* Leveraging serverless/cloud services for a microservices architecture\n\t* Deployment to various platforms including AWS, Azure, Heroku, etc.\n\nLet's admit that that is an impossible list - even assuming only a minimal level of expertise in some or most of these. I also left out things like understanding web application security, managing version control, configuring a web server that are all essentially assumed skills.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The &quot;full stack&quot; dev is a dying breed. Just keeping up with JS &amp; React ecosystems is a full-time job! Redux, MobX, GraphQL/Apollo/Relay, Jest, Enzyme, Babel, Webpack, ESLint...plus frequent React releases, annual JS versions, and countless npm packages!<a href=\"https://twitter.com/hashtag/javascript?src=hash&amp;ref_src=twsrc%5Etfw\">#javascript</a> <a href=\"https://twitter.com/hashtag/greatproblem?src=hash&amp;ref_src=twsrc%5Etfw\">#greatproblem</a></p>&mdash; Cory House 🏠 (@housecor) <a href=\"https://twitter.com/housecor/status/974700015414382592?ref_src=twsrc%5Etfw\">March 16, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nListed out in a manner such as this makes the requirements of a \"full stack developer\" seem laughable. However, as an employer, I can still _imply_ all of those same requirements under the acceptable term of \"full stack developer.\" Recruiters and other people training developers in the industry are reading things like the \"6 Essential Tips on How to Become a Full Stack Developer\" or \"What the Heck is a Full Stack Developer?\" that attempt to normalize the definition and make it seem more reasonable and palatable.\n\nThe net result is that even if companies don't get everything they want on this list, they've still successfully ratcheted up the requirements for being a successful developer - and made it acceptable to ask for everything in the first place. They've made junior devs and future devs aspire to the qualifications of a supposed \"full stack developer.\"\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">After reading an article on Hacker Noon, I am reminded that I&#39;m not a fan of the term &quot;full stack developer.&quot; I think it gives companies an easy way to unrealistically ask for everything and sets a unachievable standard, especially for junior devs.</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/971074236596084738?ref_src=twsrc%5Etfw\">March 6, 2018</a></blockquote>\n\nIn effect, we have allowed the \"full stack developer\" term to frame the debate. We should not. It is a term that defines something that doesn't exist - cannot exist because it is an impossible standard. We can begin by refusing to use the term ourselves. We can try to cut through the BS being fed to junior devs and aspiring devs so that they don't see the term as an impediment to future success. And we can ask our employers to not use the term - lay out your requirements, rather than hide them under a ridiculous title. If you have a good job at a good company under the \"full stack developer\" title, try to convince them that it would be better to use a clearer title that better reflects the specifics of the role.\n\nHopefully the less we are willing to accept this term, the less we see it used and the more we can regain control over the discussion about what it takes to become a successful developer.\n"},{"slug":"get-started-with-static-site-generators","category":"blog","title":"Get Started with Static Site Generators","description":"A free report on static site development from O'Reilly.","tags":["web development","Jamstack"],"body":"\nIn the early days of the web, there was no such category as \"static sites\" - the web was made up of static resources. This was a maintainable solution when the web was simple. That didn't last long.\n\nStatic sites had enormous limitations that made them an impractical solution for most web sites - even the relatively simple ones.\n\nMore recently, however, a combination of asynchronous content, third-party services and new tools, called static site generators, have made the old skool static site both feasible and cool again. Tools like [Jekyll](http://jekyllrb.com/) are used to run thousands of sites across the web (including this one...though it admittedly deserves more love).\n\nBut what are static site genertors? Which one of the 400 or so of them should you consider using? What types of sites are they most suitable for?\n\nThese are some of the questions I aim to answer in a [*free* report on static site generators for O'Reilly Media](http://www.oreilly.com/web-platform/free/static-site-generators.csp). I know what you are thinking - \"Awesome, just in time for the weekend!\" You're right! Did I mention it is free? Also, I should note that it is free.\n\nHopefully this report will answer any questions you may have about static site generators and help you get started in choosing one.\n\n[![Static Site Generators - Modern Tools for Static Website Development](http://covers.oreillystatic.com/images/0636920040095/cat.gif)](http://www.oreilly.com/web-platform/free/static-site-generators.csp)\n\n[Static Site Generators - Modern Tools for Static Website Development](http://www.oreilly.com/web-platform/free/static-site-generators.csp)\n"},{"slug":"github-pages-https","category":"blog","title":"GitHub Pages Now Support HTTPS - Use It!","description":"GitHub has finally announced HTTPS support.","tags":["general"],"body":"\nToday [GitHub announced](https://blog.github.com/2018-05-01-github-pages-custom-domains-https/) that custom domains will support HTTPS. This is great news!\n\nAs many of you may already know, [GitHub Pages](https://pages.github.com/) was a great (and completely free) way to host static sites. It has built in integration for anyone using [Jekyll](https://jekyllrb.com/) so that it will automatically rebuild your site whenever new code is checked in. However, you could deploy and host any static site, which made it a great solution for things like personal blogs or event sites or project sites.\n\nThe drawback, up until now, was that you could not use HTTPS without the support of something like [CloudFlare](https://www.cloudflare.com/), which offers a free account with a shared SSL cert. This is fine for many projects, but not always suitable. For instance, I hosted some event sites for work on GitHub pages, and you had no way to know with whom you shared the SSL cert (which, for a company, could lead to some embarrassment).\n\nThe only other option was to accept the the dreaded \"Your connection to this site is not secure\" warning. This warning only gets worse if, as [planned for July in Chrome 68](https://techcrunch.com/2018/02/08/chrome-will-soon-mark-all-unencrypted-pages-as-not-secure/), Chrome begins marking pages as \"not secure\" prominently in the address bar.\n\nEven better, GitHub has added the ability to configure your URL to enforce HTTPS, meaning that any visitors to the unsecured version of your domain will be automatically redirected to HTTPS.\n\nIf you want to get started configuring your domain for GitHub Pages, [check the documentation](https://help.github.com/articles/using-a-custom-domain-with-github-pages/) and then walk through the instructions in the [announcement post](https://blog.github.com/2018-05-01-github-pages-custom-domains-https/) to configure SSL or in their [documentation of the feature](https://help.github.com/articles/securing-your-github-pages-site-with-https/)."},{"slug":"goodbye-mobile-dev-weekly","category":"blog","title":"Goodbye Mobile Dev Weekly","description":"It's been a fun run over the past 8 years.","tags":["general"],"body":"\nThis week's issue 383 of [Mobile Dev Weekly](https://mobiledevweekly.com) will be the last. That's nearly 8 years of weekly issues that I've helped put together along with my friend [Holly Schinsky](https://twitter.com/devgirlfl) and the awesome folks at [Cooper Press](https://cooperpress.com/). Obviously, mobile development is more imporant than ever today, so I wanted to take a momentand reflect on what has changed during the 8+ years since I initially proposed the newsletter to Peter Cooper and today.\n\n![Issue 1](/images/posts/issue1.png)\n\nFirst of all, Mobile Dev Weekly actually began its existence as Mobile _Web_ Weekly. 8 years ago, it wasn't at all clear that the web would be a dominant platform on mobile. Obviously, phones had browsers, but mobile apps ruled and most interactions on mobile phones were occuring within apps (that's largely still true today as [recent stats](https://www.emarketer.com/content/the-majority-of-americans-mobile-time-spent-takes-place-in-apps) show that close to 90% of all mobile time is spent within apps).\n\nResponsive web design was relatively new in 2014 (the term having been coined only [in 2010](https://alistapart.com/article/responsive-web-design/)). Probably the most popular use of mobile web technologies in 2014 was tools like PhoneGap. A lot of companies, including the one I worked for at the time, were building mobile app development platforms using PhoneGap, to bring mobile app development to web developers and eliminate the need for specialized teams that developed for iOS and Android independently.\n\nWhile I used and talked about these technologies, I have always felt strongly about the web on mobile. I hoped the newsletter could help bring awareness to content around using the web to build applications for mobile. Today, while apps are still dominant on mobile devices (and tools like PhoneGap have largely faded to the background), I feel that the web is on a stronger footing. It's no longer a fight for relevance, but a fight against corporations that want to neuter modern web platform features on mobile to further their own goals.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">To repeat: the problem isn&#39;t Safari, it&#39;s iOS and App Store policies that have cut off real browser competition at the knees.<br><br>No iOS user is ever allowed better than the lowest-common-denominator web, and that&#39;s *terrible* for developers and users alike. <a href=\"https://t.co/IDYTrfSuZ4\">https://t.co/IDYTrfSuZ4</a></p>&mdash; Alex Russell (@slightlylate) <a href=\"https://twitter.com/slightlylate/status/1385630850373459973?ref_src=twsrc%5Etfw\">April 23, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nWhile the newsletter expanded to cover all mobile development, including native app development, some years ago, I've remained focused on bringing these issues around the mobile web to subscribers. I still believe that, despite attempts to limit it, the web is still the best way to build applications \"cross-platform\", but its future success on devices still isn't guaranteed.\n"},{"slug":"goodbye-telerik-progress","category":"blog","title":"Saying Goodbye to Telerik and Progress","description":"In some personal news, I am moving on to a new role.","tags":["general"],"body":"\nI met [Burke Holland](https://twitter.com/burkeholland) at the first ever O'Reilly Fluent conference in San Francisco. He worked for a Bulgarian company named Telerik and saw me speak at a pre-conference session about Adobe's new open web focus (those were the days). We hit it off quickly - on my part, I invited him to write for the Adobe Developer Connection and he invited me to speak at DevReach in Sofia, Bulgaria (I clearly got the better end of the deal).\n\nIt was at DevReach that I met [Todd Anglin](https://twitter.com/toddanglin), [Brandon Satrom](https://twitter.com/brandonsatrom) and others from the Telerik team. I'd heard of Telerik via Kendo UI, but knew little else previously. I left impressed. Another DevReach speaking opportunity later and I decided I wanted to join the team.\n\nIt's been a bit more than 5 1/2 years and one acquisition by Progress since. However, today it is time to say my goodbyes.\n\nI know everyone says they got to work with great people when they leave their job, but they didn't get to work with the people _I_ worked with. My immediate DevRel team was full of amazing, smart and talented people, some of whom remain and some have since moved on, including [TJ VanToll](https://twitter.com/tjvantoll), [Jen Looper](https://twitter.com/jenlooper), [Rob Lauer](https://twitter.com/RobLauer), [Sebastian Witalec](https://twitter.com/sebawita) and [Tara Manicsic](https://twitter.com/Tzmanics). The same goes for my extended DevRel team including Ed, Sara, Sam, Alyssa, Eric, John and others outside DevRel who I got to work closely with during those years including Dan, Nora, Merrill, Leah, Tejas, Carl and more.\n\nMy last year, I had the opportunity to help lead a team with the marketing and communications department. I was fortunate to have a talented team of writers and just overall good people (thanks Mike, Mark, Danny and Nick). I also got to be part of an extended communications team filled with fantastic colleagues (Erica, Courtney, Danielle, Chris, Nicole, Colleen, Ani, Kim). It has been a great pleasure working with you all.\n\nThese years really have been the defining years of my career so far. I accomplished a lot of things and learned even more. While I am excited about what's next (more on that shortly), it isn't easy letting go of people whom you care about and enjoy working with every day. Thanks for all the opportunities Telerik and Progress!\n\nI have so many great memories but here are some of my favorite memories:\n\n![DevRel team building at Hollywood Studios](/images/posts/adiosprogress/disney.jpg)<br>\nDevRel team building at Hollywood Studios 2017\n\n![TJ VanToll and Eddy Verbruggen at TelerikNEXT](/images/posts/adiosprogress/teleriknext.jpg)<br>\nTJ VanToll and Eddy Verbruggen at TelerikNEXT 2015 in Boston\n\n![DevRel team members in Sofia](/images/posts/adiosprogress/sofia.jpg)<br>\nDinner with colleagues in Sofia, Bulgaria, 2017\n\n![Roaming Sofia with horsehead Burke](/images/posts/adiosprogress/horse.jpg)\nRoaming around Sofia, Bulgaria in a cab with Burke Holland in a horse head in 2013\n\n![DevReach 2018 dinner with speakers and colleagues](/images/posts/adiosprogress/devreach.jpg)\nDinner in Sofia with speakers and colleagues after DevReach 2018\n\n![Dinner with colleagues in Austin 2018](/images/posts/adiosprogress/kinvey.jpg)\nDinner with colleagues after Kinvey team meeting in Austin 2018"},{"slug":"heavyweight","category":"blog","title":"Heavyweight","description":"Learning about yourself through the experience of others.","tags":["general"],"body":"\nI don't usually talk about personal things here, but I will admit that 2016 hit me hard. It's a tough thing to explain as both personally and professionally, nothing terrible happened. Yes, the election was part of it, but it was a feeling I was facing much earlier in the year. It led to me pulling back from writing more publicly and speaking at events (even now, I write this blog but pretty much never promote my own posts).\n\nSuffice it to say, 2016 forced me to face the need to change myself. I am someone who tends to thrive on routine but over time that routine can become a trap from which it is hard to escape. The only way out is through a bit of learning about yourself and learning to defy your own instincts.\n\nAs part of that learning, I have started to explore some resources that are outside of my typical tech blog or news articles that I read on a daily basis. One podcast that I recently came across is called [Heavyweight](https://gimletmedia.com/show/heavyweight/). I've already gone through several episodes and I highly recommend it.\n\nWhat is Heavyweight about? That's a bit tough to explain. It explores people's experiences - their regrets, their anger, why they want what they want, how their behavior impacts others and, probably most of all, the how our ability (or inability) to communicate and see each others perspective can come to almost define a person's life.\n\nYes, it's a bit philosophical, but it also never seems that way. The host, [Jonathan Goldstein](https://twitter.com/@J_Goldstein), simply allows people's experiences to more or less speak for themselves, while also adding necessary detail and backstory in his commentary. Often, the guest (and subject) of the show finds out things about themselves that they didn't know. And yet, the stories being told are engaging. Meanwhile, listening and reflecting on your own behavior, experiences and emotions as it relates to their story can, in my opinion, help you learn a bit about yourself.\n\nAnyway, for the three of you who read this (all bots, I know), sorry to get all overly touchy feely here. That's not typical of me - I told you 2016 hit me hard."},{"slug":"hostile-to-documentation","category":"blog","title":"Hostile to Documentation?","description":"Developers don't like writing documentation.","tags":["general"],"body":"\nI think every developer has had that feeling when they discover a project on GitHub that seems like the answer to the problem they are trying to solve. Unfortunately, many times this project turns out to be either undocumented or minimally documented and the experience ends in frustration.\n\nYesterday I released an article titled \"[Your Open Source Project is Considered Harmful](http://developer.telerik.com/featured/open-source-project-considered-harmful/)\" (fwiw, the title is meant to be cheeky though not everyone took it that way) that discusses the huge abundance of undocumented and poorly documented code on GitHub. The goal of the article is to ask developers to think before they make their code public - and if you are just posting a project that you don't intend to maintain, support or document, make that clear to the end user.\n\nI knew that the topic would be somewhat controversial but I didn't realize the level of hostility and sometimes anger (towards me specifically) it would engender. I want to take a moment to discuss some of the responses.<!--more-->\n\n## It's the User's Problem\n\nMany responses seemed to think that it is the user's responsibility to write documentation if they feel it is needed.\n\n> \"The problem is people using a project, but not contributing to documentation.\"\n>\n> \\- [Comment from The Engineer](http://developer.telerik.com/featured/open-source-project-considered-harmful/#comment-2593324936)\n\nThis seems to relate to a sense of altruism - I created this code for the benefit of you (i.e. the developer community). By asking more of me, you are being ungrateful.\n\n\n> It’s helping people willing to do the work to figure out if the project is useful to them. Sorry if that isn’t you, but the author is under no obligation to appease anyone.\n> \n> \\- [Comment from zeebo](https://lobste.rs/c/oxnhwy)\n\nA similar sentiment was occassionally expressed in a more hostile manner.\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Actually <a href=\"https://twitter.com/Telerik\">@telerik</a>, maybe your attitude and sense of entitlement is harmful <a href=\"https://t.co/B2XhmIwO1C\">https://t.co/B2XhmIwO1C</a></p>&mdash; Imperator Pathogen (@sandfoxthat) <a href=\"https://twitter.com/sandfoxthat/status/714746046346342400\">March 29, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nI do believe that most developers share their code in large part out of a sense of altruism. Sure, in many cases, we wouldn't mind the attention of our peers, but I think the overriding sense is that it is good for the community to share our code. I understand that no one likes to be told that their \"gift\" is unwanted - and, in some respects, that is what I am being perceived to be doing.\n\nWhat I am unclear on here is why a developer with such good intentions wouldn't want to make even a minimal effort to ensure their \"gift\" is well received. I wouldn't give someone a gift and hand them half the bill - but by only writing the code but not the documentation, you've left half the bill unpaid. As I said in the article, this will also help you determine \"why anyone outside of yourself would need it. What problem does it solve? Who is the target audience (ex. what skills are needed to use it)? And even, what do I hope to gain by sharing this and how committed am I to maintaining it for the community?\"\n\nIf the project is a personal project and you don't really intend to maintain it, document it or support it - it seems pretty easy to make that clear in the readme. If the project is purely experimental and not intended for production use, make that clear - even if your plans may change. If a user still decides to use it, they do so well aware of the risks.\n\n## The Risks Are Obvious\n\nMany other commenters seem to believe that the risks of using undocumented code are obvious and, in effect, the user is already well aware of the developer's intention.\n\n> Disagree with the conclusion, the answer is much simpler. As a rule, if the project isn’t documented just assume it probably isn’t suitable for public use and certainly isn’t suitable for production use.\n>\n> \\- [Comment from sdiehl](https://lobste.rs/c/q58sv7)\n\nOthers also make it clear that the onus is on the user - and that since the developer can't know how the user intends to use the code, it's up to the user to document it if they wish, should they choose to use it.\n\n> Many users shared your frustrations, but they’re still users. Their frustrations with the project must be less than whatever frustrations drove them to use someone’s undocumented code. If enough people find this code useful, maybe they’ll consider contributing documentation back to the code base as they figure it out. If the author sees this, they may realize that if people find the undocumented draft project useful, that maybe it’s worth some effort to improve it. Or the author doesn’t care, someone forks the project, and it takes off.\n> \n> There are many paths to useful open-source projects, and they don’t all require the author to spend an inordinate amount of time documenting every feature for a project nobody may ever see. The onus on deciding how to put together your project is still on you, not the authors of every piece of open-source code that might be relevant to your project.\n> \n> \\- [Comment from ericdykstra](https://lobste.rs/c/kfaq2a)\n\nOther say that if you ue a project with little or poor documentation, it's due to a lack of due diligence (and, again, if you want documentation, write it yourself).\n\n> It really is not that hard to instead of just searching for all available projects, talk to some peers and see what mature options are out there, or do the ‘research\" yourself. If it is a good product and there is no documentation, and that’s a problem for you, write some.\n> \n> \\- [Comment from voronoipotato](https://lobste.rs/c/wltdis)\n\nThe issue I have here is that it is not always so cut and dry. I'm going to use two examples from the world of static site generators (because I spend a lot of time with them). Please note, I am not meaning to pick on the authors who dedicated time to these projects - just to give an example of where, I believe, the lack of documentation is not so obvious and, in my opinion, hurts potentially strong projects.\n\nIf you look at [Wintersmith](http://wintersmith.io/) you'll see that there is a good overview and even a getting started guide. However, once you get past the getting started guide, unfortunately, there is little else. I have built projects using Wintersmith and spent a lot of time digging through the code to figure things out. In many cases, I spent far more time than otherwise would have been necessary in order to figure out a simple feature due to the lack of documentation. The thing is, I actually generally like Wintersmith, but the lack of documentatin makes it harder to recommend it.\n\nAnother example is [Metalsmith](http://www.metalsmith.io/). It also has a nice home page. It includes basic installation and configuration documentation for the base project and for most of the plugins I researched. It does not have any form of usage documentation (yes, it has a few sample projects, but these are so incredibly simplistic that they are not very useful).\n\nBoth of these examples are of potentially strong projects that are a) not obviously undocumented and b) hurt by their lack of documentation. A quick perusal of the issues on projects like these show that misunderstandings are common due to a lack of documentation.\n\n## Community Contribution\n\nThis doesn't mean that you, the project owner, need to document absolutely everything, even if you intend your project for public consumption. But I'd argue that you should have at least the basics of installation, configuration and usage that cover at least the primary use cases for your tool. It's ok to rely on the community to expand the docs to meet more use cases or cover deeper topics, but without giving them at least the basics to start with, I can't actually forsee that happening.\n\nAgain, if this project is still in development, is intended primarily for personal use, or is purely experimental - just say so.\n\nI do believe that users should contribute more to documentation. In fact, this is something I have [publicly discussed before](https://www.youtube.com/watch?v=VtFbMhm8z9A). But it starts with us as a community (including OSS developers) **valuing documentation**, and the \"if you want documentation so bad, write it yourself\" attitude that seems pervasive in the comments makes it clear that we don't value documentation. Instead, that potential documentation contributor to your project is off writing their own project and posting it to GitHub.\n\nOffering contributon guidelines specifically for documentation (as [some](https://contribute.jquery.org/documentation/) [projects](https://github.com/angular/angular.js/blob/master/CONTRIBUTING.md#-found-an-issue) [do](https://jekyllrb.com/docs/contributing/#ways-to-contribute)) can both encourage participation and show that you value documentation.\n\n## Overall a Good Discussion\n\nI should be clear, though, that most of the comments on the article were extremely thoughtful and constructive. In fact, I reworded some of my suggestions as they obviously came across more prescriptive and black-and-white than I'd intended. The goal of the post was simply to get people thinking of the importance of documentation and the potential cost to the very community that these projects aim to help simply by not including it. Despite some hurt feelings and angry reactions, hopefully I was able to at least start a conversation.\n\n\n\n"},{"slug":"how-ssgs-work","category":"blog","title":"How Static Site Generators Work","description":"Sure, they seem simple, but are they really?","tags":["content strategy"],"body":"\nAnyone who follows this site knows that I have an unhealthy obsession with static site generators. One of the things that I like about them is the straightforwardness of what they do - take some combination of lightweight markup and templates and compile those into static HTML, CSS and JavaScript.\n\nBut is it really that simple? This is a topic I take a look at in my recent article for CSS Tricks called \"[What Really Makes a Static Site Generator?](https://css-tricks.com/really-makes-static-site-generator/)\" In this article, I dissect a static site generator called Harp to see how it handles the process of serving and compiling the files that make up your finished site. As I note in the article, I chose Harp because it is simple by design (and because I know JavaScript well enough to understand the code).\n\nHopefully some folks find the article useful. I'd love to hear any feedback you may have."},{"slug":"how-to-speak-at-fluent","category":"blog","title":"How to Speak at Fluent","description":"Tips for prospective Fluent Conference speakers.","tags":["conferences"],"body":"\nThere's a [good post by Ben Vinegar](https://medium.com/@bentlegen/three-tips-for-getting-a-talk-accepted-at-fluent-9eff841efc54#.hgqvl4jjd) suggesting tips for getting accepted to speak at [Fluent Conference](http://conferences.oreilly.com/fluent/fl-ca/public/cfp/522). These are all good tips and, as he says, will work for just about any event you want to speak at. It's worth a read.\n\nAs someone who has spoken at every Fluent so far, and someone on the conference committee, I'd add one other important suggestion - **choose a topic where you aren't going to face as much competition**.<!--more-->\n\nThis was a strategy that worked for me even before I joined the committee. Having reviewed proposals the past couple years I can say that whatever the hot framework or library of the moment happens to be will get hundreds of similar proposals. Sure, someone will get picked to talk on that topic, so, if you have a great talk, by all means submit it, but your chances are definitely lower.\n\nIf you take a closer look at the [CFP](http://conferences.oreilly.com/fluent/fl-ca/public/cfp/522), you'll see that it has a long list of topics under the categories of \"core web platform technologies\", \"tools to help build the modern web\" and \"building performant and resilient apps and sites.\"\n\nI am not speaking on behalf of O'Reilly or Fluent here, but, based on my experience with this event, here's my best guesses as to which categories will be _under-represented in proposals_:\n\n- Tools to help build the modern web\n    - People and teams\n        - Collaboration tools\n        - Engineering culture\n        - Building great teams\n- Building performant and resilient apps and sites\n    - Performance matters\n        - Monitoring, measurement, and metrics\n        - Scalability\n        - Automation\n        - Data science and analytics\n    - Modern web essentials\n        - Security\n        - Privacy\n- The expanding web\n    - The web everywhere\n        - Monetization of the web\n\nIf I were submitting (and, for what it's worth, I am not), I'd probably pick a topic among those as at least one of my proposals. Again, this is no guarantee, but it has worked in the past for me and it's more likely to be successful than being one of the 20 proposals on RXJS (to choose a somewhat random example).\n\nBest of luck to any of you who submit!"},{"slug":"hugo-tips-tricks","category":"blog","title":"Quick Tips and Tricks for Hugo Development","description":"A look at some simple but overlooked as well as some advanced techniques for the Hugo static site generator.","tags":["Jamstack","web development"],"body":"\n[Hugo](https://gohugo.io/) is a really powerful static site engine built in Go. I've used it in various projects including using it to build the site for the [events I run](https://cfe.dev/) (which includes my free online monthly meetups). It was pretty basic, as I didn't know at the time where this would all lead. Finally, two years later I am taking the time to properly rebuild the site (though it isn't live yet) and, in the process, am learning a lot of new things about Hugo.\n\nWhile I commend Hugo on documentation that includes a host of usable example templates and code, this post shares some of the things I've learned so far while building this site that expand a bit on what is in the documentation. I should note that there may be better ways to do some of the things I am doing, so, if any of you are Hugo experts, I'd love to hear ideas for improvement.\n\n## Basic Pagination\n\nHugo provides configuration and an object (`.Paginator`) to assist in [pagination](https://gohugo.io/templates/pagination/). The default number of items on a paginated list page is 10, but in my case I only wanted 5. In order to do that, I changed the setting in my `config.yaml`.\n\n```yaml\npaginate: 5\n```\n\nBeneath the list of items on the page there was a list of pages by number, as well as a back and forward button. What I wanted to do was show the navigation if there was more than one page, the back button only if there were previous pages and the forward button only if there were subsequent pages. Finally, the current page would have different styling and not be linked.\n\n```html\n{{ if gt .Paginator.TotalPages 1}}\n  <!-- Pagination -->\n  <nav class=\"pagination\">\n    {{ $paginator := .Paginator }}\n    {{ if .Paginator.HasPrev }}\n    <a href=\"{{ .Paginator.Prev.URL }}\" class=\"pagination__page pagination__icon pagination__page--next\"><i class=\"ui-arrow-left\"></i></a>\n    {{ end }}\n    {{ range .Paginator.Pagers }}\n      {{ if eq .PageNumber $paginator.PageNumber }}\n    <span class=\"pagination__page pagination__page--current\">{{ .PageNumber }}</span>\n      {{ else }}\n    <a href=\"{{ .URL }}\" class=\"pagination__page\">{{ .PageNumber }}</a>\n      {{ end }}\n    {{ end }}\n    {{ if .Paginator.HasNext }}\n    <a href=\"{{ .Paginator.Next.URL }}\" class=\"pagination__page pagination__icon pagination__page--next\"><i class=\"ui-arrow-right\"></i></a>\n    {{ end }}\n  </nav>\n  {{ end }}\n</div>\n```\n\nThe first line of the above code checks if we have more than one total pages. `.Paginator.HasPrev` is used to determine if a previous paginated page exists and `.Paginator.HasNext` if a next page exists. Likewise `.Paginator.Prev` contains the preceding paginated page object and `.Paginator.Next` the next page object. `.Paginator.Pagers` contains all of the paginated pages to iterate through.\n\nOne quirk you may notice is that I set a variable with the paginator. Why? Well, it allows me to compare `.PageNumber` of the paginated page object when iterating to the page number of the current page object to me to properly highlight the current page on the navigation. \n\n## Get Posts by Date\n\nThis is a bit of a quirk related to the type of site I am creating. In my site, there are future events (that are future data, thus I need to use the `--buildFuture` flag when building) and past events that are recorded. This kind of query though could also be useful if you want to get posts within a date range perhaps. The end result was actually quite simple, but I will admit to trying a ton of different attempts to get this to work and failing.\n\nIn the first case, the only future dated posts on my site are events, so I just query for pages with a date greater than `now`. I set this in a variable so that I can check if it is empty and display a message if it is. Otherwise, I just iterate through and display upcoming items.\n\n```html\n{{ $upcoming := where .Site.RegularPages \".Date\" \"ge\" now }}\n{{ if ne (len $upcoming) 0 }}\n\t{{ range $upcoming }}\n\t\t<!-- display upcoming events -->\n\t{{ end }}\n{{ else }}\n\t<p>Shoot! There are no upcoming events</p>\n{{ end }}\n```\nThe query for past events is a little trickier since I need to select only pages in the events section. In this case, I just need to nest my [where functions](https://gohugo.io/functions/where/).\n\n```html\n{ $recorded := where (where .Site.RegularPages \".Date\" \"le\" now) \"Section\" \"events\" }}\n{{ if ne (len $recorded) 0 }}\n\t{{ range $recorded }}\n\t\t<!-- display recorded events -->\n\t{{ end }}\n{{ else }}\n\t<p>Shoot! There are no recorded events</p>\n{{ end }}\n```\n\n## Shortcodes\n\nThis one is pretty simple and well covered in the [documentation](https://gohugo.io/content-management/shortcodes/), but I mention it because it's a feature that can be easily overlooked. Shortcodes are useful for when I want to be able to be able to display something within Markdown generated content that is more complicated than what Markdown can handle. For example, Hugo has some [built-in shortcodes](https://gohugo.io/content-management/shortcodes/#use-hugo-s-built-in-shortcodes) for things like adding Gists, highlighting code or much more.\n\nIn my case, I want to be create a custom shortcode to display a list of the recorded events that I created above. The first thing I do is place the template for this within `/layouts/shortcodes/`. In this case, imagine I named the file `recorded-events.html`. Next I can just call it from within the Markdown of the page.\n\n```html\n{{% recorded-events %}}\n```\n\nShortcodes actually support passing parameters, which makes them much more powerful than what I show here, but I just want to ensure you are aware of the feature.\n\n## Menu Navigation\n\nMaintaining menu navigation can get tricky, which is why Hugo provides a [menu object](https://gohugo.io/templates/menu-templates/) to help you manage it. You can have multiple navigation menus. In my case, I have two defined in `config.yaml`: \"main\" and \"top\". (Yes, I am super creative at naming them!)\n\n```yaml\nmenu: [\"main\", \"top\"]\n```\n\nIf I wanted to, I could define the menus further within the configuration, but, in my case, I wanted to navigation to create a drop down of recorded events. This list would be limited to the most recent ten events, after which it would just link you to the page with the full listing of past events.\n\nIn this case, I relied on defining the navigation within the front matter of each page. For example, here's the relevant front matter from my past April meetup:\n\n```yaml\nmenu:\n  main:\n    parent: \"events\"\n    name: \"April 2019\"\n```\n\nThis says that it is in the main menu, under \"events\" (which is the identifier for the \"Recorded Events\" menu item). Now I just need to iterate through the most recent 10, so I use a sort to sort on the child page object's date descending.\n\n```html\n{{ $currentPage := . }}\n{{ range .Site.Menus.main }}\n    {{ $parentNavURL := .URL }}\n    <li{{ if .HasChildren }} class=\"nav__dropdown\"{{ end }}>\n    <a href=\"{{ .URL }}\">{{ .Name }}</a>\n    {{ if .HasChildren }}\n    <ul class=\"nav__dropdown-menu\">\n        {{ $children := sort .Children \".Page.Date\" \"desc\" }}\n        {{ range first 10 $children }}\n        <li><a href=\"{{ .URL }}\">{{ .Name }}</a></li>\n        {{ end }}\n        {{ if gt .Children 10 }}\n        <li><a href=\"{{ $parentNavURL }}\">More...</a></li>\n        {{ end }}\n    </ul>\n    {{ end }}\n    </li>\n{{ end }}\n```\n\nIn this case, I set a variable `parentNavURL` to the parent's URL (i.e. the \"Recorded Events\" menu item) so that I can create a menu item of \"More...\" to link to the list of all recorded events. I then iterate through only the first 10 and display the \"More...\" link only if there are more than 10 children.\n\nOne side note, I couldn't a way to dynamically add events to the upcoming or recorded menu despite several attempts. Thus, I am now manually swapping these in the navigation.\n\n## Next/Previous Page Navigation\n\nWhen you are viewing a post (or, in my case, event), it might be useful to be able to navigate directly to the next or previous post. Hugo makes this pretty easy via some properties on the page object. Here's the relevant code from my template.\n\n```html\n<!-- Prev / Next Post -->\n<nav class=\"entry-navigation\">\n\t<div class=\"clearfix\">\n\t{{ if ne .PrevInSection  nil }}\n\t<div class=\"entry-navigation--left\">\n\t\t<i class=\"ui-arrow-left\"></i>\n\t\t<span class=\"entry-navigation__label\">Previous Event</span>\n\t\t<div class=\"entry-navigation__link\">\n\t\t{{ with .PrevInSection }}\n\t\t<a href=\"{{.Permalink}}\" rel=\"next\">{{ .Title }}</a>\n\t\t{{ end }}\n\t\t</div>\n\t</div>\n\t{{ end }}\n\t{{ if ne .NextInSection  nil }}\n\t<div class=\"entry-navigation--right\">\n\t\t<span class=\"entry-navigation__label\">Next Event</span>\n\t\t<i class=\"ui-arrow-right\"></i>\n\t\t<div class=\"entry-navigation__link\">\n\t\t{{ with .NextInSection }}\n\t\t<a href=\"{{ .Permalink }}\" rel=\"prev\">{{ .Title }}</a>\n\t\t{{ end }}\n\t\t</div>\n\t</div>\n\t{{ end }}\n\t</div>\n</nav>\n```\n\n`. PrevInSection` gives you the page object for the previous page within the same site section. If it doesn't exist, it will be null (`nil` in the case of Go). The `with .PrevInSection` simply allows me to use the shorthand dot-notation for the object properties (i.e. use `.Permalink` rather than `.PrevInSection.Permalink`).\n\n## Related Posts\n\nHugo has built-in support for [related content](https://gohugo.io/content-management/related/). It includes default configuration for how it determines if an item is related, but, in my case, I had to customize it a bit within `config.yaml`. The key difference was that I relied primarily on the categories property of each page to determine if it was related and I wanted to include newer pages as I would like to recommend the current event, for instance, if you are viewing a related older event.\n\n```yaml\nrelated:\n  threshold: 80\n  includeNewer: true\n  toLower: false\n  indices:\n  - name: categories\n    weight: 100\n  - name: date\n    weight: 10\n```\n\nDisplaying the related pages is pretty simple within my template. In my case, I want to display the top five related pages to the current page.\n\n```html\n{{ $related := .Site.RegularPages.Related . | first 5 }}\n{{ with $related }}\n{{ range . }}\n\t<!-- display related items -->\n{{ end }}\n```\nIn the case of the above code, the `.` after `.Site.RegularPages.Related` is an argument passed to that function (i.e. `Related`) that to the current page object. The `| first 5` is a filter that limits the results. Again, `with $related` just lets me use the shorthand dot-notation within my iteration.\n\n## Display Relative Age\n\nFor my final item (at least, so far), when listing past events in certain locations, I wanted to display the relative age of an event rather than just the date.\n\n```html\n{{ $ageDays := div (sub now.Unix .Date.Unix) 86400 }}\n{{ $ageMonths := div (sub now.Unix .Date.Unix) 2592000 }}\n{{ $ageYears := math.Floor (div $ageMonths 12) }}\n<li class=\"entry__meta-date\">\n{{ if lt $ageDays 0 }}\n\t{{ $ageDays := mul $ageDays -1 }}\n\tIn {{ $ageDays }} {{ cond (eq $ageDays 1) \"day\" \"days\"}}\n{{ else if ge $ageYears 1 }}\n\t{{ $ageYears }} {{ cond (eq $ageYears 1) \"year\" \"years\" }} ago\n{{ else if eq $ageDays 0 }}\n\tToday\n{{ else if lt $ageDays 31 }}\n\t{{ $ageDays }} {{ cond (eq $ageDays 1) \"day\" \"days\"}} ago\n{{ else }}\n\t{{ $ageMonths }} {{ cond (eq $ageMonths 1) \"month\" \"months\" }} ago\n{{ end }}\n</li>\n```\n\nThe gist of this is easy. First I create variables that determine the age in days, months and years of the page. Then, utilizing various function provided by Hugo, I display these. For example, since I have events that are future dated, some of them can come back with a negative age. Thus, if the age in days is less than 0, I multiply (using `mul`) by negative one. I also use `cond` to display either the singular or plural based on the condition.\n\n## More to come...\n\nAs I said, I am not quite done with this site redesign. If I gain any more insights, I'll be sure to share. Hopefully this is useful for some of you researching how to do things in Hugo. If you have any tips or any suggestions on how I could do the above better, let me know."},{"slug":"improving-perceived-performance","category":"blog","title":"Promoting Perceived Performance with Prefetching","description":"A look at two libraries designed to help improve the perceived performance of web apps","tags":["web development"],"body":"\nThere will always be a difference between how your site actually performs versus how people perceive it to be performing. This perceived performance is impacted by any number of factors, some of which you have no control over, from network or connection speed to simply differing user expectations. Actual site performance is something you largely have control over as a developer, but how your site is perceived to be performing by the end user is, for the most part, beyond your control.\n\nThat's why some new projects fascinate me. They attempt to improve that perceived performance by the end user by using different methods to prefetch the content they may load to allow it to load _before_ they want it.\n\nIn this post, I want to take a look at two libraries: [quicklink]() and [instant.page](). Both attempt to utilize the `<link rel=\"prefetch>` feature to load pages. This feature is relatively new and isn't supported across the board, as you can see in the support matrix from [caniuse.com](https://caniuse.com/#feat=link-rel-prefetch).\n\n![prefetch support](/images/posts/prefetch/prefetch-support.png)\n\n> Learn all about `preload`, `prefetch`, `preceonnect` and other types of `<link rel>` tags in [this excellent post by Ivan Akulov](https://3perf.com/blog/link-rels/).\n\n## quicklink\n\n[Quicklink](https://github.com/GoogleChromeLabs/quicklink) is a project from Google Chrome Labs. It is designed to prefetch any links that are in the viewport to speed up subsequent page loads. It does this by relying on two newer browser APIs: [Intersection Observer](https://developer.mozilla.org/en-US/docs/Web/API/Intersection_Observer_API) and [requestIdleCallback](https://developer.mozilla.org/en-US/docs/Web/API/Window/requestIdleCallback).\n\nThese new APIs are not universally supported, meaning that you have to use one or more polyfills (depending on which browsers you need to support), otherwise support is limited to Chrome, Firefox, Edge, Opera, Android Browser, Samsung Internet.\n\nLet's take a quick look at how to use it in a simple web page. The basic example is as simple as calling `quicklink()` after the page loads by either adding a listener for the load event or just putting the `<script>` tag before the closing body tag.\n\n```javascript\nwindow.addEventListener('load', () =>{\n\tquicklink();\n});\n```\n\nYou won't get any notification that the content has loaded, but you should immediately notice some improvement in the load time of links you click.\n\nThere are also a bunch of customization options. By default the library uses XHR to load all the links but you can ask it to use the fetch API and fall back on XHR:\n\n```javascript\nquicklink({ priority: true});\n```\n\nYou can also specify what URLs it should prefetch in case you want to limit how much it attempts to prefetch (which is basically anything within the current viewport). For instance, you can specify an DOM element containing URLs to prefetch.\n\n```javascript\nconst nav = document.getElementById('menu');\nquicklink({ el: nav });\n```\n\nYou can also specify a custom array of URLs to prefetch or even a pattern of URLs to ignore.\n\nIt is important to note that, by default, this only loads content for current origin (i.e. same URL). This is because unless the others have [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) enabled, you'll hit a cross-origin security issue. This is true whether you specify a list of URLs or whether you use fetch or XHR.\n\nTo override this behavior you can specify a list of allowed origins or you can allow all origins.\n\n```javascript\nquicklink({origins: true});\n```\n\nHowever, allowing all can result in a long list of cross-origin scripting errors that you probably want to avoid as seen below (this is testing locally on a simple site I created for the purpose).\n\n![cross origin errors](/images/posts/prefetch/cross-origin-issues.png)\n\nAll in all, the library is easy to use, and even accepting the browser compatibility issues, it can be a very easy progressive enhancement to improve perceived performance on browsers that will support it.\n\n## instant.page\n\n[instant.page](https://instant.page/) takes a different approach to solving the same problem. Rather than load everything in the viewport, it looks at content that the user is in the process of hovering or clicking and then starts prefetching that content. This prevents the issue of preloading too much and instead focuses on preloading only that content the user is likely to click.\n\nThis change in approach also affects the technical implementation. instant.page does not rely on `IntersectionObserver` or `requestIdleCallback` because it only prefetches items based on the `touchStart` or `mouseover` events. However, it does still rely on `<link rel=\"prefetch\">` which is not supported in Safari or Edge at the moment. For this reason, it is designed as a progressive enhancement as well, meaning it will improve the experience where it is supported but not hurt it where it isn't.\n\nUsing instant.page is simply a matter of including it.\n\n```html\n<script src=\"//instant.page/1.2.2\" type=\"module\" integrity=\"sha384-2xV8M5griQmzyiY3CDqh1dn4z3llDVqZDqzjzcY+jCBCk/a5fXJmuZ/40JJAPeoU\"></script>\n```\nThere are fewer configurations for instant.page than quicklink, but there are some. For instance, as with quicklink, external links are not preloaded by default, however adding `data-instant-allow-external-links` to the body tag will automatically attempt to preload links from any URL or you can specify specific URLs by adding a `data-instant` attribute to them. Interestingly, in my local sample this didn't generate cross-origin scripting errors. In the below recording, the only failed load you can see in the network tab is a page that specifically doesn't exist for testing purposes.\n\n![loading external domains](/images/posts/prefetch/prefetch-instantpage-opt.gif)\n\nI think this is just a difference in implementation rather than function as the pages do not load noticeably quicker and similar tests with quicklink also showed up in the network tab in a similar manner but did trigger the console error.\n\nThere are also similar attributes to customize other behavior such as allowing pages with a query string to be prefetched, which they are not by default (as some may trigger an action) or to specify a link specifically not be loaded. \n\n## Does it help?\n\nTesting perceived performance is a difficult task. Exactly how much better the performance seems depends on a large number of factors including the user's connection speed, the site's load times, and more. It can be something that is difficult to measure exactly. My local demo doesn't do the technique justice since everything locally loads quickly and the demo itself was relatively simple - so even on external hosting the perceivable difference might be minimal. The limitation of loading large external sites this way without CORS enabled adds to the difficulty in testing and measuring.\n\nThe Google Chrome Labs team behind quicklink themselves acknowledge this problem. They created a more complex example and found that quicklink could improve page-load performance by up to 4 seconds, as they demonstrate in [this video](https://www.youtube.com/watch?v=rQ75YEbJicw&feature=youtu.be). That would be dramatic, but your mileage may vary.\n\nThat being said, both libraries are remarkably easy to implement and carry few drawbacks that I could identify, so it would seem there is little harm in utilizing them - even a small improvement in the perceived performance by your users could have a big beneficial impact."},{"slug":"interview-aimee-knight","category":"blog","title":"From Ice Skating to Bootcamp to Full Stack Dev - An Interview with Aimee Knight","description":"Aimee Knight shares some of what she's learned on her journey from ice skater to full stack developer","tags":["general"],"body":"\n[![\nImproving Your Apps - Performance and Debugging](/images/posts/Banner_Improving-You-Apps-Debugging.jpg)](https://certifiedfreshevents.com/events/improving-your-apps/)\n\n[Aimee Knight](https://twitter.com/Aimee_Knight) is one of the featured speakers at [Improving Your Apps - Performance and Debugging](https://certifiedfreshevents.com/events/improving-your-apps/) online event that I am running next Wednesday, January 17 at 12pm ET. You can [sign up for free today](https://certifiedfreshevents.com/events/improving-your-apps/).\n\nAimee recently gave a keynote at the Nodevember conference where she gave her, \"It’s not dark magic\" presentation. Just to give you a sense of the reactions:\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Mind blown by <a href=\"https://twitter.com/Aimee_Knight?ref_src=twsrc%5Etfw\">@Aimee_Knight</a>’s day 2 keynote! “It’s not dark magic” <a href=\"https://twitter.com/hashtag/nodevember?src=hash&amp;ref_src=twsrc%5Etfw\">#nodevember</a> <a href=\"https://twitter.com/hashtag/nodevember2017?src=hash&amp;ref_src=twsrc%5Etfw\">#nodevember2017</a> <a href=\"https://twitter.com/hashtag/sketchnotes?src=hash&amp;ref_src=twsrc%5Etfw\">#sketchnotes</a> <a href=\"https://twitter.com/hashtag/visualnotes?src=hash&amp;ref_src=twsrc%5Etfw\">#visualnotes</a> <a href=\"https://t.co/ZLAT52rRTn\">pic.twitter.com/ZLAT52rRTn</a></p>&mdash; David Neal (@reverentgeek) <a href=\"https://twitter.com/reverentgeek/status/935538604838932480?ref_src=twsrc%5Etfw\">November 28, 2017</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nYou can see other glowing reactions [here](https://twitter.com/WebDevJevon/status/935539808889462786) and [here](https://twitter.com/thecodingcouple/status/935538724645036032) for example. Needless to say, this was a presentation I _really wanted to see for myself_, so thankfully she's reprising it for us next week. In the meantime, I had the chance to ask Aimee some questions about her interesting career path and why developers often find CSS so difficult.\n\n> **You have a unique background, coming from figure skating to software engineering? I know you've talked about this before, but can you share a little bit about how you made that journey? Do you think your background as an athlete impacts your approach to your work as a developer and, if so, how?**\n\nComing from a background in collegiate sports I’m highly driven. After my first degree, I spent a lot of time working with developers and in late 2012 my career path began to diverge. When a developer for my employer’s site handed off their CMS to me saying “don’t touch anything outside of this” my fate was sealed. My curiosity, coupled with increasing frustrations from the surmounting code changes we were always needing, led me on a path of no return. I started to stay up really late so I could work on the site while (hopefully) no one was looking. Within a few weeks, I was hooked. My background as a skater definitely impacts my career as a developer. I’d say it’s instilled in me a tremendous amount of energy and grit. \n\n> **At one point you decided to go through a \"boot camp\" for software development. How would you describe the experience? Do you think there are specific challenges that boot camp graduates face that others may not? Alternatively, are there strengths boot camp graduates bring that others may not?**\n\nMy boot camp experience was definitely intense, but I also loved every minute of it. I feel extremely fortunate to have had the opportunity to go. Being that it was six months rather than a few weeks I was able to really immerse myself in the experience which is exactly what I wanted. I think the number one challenge boot camp graduates face currently is finding a job. The market is pretty flooded now with new developers. I still encourage people to attend, but you have to really love programming I think. Our field can be a ton of fun, but it’s also very challenging. A lot of book camp graduates have an immense drive which can set them apart from someone who opted for a traditional university program only because they ‘had’ to chose something. \n\n> **Your [upcoming talk](https://certifiedfreshevents.com/events/improving-your-apps/) is about CSS not being \"dark magic.\" CSS is often a target for developer's disdain and ridicule. Why do you think that is? What do developers tend to find so frustrating about CSS?**\n\nI think there are a few reasons. First is that CSS, like HTML, is a markup language rather than a programming language. That usually means it’s dismissed as something you don’t really need to devote much time to learning which isn’t true. It’s also very different from JavaScript which a lot of people who write CSS are also writing. In JavaScript, global variables are usually a code smell, in CSS they’re usually a good thing. Mastering CSS requires a different type of thinking than writing JavaScript.\n\n> **You seem to spend a lot of time and effort on mentoring. If you were to give one key piece of advice to someone considering starting or switching their career to become a developer, what would it be?**\n\nMy advice is to get comfortable being uncomfortable. I actually have a talk on this... that's how strongly I feel about it being the key to success. For me, some of the hardest obstacles in my journey have been with my self-doubt. If you're aware of that though, you can shift your focus. We are all human and we have a finite amount of mental energy. So, it's important that you spend it wisely! If you can learn to become comfortable with the feeling of not knowing, you're able to focus solely on the challenge at hand and you'll inevitably be able to tackle it that much faster!\nI also encourage juniors to try and find a mentor or programming buddy. If you can find a mentor it's probably the fastest way to progress. Developers who received mentoring were promoted five times more often than those who didn’t. If nothing else, you can try to work on some small open source projects and get mentorship in the form of code reviews there. Your First PR is an excellent resource for finding newbie friendly projects."},{"slug":"interview-tammy-everts","category":"blog","title":"Why Web App Performance Matters and What to Watch Out For - An Interview with Tammy Everts","description":"Tammy Everts talks about what performance metrics matter most to developers.","tags":["general"],"body":"\n[![\nImproving Your Apps - Performance and Debugging](/images/posts/Banner_Improving-You-Apps-Debugging.jpg)](https://certifiedfreshevents.com/events/improving-your-apps/)\n\n[Tammy Everts](https://twitter.com/tameverts) is one of the featured speakers at [Improving Your Apps - Performance and Debugging](https://certifiedfreshevents.com/events/improving-your-apps/) online event that I am running this Wednesday, January 17 at 12pm ET. You can [sign up for free today](https://certifiedfreshevents.com/events/improving-your-apps/).\n\nI've been a fan of Tammy's for years - her writing on the topic of web performance has been important and influential for years. I then had the opportunity to see her speak at an event several years back at Web Unleashed and I remember thinking something like, \"This topic is so important to developers, but these sessions are often at non-developer events.\" I was already involved with the Fluent conference committee, so I suggested to Tammy that she think about submitting to Fluent 2016. Of course, she was a huge hit - so much so that she became a co-chair the conference itself the following year!\n\nThe good news is that developers seem to be paying more attention to the performance of their web apps. The bad news is, it can be hard to know what metrics to pay attention to! I asked Tammy about this.\n\n> **For those who don't already know you, tell us a little bit about yourself? How did your career lead you to focus on web performance?**\n\nI always feel like the first thing I need to tell people is that I’m not a developer or an engineer. For a long time, that made me a bit of an oddity in the performance industry, though actually it’s been more of an advantage than anything else. My background is in studying usability and user experience, which I’ve been doing for twenty years, starting with designing and conducting usability lab studies back in the early days of the web.\n\nAbout nine years ago, I started working in performance and was immediately fascinated by this brand-new (to me, anyway) dimension of UX – page speed – which had previously been ignored by most usability folks. The fact that you could measure the impact of performance on both UX metrics and business KPIs (like cart size, revenue, and user retention) was – and still is – very exciting to me. In the past few years, I’ve done a lot of original research in this area, as well as studying the growing volume of research done by other people and companies. In 2016, I corralled a lot of these findings into a [book for O’Reilly](http://shop.oreilly.com/product/0636920041450.do). I also help curate WPOstats.com, which is a nifty [repository of performance research and case studies](https://wpostats.com/).\n\nI work with Steve Souders and Mark Zeman at [SpeedCurve](https://speedcurve.com/), where we provide synthetic and real user performance monitoring to a huge spectrum of companies – from start-ups to household-name sites like Expedia and BBC. I’m also a chair of [O’Reilly Fluent](https://conferences.oreilly.com/fluent/fl-ca), which has a major focus on web performance.\n\n> **One of the things that developers are often told they should worry about is page bloat. I know this is an issue that you've focused on a lot over the years, but recently you argued that it may not be as important a metric as we're led to believe. Can you briefly summarize why?**\n\nI’ve been writing about page bloat for the past six years, ever since the average web page hit 1 Mb in size. At the time, that seemed incredible, though by today’s standards 1 MB would be considered pretty lean.\n\nLast summer, when the average web page hit 3 MB, I [wrote a post](https://speedcurve.com/blog/web-performance-page-bloat/) that talked about why, if you care about user experience, page size isn't the right metric to track, because metrics like page size and load time aren't reliable indicators of user-perceived performance.\n\nTake Amazon, for example. It's widely considered to be a performance leader, yet it has relatively heavy pages (defining \"heavy\" as 3MB or more) and slow load times (defining \"slow\" as 5 seconds or more). But for Amazon, page size and load time are the wrong metrics to look at. Looking at this performance test for the Amazon home page (which weighs in at just over 5MB), you can see a start render time of 1.4 seconds and a well-populated viewport at 2.5 seconds – despite the fact that the page doesn't fully load till 18.8 seconds.\n\n![Amazon Page Weight](/images/posts/performance.png)\n\nNow, having said all that, I should add that while page size may not be a relevant UX metric, it still matters a lot to users from a bandwidth perspective. You should also care about page bloat in terms of how it affects mobile users, especially mobile-only users who are dealing with bandwidth constraints or data limits. You should care even more if you have users who live in areas with significant connectivity issues. It’s so easy to forget just how poor networks can be in other parts of the world.\n\n> **One of the things that I know I've often struggled with, and I think many other developers do as well, is missing the forest for the trees when it comes to web performance. I wonder if that's partly why page bloat became so important - because it distilled a bunch of issues (JS bloat, CSS bloat, image bloat) into an easy to understand number. I think developers have a tendency to focus on things like the performance of a specific JavaScript function or minor differences in the performance of various libraries and frameworks and overlook much more impactful fixes that may even take less time and effort. This is a long way of asking, do you believe that's true and, if so, what are some of the areas that you'd focus on first and foremost as a developer that can have the most direct impact on their site's performance?**\n\nI think you’ve really hit the crux of it with this question. I talk with developers every day and I feel their pain. I completely see how with today’s massive, complex pages, it’s really hard to know what to focus on. You can’t optimize all the things, so how do you know where to optimize for maximum impact from your users' perspective?\n\nMost performance issues can be lumped under three tags: images, blocking JS and CSS, and third parties.\n\nImages make up the bulk of the average page, and you should definitely make sure you're not serving huge unoptimized images to your users. But this is one of those low-hanging fruit that's relatively easily addressable.\n\nYou should worry more about CSS and JavaScript. If you're serving asynchronous versions of your stylesheets and scripts, these have the potential to block your pages altogether, because they're major CPU hogs. Asynchronous scripts are better than synchronous, but there's an argument for deferring scripts (if you can wrangle it). And if you're not already measuring CPU usage, you should consider starting now.\n\nThird parties are tricky because you don’t have complete control over them. But you do have more control than you might think. For example, you can monitor how they affect your pages over time and use that data to negotiate SLAs with your third-party providers. You don’t need to passively accept poor third-party behavior. That leads me to a really important point…\n\nYou can’t fix what you don’t measure. That saying has become an industry aphorism, because it’s true. You can obsess over libraries and frameworks all day long, but if at the end of the day you don’t know the impact that changes will have on how users perceive your site, you’re just obsessing in the dark. You need to focus on tracking the rendering metrics that matter most for your pages. Then you'll be able to see what UX impact, if any, your optimizations are having. \n\nIf you're doing synthetic testing, then the best metrics to focus on are hero rendering times and Speed Index. If you're doing real user monitoring, then focus on custom metrics that measure the most important visual elements on your pages, such as product images or third-party ads. ([This post](https://speedcurve.com/blog/rendering-metrics/) does a good job of explaining and comparing the different rendering metrics.) \n\n> **You have often discussed how poor website  performance can have a negative impact on a business. The obvious impact would be things like abandoning a purchase, but what are some of the broader ways it can impact a company - even one that doesn't sell direct to consumers online?**\n\nThere are so many ways that performance has been proven to affect businesses: from brand perception and user retention to internal productivity and cost savings. \n\nIn one study I worked on, we had all our participants engage with the same site. Half the participants had a relatively speedy experience, while we artificially throttled the site for the other half. The people who had the slower experience didn't just perceive the site as being slower: they also reported that they considered the content, design, and navigation to be poor. In other words, the site's slowness gave them an overall negative perception of the entire site. \n\nFrom a cost savings perspective, a couple of years ago Wikipedia reported that they deployed new technology that sped up their underlying PHP-based code and ultimately improved load times by about 66%. It also allowed them to radically cut back on new server costs. Netflix saw a 43% decrease in its monthly bandwidth bill after it enabled gzip and reduced payload by more than half. \n\nI could go on and on. One thing I've learned over the years: if you can name a business metric, then you can probably map it to performance in some quantifiable way. I have yet to find a metric that defies mapping.\n\n> **I am excited to see Tammy speak this Wednesday and hopefully you are too. Join us at [Improving Your Apps - Performance and Debugging](https://certifiedfreshevents.com/events/improving-your-apps/)!**"},{"slug":"interview-with-brian-leroux","category":"blog","title":"From Cordova to Bots to Serverless - An Interview with Brian Leroux","description":"Brian Leroux previews his upcoming presentation by discussing why he created arc.codes and why serverless matters.","tags":["general"],"body":"\n[![The Future of Development](/images/posts/Banner_The-Future-Of-Development.jpg)](https://certifiedfreshevents.com/events/future-of-development/)\n\n[Brian Leroux](https://twitter.com/brianleroux) is one of the featured speakers at [The Future of Development](https://certifiedfreshevents.com/events/future-of-development/) online event that I am running next Friday, December 15 at 12pm ET. You can [sign up for free today](https://certifiedfreshevents.com/events/future-of-development/) .\n\nBrian and I crossed paths when we both worked for Adobe - he was helping to lead PhoneGap and Apache Cordova, both of which fell under my areas of focus within my role at the time. A couple years later, we bumped into each other at PhoneGap Day in Salt Lake City and he told me about his new startup focused on bots, but recently he&#39;s gained a lot of attention for creating a tool called arc.codes for building serverless architectures. In this interview, Brian explains this journey and why serverless matter.\n\n> **For those readers who may not know you, tell us a little about yourself and give us an overview of your technology/development background?**\n\nBeen writing code for a long time, but probably the first thing I did that got any significant attention was [wtfjs.com](https://wtfjs.com/) in 2007ish. A few years later, myself and a band of misfits created PhoneGap which was acquired by Adobe in 2011. From there I had the huge privilege of stewarding the opening moments of Apache Cordova. All that mobile work lead me to messaging, bots and -- a bit weirdly -- serverless.&nbsp;\n\n> **What does your the current business you co-founded, Small Wins, focus on? What inspired you to create this business?**\n\nSmall Wins is our operating name which reflects a core belief in incrementalism. Our product is [begin.com](https://begin.com/) which is a tasking app for Slack. Somewhere around 2014 it was becoming clear that mobile had commodified, the winners were clearly Google and Apple and interestingly adoption via mobile apps had stalled. Mobile is still huge but there is no growth anymore. So the big question was: what are people doing with their attention on these devices? The answer is messaging. Slack was just starting to skyrocket in 2015 when my cofounder Ryan and I saw there was a window to shake up productivity if we got to work on messaging apps (sometimes called bots) right away.&nbsp;\n\n> **How did working on bots lead you into the serverless space and to create [arc.codes](https://arc.codes/)?**\n\nYeah this was something I didn&#39;t expect to happen. I avoided it if anything. I was sort of done with the whole developer tooling space after close to a decade driving PhoneGap, PhoneGap/Build and Cordova. Don&#39;t get me wrong I loved it, but I was ready to dive into the consumer productivity and apps space with Ryan. It was around November of 2015. We had a greenfield in front of us. Choosing to build for the cloud is a no brainer. Choosing AWS is easily the lowest risk choice. Bots, real time NLP, conversational UI, and machine learning seemed risky enough! Faced with standing up our initial infrastructure it seemed really obvious that the puck was going towards this whole serverless / functions as a service model. You have to remember startups are risky af. Any edge we can get, anything at all, and we&#39;ll take it. API Gateway had *just* been released that July. I toyed with it a little and realized we could get zero downtime deploys to HTTP endpoints in &hellip; a few seconds. I had never seen anything like it. So we just went for it without much more thought.\n\nAt first, things where awesome but the team was small and we had less than a dozen endpoints. And remember automation tooling was completely non-existent. A thing called JAWS was out there but it wasn&#39;t any better than the Bash scripts we cobbled together. (Later that became Serverless&trade; the well known framework and venture-backed startup.) There was no CloudFormation support. There was no Terraform support. And worse, our method for development was, effectively, shitty scripts and checklists. Inevitably, and unsurprisingly in hindsight, it began to fall apart. We didn&#39;t know what we had deployed where. We had bugs that were nearly impossible to trace, let alone reproduce and fix.\n\nWe had to automate our infrastructure provisioning and deployment because we were getting into deep trouble. We created a manifest format .arc as a nod to other UNIX-y config manifests like .bashrc or .vimrc. Initially the format stood for Amazon Run Commands though today I&#39;d say Architecture Run Commands.\n\nWe automated against the .arc manifest with npm scripts. Things rapidly became predictable. Our cadence improved drastically. Our quality and speed to resolution followed. Other approaches started to get attention and we felt we had a better answer. A lot of frameworks out there are being built with the goal of being a framework. We built .arc to build a product and it shows. It is designed for standing up web and Slack apps rapidly with both staging and production environments pre-baked. Provisioning takes minutes. Deployment is measured in seconds.\n\nSo I don&#39;t believe cloud infrastructure projects make good products and I also believe, quite strongly, that proprietary code that isn&#39;t our core product is a liability not an asset. Open code is faster code. Many eyeballs do make all bugs shallow and it&#39;s a great quality forcing function from a performance and security perspective. Ryan and I debated it a bunch and I kind of couldn&#39;t believe I was going to do this again but it was the best idea for the company so we spoke with the JS Foundation and donated the code and copyright to them to ensure that the code was open source and so was the governance. We announced it in July of 2017 at Node Summit as JSF Architect though colloquially we mostly call it &#39;arc&#39;.\n\n> **To many people, serverless seems like just a buzzword. Why do you think it is important for developers to learn about it? What kind of impact do you think it will have on the future of development?**\n\nIt is a buzzword! The idea of entirely managed infrastructure is obviously not super new but the idea of removing the *server* metaphor is. This is very new and a super powerful evolution on microservices. Systems built this way are anti-fragile in ways I&#39;ve never seen with theoretical infinite availability. Its seriously hard to bring down a system when every endpoint is deployed independently. Deployments, with zero downtime, are measured in seconds which means you get more iterations. More iterations means you get an edge (possibly) finding product/market fit. *You learn faster.* The pricing is also nice. 10 Million executions is $1 a month.\n\nUltimately being faster and more resilient is the part that makes me excited as a developer.\n\nAs to impact, I have no idea but there is a fun thought experiment that this level of managed infrastructure could lead the first solo employee billion dollar startup. I like the ambition in that idea. With legacy techniques a solo employee billion dollar company is most definitely not unattainable.\n\n> **Your presentation says that arc.codes is serverless on &quot;easy mode&quot; - without giving away the whole presentation, can you explain what you mean by that?**\n\nJSF Architect shines in its focus on creating fast iterations. Anyone with an AWS account and a text editor can spin up an endpoint in a few minutes. In another 20 you can have a custom domain name propagated complete with a fully scalable backend. So that&#39;s what we&#39;ll do.\n\n[Sign up for The Future of Development for free!](https://certifiedfreshevents.com/events/future-of-development/)"},{"slug":"is-the-web-in-trouble","category":"blog","title":"Is the Web Really in Trouble?","description":"An overview of the debate over web versus native.","tags":["web development"],"body":"\nThis morning I published a post on the [Telerik Developer Network](http://developer.telerik.com) that asks the question \"[What's Wrong with the Web?](http://developer.telerik.com/featured/whats-wrong-with-the-web/)\"? If you read about web development at all (and apparently you do, since you are reading this), you can't possibly have missed the long list of posts declaring that the web, as we know it, is in serious jeopardy. The main issues are:\n\n* The web is losing the battle to native\n* The web is too slow, largely due to the weight of advertising\n* The web is too slow, largely due to the cruft of too many libraries and frameworks\n* The web is trying to be something it isn't (i.e. native) and adding too many unecessary features\n\nThere may be more, but these are the core debates.\n\nThe thing about all these debates is they are very technical - they are about *how* we build web apps or the underlying technology of the web. None of these debates seems concerned with *what* we are building. As I argue in the conclusion of my [post](http://developer.telerik.com/featured/whats-wrong-with-the-web/), perhaps we're worried about the wrong thing. Perhaps if we focused on building awesome and creative things on the web again, the answer to these problems would work itself out.\n\n**I worry that web developers have become like bureaucrats, too worried the procedure of building web apps, having lost sight of the point of building them in the first place.**\n\nI'd love to hear your thoughts. Please comment on the [post on the Telerik Developer Network](http://developer.telerik.com/featured/whats-wrong-with-the-web/)."},{"slug":"its-ok-not-to-be-right","category":"blog","title":"Developers, It's ok Not to be Right About Everything","description":"Just because we don't solve a problem the same way, doesn't make me wrong.","tags":["general"],"body":"\nLate last week, there was a big todo about a recent presentation by <a href=\"https://twitter.com/ppk\">PPK</a>. Here's the part that seemed to offend some:\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Preach on, <a href=\"https://twitter.com/ppk\">@ppk</a>. Brilliant talk tonight about what went wrong in modern frontend web development. Too many tools, too little thinking. <a href=\"https://t.co/1jxaP97hsq\">pic.twitter.com/1jxaP97hsq</a></p>&mdash; Adrian Holovaty (@adrianholovaty) <a href=\"https://twitter.com/adrianholovaty/status/829777292633194497\">February 9, 2017</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThis seemed to be following a larger theme you'll often find amongst developers along the lines of \"You're not a real developer if...\" It's a tool often used to marginalize groups. Heck, it's something I heard often lobbed at web developers early in my career (at least in that manner, things have changed).\n\nNow, I get that PPK has a larger point to make here about developers' overreliance on tools. It's an argument I tend to agree with. And, as I didn't hear the session, I'll give him the benefit of the doubt that this came off with more nuance than the slide text implies. However, it gets at a larger point to me, which is that, too often, developers can be intolerant of differing points of view.\n\nThink about how many times recently you may have seen a post about why framework X is better than framework Y or why language N is much smarter choice than language Z. Sure, sometimes these are designed for clicks, but we've all worked with that person. I have. In fact, for some time, I _was_ that person.\n\nBut the truth is that our work as developers is ephemeral. Today's code isn't designed to withstand the test of time. I've had code that lived less than a year and other code that managed to last about ten - but probably more of the former than the latter (it can depend on the nature of the code you write). Even that code that lasted ten years wasn't written in stone. It could be improved or rewritten.\n\nI'm not excusing bad code. I'm just saying, get your job done the best that you can and don't get caught up in developer politics or religiosity. If using a tool works for you and your team, by all means, use it. If you and your team think React is the \"coolest framework evar!\" - go for it. That doesn't make using Angular the wrong solution. If your team uses a language that you personally are not a huge fan of, change it (if you can), get over it or leave.\n\nAs a recovering \"_right way to code_\" true believer, I hereby accept the diversity of solutions that developers can choose...but...\n\n> You're not a real developer, if you don't code."},{"slug":"j-in-jamstack","category":"blog","title":"The J in JAMstack Does Not Stand for React (or Angular, Vue, Svelte, etc.)","description":"Correcting what seems to be a common misconceptions about what makes an app JAMstack","tags":["Jamstack"],"body":"\nOnce upon a time, I was asked to present the best static site generators for JavaScript developers. I painstakingly went through each of the available options at the time and then got to the end where I revealed which one I recommended. The answer: none of them. Compared to the other options at the time (Jekyll, Hugo, Middleman), they were slow, less full-featured and lacking in much of an existing ecosystem (or documentation).\n\nThankfully, that is not the case anymore. There are a ton of great options for JavaScript developers including [Gatsby](https://www.gatsbyjs.org/), [Next.js](https://nextjs.org/) and [React Static](https://github.com/react-static/react-static) if you prefer React, [Nuxt](https://nuxtjs.org/), [Gridsome](https://gridsome.org/) and [VuePress](https://vuepress.vuejs.org/) if you prefer Vue, and more recently, [Scully](https://github.com/scullyio/scully) for those who prefer Angular.\n\nThe existence of mature JavaScript-based tools has been part of the growth of the overall usage of static site generators, which are a key ingredient in the JAMstack. However, this seems to be fueling a common misconception that the frameworks themselves are a key part of the JAMstack - that the J in JAMstack is for your JavaScript framework. This is _not_ the case.\n\nIt's important to keep in mind that in 2016 when the term JAMstack first came about, Gatsby was little more than a year into its existence and far from the powerhouse it is today. Next.js came around in 2017; Gridsome in 2018. The point is, JavaScript frameworks were not even a relevant factor in the the term JAMstack. The role of JavaScript as [originally defined](https://web.archive.org/web/20160527203229/http://jamstack.org/) was as follows:\n\n> JavaScript is in charge of any dynamic programming during the request/response cycle and runs entirely on the client.\n\nMy goal here is not to dissuade you from using a JavaScript framework. If you are a JavaScript developer, there are great tools for you if you'd like to use a JavaScript-based static site generator. However, I think it is a mistake if we confuse the term whereby JAMstack becomes synonymous with JavaScript frameworks. I believe one of JAMstack's strengths is the variety of options that are available (though, the variety of choices can also make JAMstack a bit intimidating). The fact that there are enough tools, even among just the widely used ones, for developers with varying programming backgrounds, whether that is JavaScript, Ruby, Go, Python, or others. If you're a developer, it's likely that regardless of what you program in, there is a static site generator that fits into your JAMstack."},{"slug":"jamstack-in-2021","category":"blog","title":"What Is the Jamstack in 2021?","description":"What Jamstack means is evolving. While labels don't help you get your work done, they are also important.","tags":["Jamstack"],"body":"\n2020 was a terrible year for a lot of things but it was a pretty good year for the Jamstack. We not only saw a lot of startups in the Jamstack space getting massive funding, but also big companies jumping in as well. For example, Microsoft launched Azure Static Web Apps and, more recently, Cloudflare launched Cloudflare pages. As I argued in the recent issue of [Jamstacked](https://jamstack.email/), I think we will look back on this year as the year the Jamstack went mainstream.\n\n> On a side note, if you're interested Jamstack, make sure to join me at [TheJam.dev](https://thejam.dev), a Jamstack community conference being held on January 28-29.\n\n## What Does Jamstack Mean in 2021?\n\nThis has also been a year in which the concept of the Jamstack has been evolving. What began as just tools for static sites, was redefined to include dynamic client-side functionality via JavaScript and APIs in 2016, when the term Jamstack was coined. In 2020 we saw the first hints of change in this definition since it was originally defined caused by the rise of hybrid sites that use a combination of SSR (server-side rendering) and static pre-rendering. This hybrid option has been popularized largely by Next.js.\n\nBut are these sites truly Jamstack? I'd argue that, on the one hand, how we define and redefine the Jamstack term doesn't matter at all in practice, while on the other it is actually really important.\n\n## The Background\n\nJavaScript based Jamstack tools like Next.js, RedwoodJS and Nuxt allow developers to define how a route within a site will be generated. For instance, my blog pages could all be purely static, while my home page could be server-side rendered. This was initially only available via hosting on Vercel or a Node-based hosting service, but Netlify has also begun supporting these hybrid SSR/SSG sites via tools like [Next on Netlify](https://www.netlify.com/blog/2020/12/07/announcing-one-click-install-next.js-build-plugin-on-netlify/).\n\nThere has been lively debate within the community about whether these sites are Jamstack or not. As with every debate about the term Jamstack, this is colored by the fact that Netlify largely created and maintains the term. This has become more pronounced as Jamstack has gained popularity and, in particular, as companies have jumped into the ecosystem. For instance, while I'm not privy to any of the internal discussion, I largely suspect this is why Microsoft uses the phrase \"static web app\" rather than Jamstack - because it can be hard to disassociate promoting Jamstack from promoting Netlify. This is no more obvious than with [Vercel's recent funding announcement](https://vercel.com/blog/series-b-40m-to-build-the-next-web), wherein the company went from being a Jamstack promoter to attacking the concept of Jamstack as \"the dogmatism of pure static.\"\n\nThus the debate has gone from whether hybrid SSR/SSG sites were Jamstack to whether they represented what you might call a post-Jamstack concept.\n\n## Labels Are Meaningless\n\nYou may wonder why anyone cares about such an esoteric debate and you'd have a point. The reality for most developers is that these definitions are pointless in the day-to-day work. We aren't paid according to our strict adherence to the concepts of Jamstack, but to get the job done. If the requirements of a site are best served by building it fully SSR, partially SSR or fully static, then that's what we should do. We may have a preference for one type of solution, which may guide us, but it doesn't - it cannot - restrict how we ultimately solve the problem.\n\nThis leads many developers to often see this as a debate about marketing. After all, they say, Jamstack was just a marketing term created by Netlify to popularize a set of tools (static site generators) that, not coincidentally, were how you built sites to run on Netlify.\n\nThat's true but...\n\n## Labels Are Important\n\nLet's go back to 2016 when the term Jamstack was created. Having been an active proponent of static site generators for already some years by that time, it was obvious to me and to others that there was a real perception problem. \"Static sites\", as we called them, were seen as purely a niche solution primarily for developer blogs and developer portfolios (and maybe, to a lesser degree, for documentation). No one would build a serious site with a static site generator, right?\n\nBy defining a new term, one that dropped the problematic use of \"static\", Jamstack helped change the perception of these tools - but it did more than that. It helped define a concept around which we could organize - write Jamstack books, host Jamstack conferences, run Jamstack meetups and so on. Doing so doesn't just require a term, but a term that has understandable meaning and value to the community. Jamstack was clearly defined enough that it accomplished this and, in my opinion, helped drive the use of these tools from a fringe solution in 2016 to a mainstream one as we enter 2021.\n\nWhich is where we get to the problem of how we define Jamstack going forward...\n\n## Jamstack in 2021 is Static-First but not Static-Only\n\nMy one big criticism of Vercel's \"attack\" on the concept of Jamstack is that it didn't offer any clearly defined alternative. We \"don’t care if an application is CSR, SSR, SSG, etc. as long as [our] end-user is delighted\" is exactly the sentiment I shared in the \"labels are meaningless\" section above but it is not a principle or concept we can organize around or evangelize. It only says what it isn't not what it is.\n\nWhich leaves us with the problem of how we define Jamstack going forward. I believe it is fair to say that the concept of Jamstack can evolve to include hybrid sites, though some will disagree. However, the term has to retain a clear definition and understandable meaning if it will continue to have value for all the reasons I defined above. Saying a site is Jamstack just because it uses a static site generator, even if it is an entirely SSR site running on Next makes the definition far too nebulous to me. What's the difference then between that and a plain old React site with SSR (and no Next)? Or really any site because, well, nearly everything on the web nowadays is JavaScript, APIs and Markup (HTML is markup after all)? Going that route, to me, ends up putting us in a position where we are, more or less, just advocating modern web development, with no real organizing principle or architecture.\n\nMy personal definition has room for hybrid solutions, but it is *static first*, by which I mean every route is assumed to be static unless the specific requirements for that route prevent the possibility of a static solution. So this is a site built upon statically generated assets sprinkled with SSR where necessary, not an SSR site sprinkled with static routes. That is not to say there is anything wrong with the alternative, just that it isn't Jamstack - and that's fine, do what works for you. I personally believe that _many_, if not a majority of, sites on the web can work in a static-first hybrid model of Jamstack. I also think adding some sprinkled SSR doesn't overly dilute the value of the term.\n\nSo for 2021, let's start first by dropping the JAM acronym (in my opinion, it creates more confusion than it helps nowadays). It's just Jamstack not JAMstack. It's an architecture or a methodology rather than a \"stack\" of specific tools - so, yeah, the stack part of the name is a bit confusing but it's the name we have. Let's define Jamstack as static-first and not static-only, making room for hybrid solutions. Finally, as a developer, do what you need to do regardless of whether it fits neatly into Jamstack or not - but learn about and apply Jamstack principles wherever you can for the benefit of your project."},{"slug":"jamstack-in-2022","category":"blog","title":"What is the Jamstack in 2022?","description":"Are we at risk of losing sight of what made Jamstack great?","tags":["Jamstack"],"body":"\n2021 was a year of big changes in the Jamstack. [A year ago](https://remotesynthesis.com/blog/jamstack-in-2021), we were struggling a bit with how to define Jamstack in a world that included the ability to use SSR in a Jamstack application. At the time, this was unique to Next.js, but today you'll find this supported in Nuxt.js 3, Gatsby 4 and even Eleventy via the Eleventy Serverless plugin. Not just that, but we've now added in multiple other kinds of rendering such that I wrote an extensive article clarifying the [various types of Jamstack rendering](https://bejamas.io/blog/understanding-rendering-in-the-jamstack/).\n\n2021 also included the release of some new tools that gained a great deal of popularity very quickly and introduced a new concept, the [islands architecture](https://jasonformat.com/islands-architecture/), to the Jamstack. Both [Astro](https://astro.build/), a completely new SSG, and [Slinkity](https://slinkity.dev/), which is built on top of Eleventy, offered the ability to use frameworks like React, but limit JavaScript to only where it is needed.\n\nSo, suffice it to say, Jamstack got more popular but it also arguably got more complicated. We probably came no closer to clarity on what the Jamstack is in 2021. And this has led to some thoughts on how I see Jamstack in 2022.\n\n_If you're into Jamstack, which I'm guessing you are because you are reading this, you'll definitely want to join me (virtually) at [TheJam.dev](https://thejam.dev) on January 26-27. It's 2 days of amazing speakers all about Jamstack and it's completely FREE!_\n\n## Where'd the Simple Go?\n\n> For any technology, the hardest part is not establishing simplicity, but protecting it over time.\n>\n> - Matt Biilmann, CEO of Netlify\n\nI got into Jamstack development – well really static site development – because it felt like a return to simpler days of developing for the web. Sure, SSGs couldn't handle every kind of site, but that was ok because they handled a lot of types of sites. Plus, they were fun and easy to use for many developers in a way that Wordpress or its alternatives were not.\n\nOver time, we added more complexity because we liked building with Jamstack and wanted it to be able to build more sites with it – sites that pure static couldn't handle. In one sense, that's been great. Only a few years ago, it was easy to think of types of sites that couldn't be built with Jamstack. That's no longer true.\n\nBut it also has come with some tradeoffs. Getting started with Jamstack was never incredibly easy given that it isn't prescriptive and there are so many options, but once you got past that, the experience used to be much simpler in my opinion. Today, I feel that the learning curve is becoming much steeper. Plus, the result isn't always better than the alternative, with large JavaScript bundles weighing down the apps performance.\n\nThis has led to \"competition\" (so to speak) appealing to developers on territory that Jamstack used to own. Frameworks like Remix or concepts like [functional web apps](https://cfe.dev/sessions/moar2021-functional-web-apps/) often specifically target Jamstack for its growing complexity. \"Why fight with rendering options and long builds when pure SSR using serverless is easier to build and offers similar performance?\" they argue. Plus, we can run on platforms like Netlify and Vercel just the same.\n\nWhile it's difficult to admit for someone like me who has been a Jamstack advocate, but I think they have a point.\n\n## 2022 is About Rediscovering the Simple\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">One of the quirks of growing older as a developer in my experience is that, while I&#39;ve learned to appreciate complexity in people a lot more, I&#39;ve also learned to appreciate complexity in code a lot less.</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1482032277005742080?ref_src=twsrc%5Etfw\">January 14, 2022</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nI feel like, if the concept of Jamstack is to continue to be valuable in 2022 as differentiated from just plain web development, it needs to rediscover what made it appealing – it needs to bring back the simplicity. The good news is that I do not believe that means going back to plain old static sites using traditional SSGs.\n\nThis is my list of requirements that I think a modern SSG needs to have:\n\n1. A way to call APIs for data at build time.\n2. The ability to modularize my code, whether that be components or partials.\n3. Some tools to make building frontend interactivity easier.\n\nTo me, everything else is a bit superfluous and adds complexity. Is the ability to build and deploy an edge function within my sites application code cool? Heck, yes. Is it a necessary feature in a Jamstack site builder? No.\n\nIt's worth remembering what all this added rendering complexity is actually doing for us and that's just handling the compiling and deployment of our application API. SSR in a Jamstack framework is just deploying parts of your code to serverless functions for you. I could actually already accomplish this to a large degree without the framework depending on the platform that I am deploying my application to. For instance, both Netlify and Cloudflare (and I am sure others) will deploy serverless functions for your API for you automatically if they are placed in a specific folder.\n\nI think we're already seeing some movement in this direction. For example, both Astro and 11ty seem to be geared towards specifically accomplishing the core requirements without the extras (I'm curious if Astro sticks to that given [recent announcements](https://astro.build/blog/the-astro-technology-company/) or moves more in the direction of Next.js). The growing popularity of both tools seems to indicate to me that this has some value and resonance.\n\nBut both tools also emphasize something that can make Jamstack _better_ than other methods in the way we always claimed it was better but [didn't always live up to](https://almanac.httparchive.org/en/2021/jamstack#performance-score). That's because both aim to deliver less JavaScript, meaning that the site they deliver should perform better than a framework-heavy alternative both because most of the content is prerendered and because they don't inlude all the extra baggage of a JavaScript framework whenever it isn't necessary. I'm hopeful that it is a path other tools pursue as well.\n\nThe original goal of Jamstack was to deliver a better experience to end users (faster and more secure) while offering a better experience to developers (easy to build and maintain). Go [check out the original manifesto](http://web.archive.org/web/20160603092304/http://jamstack.org/). Tons of new (and undeniably cool) advances in cloud computing and application development have seemingly led us down a path towards ever increasing complexity.\n\nAll of this complexity added value but complexity also came at a cost. I'm not advocating removing features, and, to be honest, I am still thinking through how this problem can be solved. But I think it can start refocusing on the core tenets of what Jamstack means – it doesn't have to be the solution to every problem but instead a solution that solve a set of particular problems, better. Maybe Jamstack needs to be more opinionated about the experience of building a Jamstack site and about the result. In my view, 2022 could be about rediscovering the simplicity of Jamstack's developer experience and the differentiation of its output or Jamstack could simply blend into web development, not really offering a clear alternative to non-Jamstack options. I personally think the concept still has a ton of value.\n"},{"slug":"jamstack-is-just-branding","category":"blog","title":"Is JAMstack All Branding and Little Substance?","description":"Is the JAMstack just fancy buzzword marketing or is there actual substance behind the term? I share my thoughts.","tags":["Jamstack"],"body":"\nLast week, when asked for to share a contrarian position, Nicole Sullivan posted something that drew a lot of people's attention:\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">JAMStack is 99.9% branding and .1% substance. 😳😆 <a href=\"https://t.co/nxoEVQ43oE\">https://t.co/nxoEVQ43oE</a></p>&mdash; Nicole Sullivan (@stubbornella) <a href=\"https://twitter.com/stubbornella/status/1226365361722773508?ref_src=twsrc%5Etfw\">February 9, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nNeedless to say, the people who love to hate JAMstack loved it and the rest of us (who love to love JAMstack I suppose) were more than a bit put off.\n\nThe thing is, Nicole is not wrong. The JAMstack term was, in fact, all about branding. It was created by the folks at Netlify in 2016 as a way of rebranding what, until then, we'd called \"static sites.\" We've seen enough of this kind of rebranding before in the developer ecosystem to be skeptical - such as when Netscape famously changed the name of LiveScript to JavaScript in order to capitalize on branding opportunities with Sun's Java despite the lack of any real-world connection between the two. But, I'd argue that in the case of static sites to JAMstack, the goal wasn't to manipulate developers with empty marketing jargon, but to make the name _more_ appropriate to the solution.\n\n## What's Wrong with Static Sites?\n\nWe still call tools like Hugo or Gatsby static site generators, so why would the end result of the process not be a \"static site\"?\n\nThe truth is that for a long time, they were by and large _static sites_. When I wrote my Static Site Generators report for O'Reilly back in 2015, I listed 3 criteria for determining if your site was a good candidate for being a static site:\n\n1. Focus on Delivering Content - static site generators at the time were heavily focused on creating and delivering long form content (usually written in Markdown) and that's what they were optimized for.\n2. Low Degree of User Interactivity - sure APIs existed at the time, but adding something like a login or a shopping cart to a static site was complex and, largely, the services to support that didn't yet exist or were in their infancy.\n3. Update Infrequently - building and deploying these sites was cumbersome and slow. Services like Netlify were new, so a the time most were deployed via FTP.\n\nAs you can see, these do not apply in any way to the modern JAMstack. That's because static sites described only an end result (static files) and JAMstack is about a way of building sites that, while deployed as static files, are far, far from static, either in the build process or in the end result.\n\n## Why People Love to Hate the Name JAMstack\n\nFirst of all, developers love to hate so-called buzzwords even as we proliferate their existence. Think about the fact that you can't use the term serverless without addressing the complaint that there are servers involved (do you know a developer who is unaware that serverless code runs on actual server somewhere?). We talk about IoT, VR/AR (or even XR), DevOps, DesignOps, continuous deployment...the list goes on. For a group that professes to hate buzzwords, we sure do love to use them. And for all our complaints, no one typically has a better, non-buzzword name for things anyway. (Even if they did, wouldn't that thereby be the new buzzword in the end?)\n\nSo part of it is generic buzzword hate. The other part is based on a legitimate complaint: JavaScript, APIs and markup (the JAM in JAMstack) can describe pretty much every site on the web. Overly generic sounding buzzwords immediately set off most developer's BS detector.\n\nMy answer is twofold:\n\n1. Despite the acronym, JAMstack is more about [how you build your site](https://remotesynthesis.com/blog/m-is-for-markup) not the ingredients of it. Or, as Divya said in her post [What makes a site JAMstack?](https://dev.to/shortdiv/what-makes-a-site-jamstack-ib1):\n\t> The JAMstack is a methodology rather than an outcome. You could say that a JAMstack site is a static site but a static site is not necessarily a JAMstack one.\n2. I don't have a better name suggestion. I didn't back in 2016 when Netlify first shared the name with me, and I still don't. Do you?\n\n## Is there Substance to the JAMstack?\n\nUp to this point, we've covered why a rebranding was necessary for \"static sites\" and some of the issues people have with the JAMstack name, but back to Nicole's original case that there is no substance to it. Three (or so) years ago, you could make the case since the reality of static sites hadn't changed with the move to JAMstack, even if the rebrand was necessary to counteract people's misconceptions. However, so much has happened in those three years and so much new ecosystem exists around the architecture, that I do not agree that the name is just marketing.\n\nToday's JAMstack ecosystem isn't just about static site generators mixed with some serverless functions and API calls. There are companies and tools built specifically for addressing this architecture, from adding registration/authentication, to enabling ecommerce and shopping carts, to allowing inline creating/editing of content for non-technical content creators. So much has changed in those few years that, in looking to update our O'Reilly book \"Working with Static Sites\", Ray and I determined it would be basically a complete rewrite.\n\nYes, JAMstack still sounds perhaps too vague and all-encompassing. It's an imperfect term that can be justifiably called marketing, but it still describes something important that should not be dismissed."},{"slug":"jamstack-with-stackbit","category":"blog","title":"Building and Deploying a JAMStack site with Stackbit","description":"A quick introduction to using the Stackbit service for creating a content-managed JAMStack site","tags":["Jamstack","web development"],"body":"\nIn recent weeks, I've discussed how to [start a new site from scratch with Netlify CMS](https://dev.to/remotesynth/a-fresh-look-at-netlify-cms-part-1-136k) and how to [modify an existing site to use Netlify CMS](https://dev.to/remotesynth/a-fresh-look-at-netlify-cms-part-2-5694). However, the tooling around JAMStack also continues to improve to where there are tools that are being created to further simplify the process of developing a content managed JAMStack site.\n\nIn this post I want to take a look at one of those tools that is currently in an early beta release called [Stackbit](https://www.stackbit.com/). As we'll see, the benefit of Stackbit is that you can choose a template and deploy a JAMStack site with CMS integration and deploy this to Netlify, all without touching a single configuration file or writing a single line of code.\n\n> Note that I was given access to Stackbit as a beta user, but I am not in any way affiliated with the company nor have I been asked for an endorsement of any sort.\n\n\n## Getting Started with Stackbit\n\nTo start off, you'll need to request a [beta invite](https://www.stackbit.com/beta/) to Stackbit. Once you have that, here's how you get started.\n\nOnce you have an account and log in, you'll want to create a new project.\n\n![create a new project](/images/posts/stackbit/new-project.png)\n\nYou'll want to give it a name or stick with a default and then select a theme. There are a handful of nice, simple themes available in the beta and they each include a live preview. Using a custom theme is an option, but, at the moment, you'll need an additional beta invite to use this feature (however, since this is all deployed to GitHub, you can do whatever with the deployed code after the project is created, including customizing the theme). It's also important to note that you cannot change themes once your project is created.\n\n![choosing a theme](/images/posts/stackbit/choose-theme.png)\n\nNext, you choose which generator you would like to use to build the site. Currently Stackbit supports three of the most popular engines: [Jekyll](https://jekyllrb.com/), [Gatsby](https://www.gatsbyjs.org/) and [Hugo](https://gohugo.io/). Vuepress and Hexo support is coming soon.\n\n![choose an engine](/images/posts/stackbit/choose-generator.png)\n\nThe final choice is a your backend CMS. Once again, Stackbit offers support for the most popular options such as [Forestry](https://forestry.io/), [Netlify CMS](https://www.netlifycms.org/) and [Contentful](https://www.contentful.com/). Forestry and Contentful are commercial options that may incur additional costs depending on your requirements. Netlify CMS is free but may not be as full featured as you require depending on your site (for example, Contentful has an API that would allow you to reuse the content on a mobile app). [Prismic](https://prismic.io/) support is coming soon. You can also choose to have no backend if you prefer.\n\n![choose a backend](/images/posts/stackbit/choose-backend.png)\n\nOnce you've made all the choices, all you need to do is connect the relevant accounts. You'll need to connect Github and Netlify at a minimum, although, if using one of the other CMS services, you'll need to connect those as well.\n\n![connecting accounts](/images/posts/stackbit/connect-accounts.png)\n\nThe site is automatically created, pushed to GitHub, connected to and deployed to Netlify. If you're using Netlify CMS, it will automatically invite you to be an editor.\n\n![going live](/images/posts/stackbit/deploying.png)\n\n## Next Steps\n\nCongrats, you deployed a fully content-managed JAMStack site!\n\n![deployed](/images/posts/stackbit/deployed.png)\n\nAt this point, from the Stackbit admin, you can go to the CMS admin or the site, but not much else (other than delete the site on Stackbit, which, I should note, doesn't delete the site on Github or Netlify). However, as I mentioned before, you are free to pull the code from GitHub and customize to your heart's content.\n\nIt's still early for Stackbit but it definitely shows some promise as an option for quickly getting a content-managed JAMStack site up and running. I'm looking forward to seeing how they continue to evolve the tool."},{"slug":"javascript-const","category":"blog","title":"Confused by JavaScript's const? Me too!","description":"Constants in JavaScript don't necessarily behave the way you think they would.","tags":["javascript","web development"],"body":"\nThe other day I had a little back and forth on Twitter around the concept of `const` in JavaScript. Kyle Simpson had pointed out a misunderstanding around `const` within an article I'd shared. My sentiment was, more or less, that I can understand where the confusion comes from since it often feels that `const` doesn't behave the way I'd _expect_ it to (note, I'm not saying it is wrong, just different from my expectation).\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Hmm... I missed this issue when I read this article. But if he (and many others) misunderstands &#39;const&#39;, could it be partly because &#39;const&#39; frequently doesn&#39;t behave the way you think it would.</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1138084777674924034?ref_src=twsrc%5Etfw\">June 10, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nEven in that brief conversation, a lot of terminology and concepts were thrown around. So I thought, let me dig into this a bit so I can better understand the concept of constants and the ways in which a variable declared with `const` actually works in JavaScript.\n\n> I should note that Kyle Simpson did write a post on this very topic, but it appears to be on a blog that is no longer live. He did share the [version available via the Wayback Machine](https://web.archive.org/web/20151113135159/http://blog.getify.com/constantly-confusing-const). It's worth a read as he goes into far more depth than I plan to.\n\n## What is a Constant?\n\nIf you Google \"What is a constant in programming?\", you'll find numerous pages that generally define a constant in the way it is defined on [Wikipedia](https://en.wikipedia.org/wiki/Constant_(computer_programming)) as a \"value that cannot be altered by the program during normal execution.\"\n\nOn the surface, this seems rather simple - set a value and it cannot be changed. This can be useful for both readability and error checking. However, not all languages have constants, and those that do don't always handle them the same. For example, in some languages the types of values a constant can hold are limited.\n\nIt's once you get beyond the simple value types where things can get confusing. This is important to the conversation here (and where a lot of my own confusion around the expectation versus the reality of constants in JavaScript comes in). Rather than try to explain, I'll give an example.\n\nLet's say I set a constant like so:\n\n```javascript\nconst NAME = \"Brian\";\n```\n\nIt seems obvious that trying to assign any new value to `NAME` will result in an error - and it does. But what if I did the following:\n\n```javascript\nconst ME = {name:'Brian'};\n```\n\nIf I change the value of `ME.name`, should I get an error? One could argue that technically, I am not changing the value of `ME` since it is still pointing at that same object, even though that object has been mutated. To be clear, in JavaScript, this will _not_ give you an error.\n\n![changing the value of an object constant](/images/posts/const_object.png)\n\nIt's at this point that computer science folks will get into the concepts of primitives and immutability. We'll talk a bit about these but, for the sake of not turning this into a chapter in a computer science book, I'm not going to cover them in great depth.\n\n> In brief, an immutable object is an object whose state cannot be modified after it is created. A primitive in JavaScript is \"data that is not an object and has no methods.\" (source: [MDN](https://developer.mozilla.org/en-US/docs/Glossary/Primitive))\n\n## Constants in JavaScript\n\nThe `const` keyword was added to JavaScript in ES6 (aka ES2015). Previously, the common convention was to use a standard variable but with an all-caps name like `MY_CONSTANT`. This didn’t effect whether the variable could be changed - it was more a hint to tell developers that it shouldn’t be changed.\n\nJavaScript constants declared with `const` can either be global scoped or block scoped. If they are within a block (i.e. between `{` and `}`) they are automatically block scoped. If they are not within a block, they are global scoped, but, unlike variables declared with `var`, do not become properties of the window object. Basically, the scope of a `const`-declared variable is always the innermost enclosing block. In case of a script, it is the global scope or, in case of a module, it is the scope of that module. (Hat tip to [Axel](https://twitter.com/rauschma) for the clarification.)\n\nAnother interesting difference between `const` and `var` is that they are [hoisted](https://developer.mozilla.org/en-US/docs/Glossary/Hoisting) differently. When you declare a variable using `const` or `let`, the declaration is hoisted, but its value is not initialized as `undefined`, thus you will get a reference error if you try to access it prior to the declaration. As you can see below, the first `console.log` referencing a variable defined with `var` returns `undefined` but the second using `const` generates an error.\n\n![temporal dead zone](/images/posts/reference_error.png)\n\nThis is referred to as the [temporal dead zone](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/let#Temporal_dead_zone), which makes it sound much more ominous than it is.\n\nThe final important thing to note about `const` in JavaScript is, as discussed earlier:\n\n> The const *declaration* creates a read-only reference to a value. It does *not* mean the value it holds is immutable, just that the variable identifier cannot be reassigned. ([source](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/const))\n\nAgain, this is where the confusion around `const` seems to emanate from. If you are using `const` with [JavaScript primitive types](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Primitive_values) (i.e. boolean, number, string, etc.), it'll behave the way you might expect (any reassignment generates an error). But, when using `const` with [JavaScript objects](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Objects) (including arrays, functions, etc.), that object is still mutable, meaning properties of that object can still be changed.\n\nFor a more detailed look at scoping around `let` and `const`, there is a whole chapter in \"[JavaScript for Impatient Programmers](https://exploringjs.com/impatient-js/ch_variables-assignment.html#const)\" on `let` and `const` by Axel Rauschmayer.\n\n## Should You Use Const?\n\nThis is a tough question to answer, especially because `let` has the same benefits of block scoping and hoisting (and I cite the latter as a potential benefit since the way `var` is hoisted could lead to unusual errors whereby a variable is inadvertently accessed before it is declared). The people who tout the benefits of `const` then typically focus on code readability. By using `const`, you have indicated that this specific variable should not change, and it will enforce that to a certain degree.\n\nThe argument for `const`'s readability, though, is a bit undercut by the fact that people seem to regularly misunderstand it, as we noted at the start of this article. Yes, there are some protections against reassigning this variable, but, to quote [Kyle's article](https://web.archive.org/web/20151113135159/http://blog.getify.com/constantly-confusing-const):\n\n> Actually, many developers assert this protection keeps you from having some unsuspecting developer accidentally change a `const`. Except, in reality, I think the likelihood is that a developer who needs to change a variable and gets a const-thrown error about it will probably just change the `const` to `let` and go on about their business.\n\nSo, if the protections `const` provides are minimal, it simply becomes a matter of style preference, particularly when choosing between `let` and `const`. If your variable will hold a primitive value that is not intended to be changed, sure, using `const` is a reasonable choice. However, recognize that if the value is something other than a primitive value, using `const` could potentially be more confusing, from a readability perspective, than helpful.\n"},{"slug":"jekyll-versus-competition","category":"blog","title":"Jekyll Versus the Competition","description":"How does Jekyll stack up to other generators? I share my thoughts.","tags":["web development","Jamstack"],"body":"\nOn Saturday, May 2, the first ever [JekyllConf](http://jekyllconf.com) was held online and featured some really prominent speakers including Tom Preston-Werner and Brandon Mathis. I had the honor of opening the event with my session comparing Jekyll to other popular static site engine options including [Harp](http://harpjs.com), [Hexo](http://hexo.io/), [Wintersmith](http://wintersmith.io/), [Hugo](http://gohugo.io/) and [Middleman](https://middlemanapp.com/).\n\nIn summary (and in my personal opinion of course), Jekyll is still in the strongest position of all the engines. It has the strongest community (partly evidenced by JekyllConf itself), the best documentation (not saying it couldn't be better, but it's better than the alternatives) and has the largest selection of pre-built templates and plugins.\n\nHowever, it has failed to reach much beyond hardcore developers. This is partly because of the nature of the tool - for instance, few people outside of the developer community enjoy working on the command line...in fact, most find it intimidating. Tooling for authors is weak too - Markdown is a terrible option for authors (who aren't developers). We think of it as being so simple and easy, but that's actually what makes it so complex. In terms of authoring, it covers a majority of use cases, but it is still very common to encounter requirements that it doesn't meet (intentionally, since it's goal was simplicity). Thus, when you teach an author Markdown, you need to teach them the syntax, what it doesn't cover and  HTML to handle those scenarios it doesn't cover. This is actually more complicated than simply teaching them HTML.\n\nIn my opinion, until the tooling is available to allow authors and contributors to write using the tooling they love, static site engines will remain a niche solution. This is a shame as they actually seem like the optimal solution for content focused sites and, perhaps more so, documentation sites. The good news is that there are people working on the tools needed to bridge this gap...we'll see how this goes!\n\nYou can see the full session recording below or view the [full recording of the day here](https://www.youtube.com/watch?v=X5sJIL-nOhg&feature=youtu.be&t=9m32s).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vT7DhK5zbv0?list=PLrxYIq_0LFJcXlsRZD-JCdITfZexwvqsQ\" frameborder=\"0\" allowfullscreen></iframe>"},{"slug":"joining-stackbit","category":"blog","title":"Why I am Excited to Join Stackbit!","description":"Excited to share my new role as a Developer Advocate at Stackbit!","tags":["general"],"body":"\nI have been passionate about what we now call the [JAMStack](https://jamstack.org/) since about 2014 - back then it was more like the MStack to be honest. I started out building sites with Jekyll and then Hugo and then tried out a long list of other similar tools. The benefits for sites were obvious - faster and more secure pages being the biggest.\n\nDevelopers have, by and large, also bought into these technologies. Tools like Netlify have eased the burden of building and deploying them, plus added a ton of missing features (like forms and serverless functions). Developers are also comfortable doing things like working on the command line, editing data files in formats in things like YAML or JSON or working with Markdown. Everyone else...not so much!\n\nWhat's been missing in the JAMStack ecosystem are the tools that make it easy to give our content creators, editors and other non-technical users an environment they feel comfortable in to create and edit content on a JAMStack site. That means connecting the site with data sources like a headless CMS and then making the process of editing and updating the site transparent for anyone who doesn't necessarily understand the complexities of how the site is built and deployed.\n\nWhat excites me about [Stackbit](https://www.stackbit.com/) is that they are working on briding those missing pieces in the ecosystem. Already they have a system that makes it easy to build and deploy sites connected to a variety of content sources (Contentful, Sanity, Forestry, or even Netlify CMS). The tooling Stackbit are working on will help bring the JAMStack ecosystem to a place where editing a site feels as easy as, for example, working in Wordpress, but with all the added benefits the JAMStack offers.\n\nThat's why I am excited to share that I am joining Stackbit as their developer advocate helping to share what Stackbit can do for developers and bring your feedback back to them. If you have tried Stackbit or would like to give it a try (it's free afterall) and want to share your experience with me, please feel free to reach out."},{"slug":"kinvey-anonymous-data","category":"blog","title":"Getting Started with Kinvey mBaaS - Pulling Data Anonymously","description":"The very first step to getting started with the Kinvey mBaaS","tags":["kinvey"],"body":"\nIn my new role at work I'm going to be focusing on [Kinvey](https://www.kinvey.com/). Much of this is as new to me right now as it may be to you as well, so I invite you to join me in this series of posts (of which this is the first) where I'll be experimenting and learning Kinvey (along with some other technologies).\n\nFor those of you who haven't heard of Kinvey, it is an [mBaaS](https://en.wikipedia.org/wiki/Mobile_backend_as_a_service) but has a ton of features over and above your typical mBaaS. Nonetheless, one of the first things you'd typically want to do is just pull some data from the data store. In this post, I'll explore how this works in Kinvey and how you might implement this in a simple JavaScript application.\n\n## Getting Set Up\n\nTo get started, I created a new app in the Kinvey console. Since I am going to try to pull data, I created a collection. Collections can either use the Kinvey data store or a data service that can connect to any number of sources (REST, Salesforce, SQL Server, etc.). For the sake of this demo, I just used the Kinvey Datastore.\n\n![choosing the Kinvey data store](/images/posts/datastore.jpg)\n\nFor anyone familiar with NoSQL datam stores, the Kinvey data store should look familiar (it's just MongoDB in the background).\n\n![My sample data](/images/posts/data.jpg)\n\n> As someone mildly obsessed with The Legend of Zelda: Breath of the Wild and also as a completionist, I decided to try to build an app that lists all the shrines in Zelda, where to find them and (eventually) allows me to check them off. If you aren't a Zelda fan, the important thing for the sake of this post is simply that I have pre-populated the data in a collection so that I have something to pull.\n\nOnce the data was set, it's time to pull it down.\n\n## Getting Data with the JavaScript (aka HTML5) SDK\n\nFor this simple example, I just pulled the data into straight JavaScript and HTML. To do this, I used Kinvey's [HTML5 SDK](https://devcenter.kinvey.com/html5/downloads).\n\n> A note about SDKs: While Kinvey offers a REST API, they also include a number of SDKs for different platforms and frameworks such as Angular, Node, native iOS and Android and many more. You get a number of benefits when using the SDK over the REST API, including things like local caching and syncing, at no extra cost.\n\nThe simple code for the sample is below. Let's take a look and then go through it.\n\n<script async src=\"//jsfiddle.net/remotesynth/kj1w9r2L/2/embed/js,html,result/\"></script>\n\nOverall, the code is pretty simple. There's just one thing that makes getting anonymous data somewhat unique in Kinvey...\n\n![users everywhere](/images/posts/user.jpg)\n\n### Creating an Implicit User Account\n\n...there is still a user - even when I am getting the data \"anonymously.\"\n\nKinvey uses a concept of [explicit versus implicit users](https://devcenter.kinvey.com/html5/guides/users#ExplicitvsImplicit). An explicit user would utilize one of the various built-in authentication methods Kinvey offers (or a custom one) while an implicit user is auto-generated. The case above is an implicit user and the generated user record looks something like this:\n\n![The auto-generated user in my users table](/images/posts/implicit_user.jpg)\n\nThe way the app is handling the user, every new, unique connection will create a new implicit user. So, if I open this on my desktop browser it will create a new, random user account. If I then open it on my phone browser, it will create another new, random user account. Yes, there will be lots of auto-generated users, and that's ok.\n\nHowever, subsequent connections from the same device or browser are cached. This is why the code only calls the `signup()` method if the active user (`activeUser`) is not already defined.\n\nThis caching can be seen in effect by viewing your browser's local storage and finding the active user as shown below.\n\n![The cached active user](/images/posts/activeuser.jpg)\n\nSuffice it to say, if I wanted to test the auto-login process, I'd simply remove that key from local storage and the login will be re-triggered.\n\n### Getting the Data\n\nNow that I am logged in (anonymously), I can get data. First, I connect to the data store that I want to pull from (the list of Zelda shrines) and pull the data:\n\n```javascript\nvar dataStore = Kinvey.DataStore.collection('shrines');\ndataStore.pull()\n\t.then(function(regions) {\n    \t// ..\n    })\n    .catch(function(error) {\n    \tconsole.log(error);\n    })\n```\nThat part is pretty easy and straightforward. However, one thing I want to point out is that, since I am using the SDK, we can see the data has been cached locally automatically.\n\n![The WebSQL Cache](/images/posts/cache.jpg)\n\n## Next Steps\n\nI know I wrote a lot here just to get some data, but understanding that you need to have a user in _all cases_ for Kinvey was a little bit of a mental hurdle for me at first. In the next post, I'll look at how I did the same thing, but in a Vue.js application, which presented its own small, unique challenges."},{"slug":"kinvey-flex-services","category":"blog","title":"Getting Started with Serverless Using Kinvey FlexServices","description":"A guide to developing serverless functions within Kinvey.","tags":["kinvey","javascript"],"body":"\n\"Pay no attention to the man behind the curtain,\" goes one of the most famous quotes from the Wizard of Oz. It is also how I felt about many of the software applications I have built over my career. Sure, everything worked, but please don't look at the code!\n\n![Pay no attention to the man behind the curtain](/images/posts/flex-services/wiz.gif)\n\nWhen you are piecing together disparate systems to build a complex application, sometimes compromises end up getting made. However, the curtain _always_ gets pulled back eventually - usually when I or one of my colleagues had to maintain the app. It's at this point that the cost of these compromises finally becomes clear. That code to integrate a third-party API that was bundled here now needs to work there as well, but it was never written for ease of reuse. 😩\n\nOne of the benefits of business logic in the cloud is it can help enable the development of a [microservices architecture](https://martinfowler.com/articles/microservices.html) of loosely-coupled _and reusable_ components. Kinvey offers multiple methods of doing this, but by far the most powerful is [FlexServices](https://devcenter.kinvey.com/nodejs/guides/flex-services) combined with the [Flex SDK](https://www.npmjs.com/package/kinvey-flex-sdk) and [FlexService Runtime](https://devcenter.kinvey.com/nodejs/guides/flexservice-runtime).\n\n### FlexServices Can Help\n\nUsing FlexServices, I can build functions containing business logic and third-party API integrations or tie into authentication systems or data integrations that may be otherwise impossible via out-of-the-box integrations. These can be enabled for reuse in a variety of ways, including as custom endpoints that can be called directly, or collection hooks that are called when data is updated or retrieved. A FlexService can also become the system of record for data in a Kinvey collection or for authentication using [Mobile Identity Connect](https://devcenter.kinvey.com/nodejs/guides/mobile-identity-connect).\n\nObviously, there's a lot to cover here. For this article, I am going to focus on building functions that can be used as custom endpoints or collection hooks. We'll look at how to get started using the FlexService Runtime and then explore [some examples](https://github.com/remotesynth/flex-service-samples) of Flex Functions to see how they are built.\n\n#### Table of Contents\n\n* [Getting Set Up](#toc_3)\n\t* [Creating a New Project](#toc_4)\n\t* [Deploying a FlexService](#toc_5)\n* [FlexService Examples](#toc_6)\n\t*  [Moderate Text FlexService](#toc_7)\n\t\t* [Using npm Packages](#toc_8)\n\t\t* [FlexServices as Collection Hooks](#toc_9)\n\t* [Email Confirmation FlexService](#toc_10)\n\t\t*  [The Temporary Object Store](#toc_11)\n\t\t*  [Sending Email](#toc_12)\n\t*  [Shorten URL FlexService](#toc_13)\n\t\t* [External Requests](#toc_14)\n\t\t* [Getting Data from Kinvey Collections](#toc_15)\n\t*  [Text Analytics FlexService](#toc_16)\n*  [Local Testing FlexServices during Development](#toc_17)\n*  [Going Further](#toc_18)\n\n_Note: This post was originally published on the [Progress Blogs](https://www.progress.com/blogs/getting-started-with-kinvey-flexservices)._\n\n## Getting Set Up\n\nFlexServices run on a Node.js-based runtime. In order to create and test them locally, you will need [Node.js](https://nodejs.org/en/) (and npm, which is generally included in the Node.js install) installed on your system. You can find [installatin instructions here](https://docs.npmjs.com/getting-started/installing-node#installing-npm-from-the-nodejs-site). It is worth noting that the FlexService Runtime currently runs Node v6 LTS.\n\nAssuming you have Node.js installed, the first thing we need to do to work with FlexServices is to install the Kinvey CLI. This can be installed globally via npm.\n\n```bash\nnpm install -g kinvey-cli\n```\n\nYou can see the full list of Kinvey CLI commands by entering `kinvey flex -h`. Assuming the CLI is working properly, let's create a new FlexService.\n\n### Creating a New Project\n\nFlexServices are all built using JavaScript and Node.js. Here are the steps to start a new project:\n\n1. Initialize the project using npm.\n\n\t```bash\n\tnpm init\n\t```\n\t\n\tThis asks a series of questions before generating the `package.json` - the defaults are fine, but feel free to put whatever you like or run `npm init -y` in order to use the defaults without being prompted.\n2. Install the latest version of the Flex SDK and add it to your `package.json` with the `--save` modifier.\n\n\t```bash\n\tnpm install kinvey-flex-sdk --save\n\t```\n3. Create the `index.js` file - this will be the entry point to your FlexService. Add the following code:\n\n\t```javascript\n\tconst sdk = require('kinvey-flex-sdk');\n\t\n\tsdk.service((err, flex) => {\n\t  \n\t});\n\t```\n\t\n\tEffectively, this is the boilerplate upon which we will create our FlexService.\n4. Write a function. Let's start simple. This function just sends back a static response with a message property.\n\n\t```javascript\n\tfunction darthVaderQuotes(context, complete, modules) {\n\t\tcomplete().setBody({message: 'I sense something. A presence I have not felt since…'}).done();\n\t}\n\t```\n\t_Note: The `context` and `modules` aren't necessary for this function since they are not used, but I am including them for example purposes as typically you would need and use them._\n5. Register the function.\n\n\t```javascript\n\tflex.functions.register('darthVaderQuotes', darthVaderQuotes);\n\t```\n\t_Note: In most cases you'd actually assign `flex.functions` to a constant, as you'll need to reference it for every function you register, but, in this example, we are only registering the one. Also, it is recommended that you generally place the handlers in a separate file to make your FlexService easier to read and maintain. You'll see this done in the subsequent examples discussed below._\n6. Test the service locally. First start it by using `node .`. To test it, do a POST to `http://localhost:10001/_flexFunctions/darthVaderQuotes`. A tool like [Postman](https://www.getpostman.com/) can assist with this.\n\n\t![Postman request](/images/posts/flex-services/postman.png)\n\n### Deploying a FlexService\n\nNow that we know our FlexService works, let's deploy it.\n\n1. In the [Kinvey Console](https://console.kinvey.com/), choose the \"Service Catalog\" tab at the top of the page and then click the \"Add a Service\" button on the right hand side of the page.\n\n\t![Add a service](/images/posts/flex-services/add-service.png)\n2. Choose the \"Flex\" option and then \"Flex Services Runtime\".\n\n\t![Add a FlexService](/images/posts/flex-services/add-service-flex.png)\n3. Complete the form, giving the service a name, scope (in this case just scope it to an existing app, but if you don't have an app yet, you'll need to create one first), and secret. The name and secret can be anything you like. Save the service.\n\n\t![new service form](/images/posts/flex-services/new-service-form.png)\n\t\n\t_Note: For future reference, the secret offers an added layer of security when calling the FlexService, however, for our simple example, it isn't necessary._\n\n4. Back in the Terminal/Command prompt, enter `kinvey flex init` to connect your local Kinvey FlexService with the service we just created in the web console. This will run through several prompts to choose your app and then the correct service. When this is done, deploy your app with the `kinvey flex deploy` command.\n\n\t![initializing a FlexService](/images/posts/flex-services/flex-service-init-opt.gif)\n5. To check the status of your deployment, you can use `kinvey flex status`. When the deployment is complete, it should state \"status: ONLINE\".\n\n\t![deployment status](/images/posts/flex-services/flex-status.png)\n6. Since this is a simple function that just returns a message, we'll just set it up as a [custom endpoint](https://devcenter.kinvey.com/rest/guides/business-logic#custom-endpoints). To do this, go to the \"Apps\" tab within the Kinvey console and choose the app and environment that you'd like to add the endpoint to then navigate to \"Custom Endpoints\" and click \"Add an Endpoint\".\n\n\t![Add an endpoint](/images/posts/flex-services/custom-endpoints.png)\n7. Give the endpoint a name and choose the \"Microservice\" option.\n\n\t![Creating an endpoint](/images/posts/flex-services/create-endpoint-step1.png)\n\n\tThen select the correct service and handler from the options (there should be only one handler option in the dropdown for the service, since we've created only one function)\n\t\n\t![Creating an endpoint](/images/posts/flex-services/create-endpoint-step2.png)\n\n8. To test our endpoint, navigate to the API Console and choose \"POST\" as the method and select your endpoint from the list of available endpoints.\n\n\t![testing the endpoint](/images/posts/flex-services/testing-endpoint-step1.png)\n\t\n\tAfter clicking \"Send\", the details of the request and the response are displayed.\n\t\n\t![testing the endpoint result](/images/posts/flex-services/testing-endpoint-step2.png)\n\nYay! We have our first FlexService deployed! 🎉\n\nBut it really doesn't do anything useful yet. 😞\n\nNow that we've covered the basics, let's look at how we might build something that is actually useful.\n\n## FlexService Examples\n\nTo help you get started exploring what FlexServices can do for your application, I built a series of [examples and posted them to GitHub](https://github.com/remotesynth/flex-service-samples). Let's take a brief look at each of these and some of the concepts they demonstrate.\n\n### Moderate Text FlexService\n\n[View on GitHub](https://github.com/remotesynth/flex-service-samples/tree/master/moderate-text)\n\nThis FlexService is designed to serve as a simple example of integrating one of the enormous library of [npm packages](http://npmsearch.com/). In this case, it uses an npm library called [bad-words](https://www.npmjs.com/package/bad-words) that is designed to filter out or identify bad language in text.\n\n#### Using npm Packages\n\nTo use a library like bad-words in your FlexService, first you need to install it and add it to your `package.json`:\n\n```bash\nnpm install bad-words --save\n```\n\nTo make it available within the JavaScript file, you need to `require` it:\n\n```javascript\nconst Filter = require('bad-words');\n```\n\nAfter this, we just use the library as we would in any other Node.js application.\n\n```javascript\nconst filter = new Filter();\nreturn filter.isProfaneLike(text);\n```\n#### FlexServices as Collection Hooks\n\nFunctions within a FlexService can be deployed as [collection hooks](https://devcenter.kinvey.com/rest/guides/business-logic#collection-hooks), allowing them to modify, filter, clean or otherwise utilize data as it is being retrieved, saved or deleted in a Kinvey collection. Since our function moderates text, one might imagine you'd want to clean a message before it was inserted as a comment, for example.\n\nTo add a FlexService method that has been deployed as a collection hook, go to \"Collection Hooks\" within the Kinvey web console and then click \"Add a Hook\".\n\nChoose the collection that you'd like to add a hook to.\n\n![adding a collection hook](/images/posts/flex-services/add-hook.png)\n\nChoose one of the available pre or post hooks.\n\n![choosing a collection hook type](/images/posts/flex-services/choose-hook.png)\n\nSelect \"Microservice\" and click the \"Create Collection Hook\" button. On the next screen, find the service and select the method.\n\n![choosing a service method for a collection hook](/images/posts/flex-services/choose-method.png)\n\nOne thing to keep in mind is that a collection hook method will need to set the body of the request if it intends to make any changes to the data being passed in or out.\n\n```javascript\nreturn complete()\n    .setBody(result)\n    .created()\n    .ok()\n    .next();\n```\n\n### Email Confirmation FlexService\n\n[View on GitHub](https://github.com/remotesynth/flex-service-samples/tree/master/email-confirmation)\n\nThis FlexService is designed to serve as an example of how to send an email confirmation when a person signs up for a mailing list or subscription. It has three types of emails that it will send depending on the type of subscription: a new subscription; an existing user who changed their subscription status to subscribe; and, finally, a user who unsubscribed.\n\nIn order to accomplish this task, there are two functions designed to be used as a series [collection hooks](https://devcenter.kinvey.com/rest/guides/business-logic#collection-hooks). Collection hooks are functions that run before or after the saving or retrieving of data from a Kinvey collection. In many cases these will modify or massage the data in some manner, but, in this case, the function only checks to see their existing subscription status during the `onPreSave` collection hook and then sends the appropriate email in the `onPostSave` collection hook, once the save has processed in the Kinvey collection.\n\n#### The Temporary Object Store\n\nThe two functions that make up this FlexService needed a way to communicate with each other. In this scenario, the `onPreSave` hook needed to inform the `onPostSave` hook what the users subscription status was (new, existing or unsubscribe). To accomplish this, I used the temporary object store.\n\nThe [temporary object store module](https://devcenter.kinvey.com/rest/guides/flex-services#temp-object-store-module) is designed to pass small amounts of data between methods in scenarios just like this. It can be accessed via the `modules` value passed into each function:\n\n```javascript\nconst tempObjectStore = modules.tempObjectStore;\n```\n\nThen a value can be set via the `set()` function. For example, here I set a value under the key of `emailType` equal to `unsubscribed`:\n\n```javascript\ntempObjectStore.set('emailType', 'unsubscribed');\n```\nIt is later retrieved via the `get()` method:\n\n```javascript\nconst emailType = tempObjectStore.get('emailType');\n```\n\n#### Sending Email\n\nTo send the email to the user, I utilized the [email module](https://devcenter.kinvey.com/rest/guides/flex-services#email-module). This module can accessed via the `modules` value passed into each function:\n\n```javascript\nconst email = modules.email;\n```\n\nTo send an email, you need to specify the from, to, subject and text body values at a minimum. There are optional values for sending an HTML version of the email body as well as the reply to address and the cc and/or bcc recipients.\n\nTo send the email, use the `send()` method. This is an asynchronous method that returns a [promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise).\n\n```javascript\nemail.send(\n  mailOptions.from,\n  mailOptions.to,\n  mailOptions.subject,\n  mailOptions.text_body,\n  mailOptions.reply_to,\n  mailOptions.html_body,\n  mailOptions.cc,\n  mailOptions.bcc,\n  (err) => {\n    if (err) {\n      return complete().setBody(err);\n    }\n    complete()\n      .setBody(context.body)\n      .ok()\n      .next();\n  }\n);\n```\n\nIt is worth noting that the email module will not be able to send email when you are testing locally (even when using the External Flex method I discussed [here](https://www.kinvey.com/developing-and-testing-of-kinvey-flex-services-the-easier-way/)).\n\n### Shorten URL FlexService\n\n[View on GitHub](https://github.com/remotesynth/flex-service-samples/tree/master/shorten-url)\n\nThis FlexService is designed serve as a relatively simple example of how to connect to a third-party API within a FlexService. In this case, it uses [Google's URL shortener API](https://developers.google.com/url-shortener/v1/getting_started) for which you will need an [API key](https://developers.google.com/url-shortener/v1/getting_started#APIKey).\n\n#### External Requests\n\nBecause the FlexService Runtime runs on Node.js, it can integrate [npm packages](http://npmsearch.com/). In this case, I utilized [Request](https://www.npmjs.com/package/request) for the HTTP request required to communicate with the Google API.\n\nTo use a library like request in your FlexService, first you need to install it and add it to your `package.json`:\n\n```bash\nnpm install request --save\n```\n\nTo make it available within the JavaScript file, you need to `require` it:\n\n```javascript\nconst request = require('request');\n```\n\nThen we can use it as we would in any other Node.js application (Request also returns a [promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)):\n\n```javascript\nrequest.post(requestOptions, (error, res, body) => {\n  if (error) {\n    return complete().setBody(error).runtimeError().done();\n  }\n  complete()\n    .setBody({ shortUrl: body.id })\n    .done();\n});\n```\n\n#### Getting Data from Kinvey Collections\n\nAccessing data in a Kinvey collection from within a FlexService isn't difficult - as you likely expect. In the case of this FlexService, as well as the text-analytics service we'll discuss later, rather than hardcode the API key into the service, I decided to access it via a collection that I specifically designed to store configuration values. \n\nBecause FlexServices run within the context of the master key, I can make this collection containing things like my API secrets private but still get access via the FlexService. Only users with master key access (via the Kinvey web console, for example) would have access to these keys. For all intents and purposes, I am using this collection as a type of private [key value store](https://en.wikipedia.org/wiki/Key-value_database).\n\nLet's look at how this collection (named \"config\") is queried. First, we need a reference to the [dataStore module](https://devcenter.kinvey.com/rest/guides/flex-services#data-store-module) from which we can get a reference to the collection (i.e. config). Finally, we need a reference to the [query module](https://devcenter.kinvey.com/rest/guides/flex-services#query-module) that we will pass when querying this collection.\n\n```javascript\nconst store = modules.dataStore(options);\nconst config = store.collection('config');\nconst query = new modules.Query();\n```\n\nNext I set the query object to look for a column (i.e. `configKey`) equal to a value, which, in this case, is the value of the `configKey` variable that equals \"Google URL Shortener API\".\n\n```javascript\nquery.equalTo('configKey', configKey);\n```\n\nFinally, I query the collection using the `find()` method and passing in this query object.\n\n```javascript\nconfig.find(query, (err, result) => {\n  ...\n});\n```\n\nFor simplicity's sake, I have left the implementation of the method off here, but the key thing to remember is that the `find()` method returns a [promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise). You can see the full code [here](https://github.com/remotesynth/flex-service-samples/blob/master/shorten-url/lib/handlers.js).\n\n### Text Analytics FlexService\n\n[View on GitHub](https://github.com/remotesynth/flex-service-samples/tree/master/text-analytics)\n\nThis FlexService is designed serve as an example of how to integrate [machine learning](https://en.wikipedia.org/wiki/Machine_learning) APIs within a FlexService. In this case, it uses [Microsoft Azure Text Analytics API](https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/) for which you will need an [API key](https://azure.microsoft.com/en-us/try/cognitive-services/?api=text-analytics). The Text Analytics API determines the language and/or sentiment of text.\n\nThe concepts within the FlexService itself such as accessing collection data, using a method as a custom endpoint and making external API requests have all been covered previously in this article, so I won't belabor them here. One note, however, is that the service utilizes the [https](https://www.npmjs.com/package/https) npm package for its external request. This works slightly differently than the [request](https://www.npmjs.com/package/request) package. If you are curious, check the code for the [FlexService example](https://github.com/remotesynth/flex-service-samples/tree/master/text-analytics).\n\n## Local Testing FlexServices during Development\n\nWhen building FlexServices there is often a disconnect between the development, which happens locally, and the services, which exist in the cloud. This can lead to particular frustration when you need to interact with services, like data for example, that exist only within the cloud-based app environment.\n\nFortunately, using Kinvey's support for [External Flex Services](https://devcenter.kinvey.com/rest/guides/external-flex), you can combine local testing with remote data and services in most cases. I have already written a full [guide to local testing using External Flex Services](https://www.kinvey.com/developing-and-testing-of-kinvey-flex-services-the-easier-way/) if you want to learn more about how to use this when building your own FlexServices.\n\n## Going Further\n\nYou can access all of the examples as well as documentation for how to use each via my [flex-service-samples repository on GitHub](https://github.com/remotesynth/flex-service-samples).\n\nFlexServices can do more than just the functions I discussed here in this article. You can create custom authentication handlers using [FlexAuth](https://devcenter.kinvey.com/rest/guides/flex-services#flex-auth). This allows you to build a unique authentication flow that matches the needs of your enterprise, even if it isn't supported out-of-the-box by our [Mobile Identity Connect](https://devcenter.kinvey.com/rest/guides/mobile-identity-connect) authentication service. Finally, there is [FlexData](https://devcenter.kinvey.com/rest/guides/flex-services#flex-data), which allows you to build custom data connections for your Kinvey collections, even when not supported by our [RapidData](https://devcenter.kinvey.com/rest/guides/rapid-data) feature.\n\nAs I think is clear, FlexServices are really where the true power of Kinvey lies. Once you become comfortable leveraging them, it can opens up all kinds of opportunities for improving your application architecture."},{"slug":"kinvey-vue-getting-started","category":"blog","title":"Getting Started with Kinvey mBaaS - A Simple Vue App","description":"Converting the previous example to work in a Vue app","tags":["kinvey"],"body":"\nFollowing up on my [prior post](https://www.remotesynthesis.com/blog/kinvey-anonymous-data), I wanted to try to integrate the [Kinvey HTML5 (i.e. JavaScript) SDK](https://devcenter.kinvey.com/html5/downloads) into a Vue app. [Kinvey](https://www.kinvey.com/) already provides pre-built SDKs for some frameworks such as Angular, AngularJS and, though it isn't as commonly used anymore, Backbone. However, if you are using a different framework like Vue or React, you can still leverage the JavaScript SDK.\n\nI had two goals with my Vue integration:\n\n* Abstract out the anonymous login process that I showed in the prior post and notify the rest of the app that data is ready to be pulled.\n* Isolate the Kinvey integration so that we just need to import the one module which already includes the SDK integration wherever it is needed in the app.\n\nIn this post I'll share my current project. Keep in mind that I am new to Vue, so I am very open to ideas for improvement. I'll reserve the option to revise, even drastically, as I build out a real app (in fact, I already did a total refactor of this once after realizing I may have taken a less-than-optimal initial approach). Also, the current status of this app is only pulling the same anonymous data as in the prior post. You can find the [sample code on GitHub](https://github.com/remotesynth/basic-kinvey-vue-web).\n\nOk. Enough caveats...let's take a look.\n\n## A Very Simple App\n\nThis app pulls the list of Zelda shrines and displays them much the same as in the pure HTML/JavaScript example prior. To set this up, I only created two Vue components.\n\nA root component that really just holds the list for now:\n\n```html\n<template>\n  <div id=\"app\">\n    <shrines-list></shrines-list>\n  </div>\n</template>\n\n<script>\nimport ShrinesList from './components/shrines-list.vue'\n\nexport default {\n  name: 'app',\n  components: {\n    'shrines-list': ShrinesList\n  }\n}\n</script>\n```\n\nAnd the shrines list component that has the following template (I'll share the JavaScript that populates the list later):\n\n```html\n<template>\n<div>\n<ul>\n  <li v-for=\"shrine in shrines\" :key=\"shrine._id\">\n    {{ shrine.name }}\n  </li>\n</ul>\n</div>\n</template>\n```\n\nFinally, when I create the app, I imported my kinvey-vue component (which I'll show in a moment) and put it in an app global scope. This allows me to access it from any component in my app.\n\n```javascript\nimport kinvey from './kinvey-vue/index'\nimport Vue from 'vue'\nimport App from './App.vue'\n\nVue.prototype.$kinvey= kinvey;\n\nnew Vue({\n  el: '#app',\n  render: h => h(App),\n});\n```\n\nSo my app was set up, but now I needed a build the module to connect to Kinvey.\n\n## A Simple Kinvey Vue Module\n\nTo get this app started I created what is the start of a reusable Kinvey Vue module that initiates the anonymous connection as soon as it is created (note that if your app doesn't ever get anonymous data from Kinvey then, obviously, you wouldn't want to do it this way). I also abstracted out the Appkey and AppSecret used to connect to Kinvey to make it easier to reuse this without having to modify the source.\n\nHere's the code and I'll discuss it in detail after:\n\n```javascript\nimport Vue from 'vue'\nimport { Kinvey } from 'kinvey-html5-sdk'\nimport KinveyConfig from './kinvey-config'\n\nconst KinveyVue = new Vue({\n    data: {\n        appkey: KinveyConfig.APPKEY,\n        appsecret: KinveyConfig.APPSECRET,\n        activeUser: null,\n        isConnected: false,\n        DataStoreType: Kinvey.DataStoreType\n    },\n    created() {\n        var client = Kinvey.init({\n            appKey: this.appkey,\n            appSecret: this.appsecret\n        });\n        this.activeUser = Kinvey.User.getActiveUser(client);\n\n        if (!this.activeUser) {\n            var that = this;\n            console.log('signing up');\n            Kinvey.User.signup()\n                .then(function(user) {\n                    that.activeUser = user;\n                    that.isConnected = true;\n                    that.$emit('kinvey-connected');\n                }).catch(function(error) {\n                    console.log(error);\n                });\n        }\n        else {\n            console.log('user exists');\n            this.isConnected = true;\n            this.$emit('kinvey-connected');\n        }\n    },\n    methods: {\n        getCollection(collectionName,datastoretype) {\n            return Kinvey.DataStore.collection(collectionName,datastoretype);    \n        }\n    }\n});\n\nexport default KinveyVue;\n```\n\nThe `created()` method is basically the code from my prior plain HTML/JavaScript example with some minor differences (and a few console logs that help visualize what was happening and when as the app ran). The key differences are:\n\n* Rather than directly call a method to begin getting the shrine data, I announce an event notifying the app that we are logged in and connected. This way _any component_ needing data can then know that it is ok to request it.\n* I set an `isConnected` flag within the component. The reason for this is that when the login is already cached in local storage, this process happens _very fast_. In my testing this meant that the event was often announced before the application even full loaded, meaning that the Vue app never even caught it. As I'll show, this flag helped me fix that issue.\n\nRight now I also added a `getCollection()` method that returns a connection to a Kinvey collection/data store. I tried numerous ways of handling this and tried including the entire call but due to the fact that the call for the data returns a promise I kept running into difficulties within the component responding to this when the asynchronous call was returned. This could be my own naivete and I may return to this later as I revise and expand the app.\n\nLastly, let's look at how I integrated this into the shrines list component.\n\n## Integrating with a Vue Component\n\nI'm going to go back to my shrines list component and add the script to connect to Kinvey and then pull the data.\n\n```javascript\nexport default {\n    data() {\n      return {\n        shrines: [{'_id':'0','name':'Loading...'}]\n      }\n    },\n    methods: {\n      getShrines() {\n        var datastore = this.$kinvey.getCollection('shrines',this.$kinvey.DataStoreType.Network),\n          stream = datastore.find(),\n          that = this;\n        stream.subscribe(function onNext(item) {\n          that.shrines = item;\n        }, function onError(error) {\n          console.log(error);\n        }, function onComplete() {\n          //...\n        });\n      }\n    },\n    created() {\n      this.$kinvey.$on(\"kinvey-connected\",this.getShrines);\n      // if it's already connected\n      if (this.$kinvey.isConnected) {\n        console.log('loaded on created');\n        this.getShrines();\n      }\n    }\n}\n```\n\nTo start I created a shrines array in my data object (populated with a dummy item to start). When the component is `created()`, I attach an event listener to the custom `kinvey-connected` event from my module. If the connection exists, we call the method to `getShrines()`. In addition, I check if the connection already exists and, if so, call `getShrines()`. I'm not thrilled with this duplication but as I explained earlier, when the connection was cached in local storage, the event seemed to be being announced _before_ this component's `created()` method was even triggered.\n\nThe code for getting the shrines is basically the same as the basic HTML/JavaScript example from my prior post with two small changes. The first is that I use my `getCollection()` method from the kinvey-vue module to connect to the collection in Kinvey. Why? This way I don't need to worry about importing the Kinvey SDK or any other code that might be necessary within every component that needs data from Kinvey - it's already there and available. The second change is that rather than push the items on the DOM directly, I am adding them to the `shrines` array and Vue takes care of updating the UI.\n\n## Next Steps\n\nObviously this example is very simple and a bit contrived. I plan to build out a more complete and realistic Vue app as I move forward - adding in actual user authentication, sync and updating data. As I mentioned before, this is a learning process and experimentation. I'll share as I go along and I'm hoping that my initial module here will hold up as my application expands. And if anyone has suggestions on how I could improve this or approach it better, I'd love feedback."},{"slug":"knowing-your-blind-spots","category":"blog","title":"Knowing Your Blind Spots","description":"What you don't know that you don't know can hold you back.","tags":["general"],"body":"\nAll of us have blind spots. Oftentimes, these blind spots are developed over the course of years of experience. Experience is a great benefit, but experience also brings biases. I don't mean biases in the typically negative sense of the word, but rather we develop a series of solutions or ways of thinking about things. We develop these biases because these solutions have worked consistently in the past, but that can leave us unable to perceive the best way to handle things, especially when the fundamentals have shifted.\n\n## An Example from History\n\nNow, this is not a post about politics. However, it was inspired by a post about politics...or at least the study of American political history.\n\nThe article [I Thought I Understood the American Right. Trump Proved Me Wrong.](https://www.nytimes.com/2017/04/11/magazine/i-thought-i-understood-the-american-right-trump-proved-me-wrong.html?_r=0), Rick Perlstein discusses at length the changing perceptions of the history of American conservatism in the 20th century. To sum it up, as the study of the American right evolved during the course of the late 20th century, a framework evolved that was used to explain it's trajectory from William F. Buckley Jr. to Ronald Reagan and onward. While this framework generally made sense of the course of history, it also often conveniently ignored certain factors and events that didn't neatly fit into the narrative.\n\nNonetheless, the narrative persisted because, overall, it still provided the clearest means of explaining American conservatisms political evolution. Even if some pieces didn't quite fit the narrative, nothing fundamentally challenged the overall framework - until Trump.\n\nThe rise and ultimate victory of Trump is forcing historians of American conservatism to rethink their framework. As it turns out, many of those inconvenient, but once insignificant events and factors that didn't quite fit the framework were far more consequential than these historians had acknowledged.\n\n(I won't go deeper here, but I definitely recommend reading the article if you are curious.)\n\n## Another Example\n\nTo use another recently topical example, United airlines has probably been using the same process for handling overbooking for years. It may not have always worked perfectly, but it functioned. Until recently, they probably overlooked these minor failures as simply outliers that didn't fundamentally challenge the way they overbooked and handled overbookings in situations where there were more passengers than seats.\n\nHowever, in this case, the system failed catastrophically. Their initial responses showed that they still tried to perceive it as a traditional outlier to an overall functioning framework. Only after realizing the scale of the failure, and its impact on their business, do they appear to be open to fundamentally altering their perception of this problem and how to solve it. (Though I have my doubts as to whether they will find a reasonable solution - these sorts of biases can be very hard to root out.)\n\n## Recognizing Your Own Blind Spots\n\nI think that most of us can think of ways that we've landed in similar scenarios in our own work experience - I know that I can. For instance, as a software developer, you may be attached to a particular language or framework or tool that has served you well over the course of years. Thus, every project that lands on your desk is simply a matter of figuring out how it fits into your language/framework/tools of choice.\n\nOftentimes, just like these historians, we don't see that the ground has shifted until our solution fails. In this case, until our software development project either cannot be completed or fails in some other catastrophic manner.\n\nThe point here is that we all need to work hard at being aware of where our own blind spots are, so that these sorts of failures don't sneak up on us."},{"slug":"license-to-confuse","category":"blog","title":"A License to Confuse","description":"More evidence that developers aren't noticing the licenses in the software they use.","tags":["general"],"body":"\nA while back I wrote a post suggesting that [developers need to start paying attention to licenses](https://www.remotesynthesis.com/blog/developers-and-licenses). It was inspired, in part, by the whole [React licensing brouhaha](https://heathermeeker.com/2017/08/19/open-source-community-over-reacts-to-x-rated-code/).\n\nWhat inspired me about that controversy was not the specifics of the React license itself (which was a version of a [BSD + patents](BSD+Patent) license) but the fact that this license had been in use by the React library since October, 2014 - nearly 3 years before the controversy came to light when the library moved from an Apache v2 license. There were stories of large enterprises looking to rip React out of complex applications because of this controversy, which could be a massive and expensive endeavor, for a problem that was readily avoidable.\n\nNow, you can argue that this was seriously overblown (what else is new?) and that Facebook has since rectified this anyway by moving to the very liberal MIT license. However, my curiosity was more \"How did it take 3 years for anyone to notice?\"\n\n## So Why Bring This Up Again?\n\nI recently got accepted to present on this very topic to [Fluent Conference in San Jose](https://conferences.oreilly.com/fluent/fl-ca) this June. I was doing a little preliminary research for my talk and became aware that React Native is still on the same controversial BSD + patents license.\n\nIn fact, I ran a diff on the [React license and patents pre-sept 25](https://raw.githubusercontent.com/facebook/react/bef45b0b1a98ea9b472ba664d955a039cf2f8068/LICENSE) and [current React Native license](https://raw.githubusercontent.com/facebook/react-native/master/LICENSE) as well as the patents grant and they are identical. The only difference is the name of the software and the year of the copyright.\n\nYet, there doesn't seem to be any outrage over the license. In fact, according to the [State of JavaScript](https://stateofjs.com/2017/mobile/results) survey results, more than 4.8k developers have used React Native and plan to use it again and another 14k respondents would like to learn and use it.\n\n![JavaScript mobile library stats](/images/posts/mobile-library-use.jpg)\n\nIt's not that _nobody_ has noticed. Paul Chong brought it up on a [post on Medium](https://medium.com/@paulhyunchong/react-native-is-not-under-the-mit-license-54308f8b26ed), for example. And some people brought it up on a [GitHub issue has since been closed](https://github.com/facebook/react-native/issues/16079) with [no indication of a pending change](https://github.com/facebook/react-native/issues/16079#issuecomment-335855158). But if the controversy was warranted with regard to React, why not React Native?\n\n> Full disclosure: I work for Progress Software, who create the NativeScript project that competes with React Native. However, I want to state that I am not here to discuss either the merits of the license or the project itself, just how the inconsistencies in the reaction of the community illustrate a potential lack of awareness around licenses in general.\n\n## My Theories\n\nI have a few potential theories.\n\n1. **Most developers realized that the initial controversy was seriously overblown and have adjusted their expectations.** This seems unlikely. The initial controversy didn't subside until React changed its license. The explanations pushed at the time for the use of BSD + patents did little to quell the outrage, even if it was arguably overblown or even undeserved.\n2. **Most developers or enterprises have differing expectations of a mobile framework than a web framework.** Honestly, this would make no sense whatsoever. Whether justified or not, the arguments made about its broad patent revocation clause (the reason React landed on Apache's [category x](https://www.apache.org/legal/resolved.html#category-x)) would apply equally to a mobile app as to a web app.\n3. **Most developers are unaware that the license differs from React and simply assume that it is the same.** Yep, my money is on this one.\n\nI've seen this occur both in my own work experience and throughout the industry as it relates to dual-licensed software. Very often, developers (and many companies) remain unaware of the various stipulations related to the open source version's usage and simply assume open-source===free. In this case, the software is not dual-licensed, but it is not illogical for a developer to assume that since React is MIT licensed (assuming the developer is even aware of the React license), then React Native would be too...so why even look at the license?\n\nI'm not arguing that in this specific case, it could get your company into potential trouble - again, I'm not here to debate the merits of this specific license. However, it is exactly this very _type_ of case - one where we, as developers, adopt tools that we are not aware of the licenses of - that could cause problems.\n\nI hope to look into this whole process more as I continue to prepare for the talk in June. I'd love to hear your thoughts and feedback to guide me as I prepare."},{"slug":"m-is-for-markup","category":"blog","title":"Markdown is Markup and Other Confusions Around JAMStack","description":"What makes a site JAMStack? A lot of it is in the M for markup.","tags":["web development","Jamstack"],"body":"\nMultiple times from multiple people I've heard the M in [JAMStack](https://jamstack.org/) described as standing for [Markdown](https://daringfireball.net/projects/markdown/). It's an easy mistake to make, since static site generators have been so closely tied to Markdown for so long. [Jekyll](https://jekyllrb.com/), for instance, has supported Markdown as the default way to create content pages going back to some of its earliest versions in 2009 and almost every other major static site generator today does the same. So if you know the history of the tools that the JAMStack is based upon, it makes sense to think the M is for Markdown.\n\n## M is for Markup\n\nHowever, the M is actually for _mark**up**_. Markup is a much broader term that encompasses Markdown, which is a lightweight form of markup. There are other similar types of lightweight markup that some static site generator tools support including [AsciiDoc](http://asciidoc.org/) and [LaTeX](https://www.latex-project.org/about/). HTML is also markup (it's in the name after all - Hypertext _Markup_ Language).\n\nBut Markup in the JAMStack sense is more than just Markdown or HTML. A key part of that is combining these markup languages with templating. So, for instance, Jekyll uses [Liquid](https://shopify.github.io/liquid/), [Hugo](https://gohugo.io/) uses [Go Templating](https://golang.org/pkg/text/template/) and many others use [Handlebars](https://handlebarsjs.com/) or something similar. This is part of the magic that turns what would otherwise be static files into something that can generate an entire web site filled with content that can then be deployed as HTML, CSS and JavaScript.\n\n## M is for More\n\nAnd this is where the M in JAMStack goes beyond just the Markdown, HTML, YAML and Liquid you may use. Almost any site includes JavaScript, APIs and Markup, but not all these sites are built with JAMStack. The M includes the build process to put these together - meaning the M includes your static site generator. If this is a little bit hidden in the name, that's not entirely unintended. To understand why, you need to look a little bit at the history of this approach to web development.\n\nJAMStack was a term essentially created by [Netlify](https://www.netlify.com/) in conjunction with some other companies beginning to work on the tooling for this approach back [around 2016](https://web.archive.org/web/20160603092304/http://jamstack.org/). Having written books and articles and presented on the topic extensively, I was approached about it back then and, to be honest, I didn't love the name at the time, but I understood the reasoning behind it and, truthfully, didn't have any better suggestions.\n\nThe problem was that up until then we'd been simply calling them static sites and they were built with static site generators. This didn't reflect the reality, which was that these sites had become increasingly dynamic. Today's JAMStack sites are often indistinguishable from any other dynamic web application incorporating things like dynamic content, authentication, and much more. Calling them static sites would be both unfair and misleading. So JA**M**Stack it is - but let's emphasize the M!"},{"slug":"microsoft-build-2018","category":"blog","title":"What Developers Should Know from Microsoft Build","description":"We're clearly entering a new era for Microsoft and for developers","tags":["general"],"body":"\nIt used to be that I could easily ignore the news coming from Redmond. Sure, Microsoft was always important, but I was never a .NET or Windows developer, so what they were saying rarely applied to me. I might be impressed by the quality of their tooling, like Visual Studio, but I didn't write C#, so it didn't really matter.\n\nThat's not the case nowadays. Microsoft has an outsize role in most every developer's career. Even if you don't directly use their products or services, the direction they take has an enormous impact on us. For example, as they recently touted, they are the largest corporate contributor to open source on GitHub.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Microsoft is the largest single corporate contributor to open source on Github. <a href=\"https://twitter.com/hashtag/MSBuild?src=hash&amp;ref_src=twsrc%5Etfw\">#MSBuild</a> <a href=\"https://t.co/Z3ugzLSRul\">https://t.co/Z3ugzLSRul</a> <a href=\"https://t.co/WXSuF7NQhg\">pic.twitter.com/WXSuF7NQhg</a></p>&mdash; Microsoft Developer (@msdev) <a href=\"https://twitter.com/msdev/status/993546257988833280?ref_src=twsrc%5Etfw\">May 7, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThat's just one of the signs of a different Microsoft. In this post, I will share some of my own observations and thoughts after attending this week's Microsoft Build conference in Seattle. I won't spend a lot of time diving into the big announcements, but more on a general view of where I see Microsoft heading and how that impacts us as developers.\n\n## How Times Have Changed!\n\nI know everyone talks about the \"new Microsoft\" but it was truly evident at this event in so many ways. Let me illustrate a few:\n\n* Microsoft frequently touted its Linux support within various products and services (including the support for Linux line endings in Notepad that was, somewhat improbably, the biggest applause line of the keynotes).\n\n* Microsoft brought Amazon on stage to demonstrate their Cortana/Alexa integration (which was somewhat underwhelming, but you need to start somewhere I suppose). Yes, the same Amazon who is their biggest competitor in cloud services.\n\n\t<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Alexa and Cortana working together? Amazon and Microsoft up on stage together at <a href=\"https://twitter.com/hashtag/MSBuild?src=hash&amp;ref_src=twsrc%5Etfw\">#MSBuild</a> showing Cortana running on an Echo and Alexa on Windows. <a href=\"https://t.co/C3kmHCWgMr\">pic.twitter.com/C3kmHCWgMr</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/993530284304879618?ref_src=twsrc%5Etfw\">May 7, 2018</a></blockquote>\n\n* The second day keynote began with a mention that they would work to be done in time for the Google I/O keynote to begin so that viewers could switch over.\n\nIn my view, Windows and .NET played a very small role in either the day one or day two keynotes. In most cases, they played a supporting role for other announcements - in some cases a very important supporting role, but not the focus.\n\nIn fact, Microsoft seems to have accepted the reality that many/most (not sure which) developers choose to develop on a Mac. For instance, one of my personal favorite demos of the keynotes was something called [Visual Studio Live Share](https://www.visualstudio.com/services/live-share/), which enables incredible, real-time collaboration between developers (something that could be a game changer for distributed teams). The key thing about the tool though is that it doesn't care if you are working on a Mac or a PC (using either Visual Studio or Visual Studio Code).\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Visual Studio Liveshare sharing code, editing and interaction between Visual Studio Code on a Mac with Visual Studio on Windows. <a href=\"https://twitter.com/hashtag/MSBuild?src=hash&amp;ref_src=twsrc%5Etfw\">#MSBuild</a> <a href=\"https://t.co/hWc8UyvlbZ\">pic.twitter.com/hWc8UyvlbZ</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/993543376971616256?ref_src=twsrc%5Etfw\">May 7, 2018</a></blockquote>\n\nAs with most of the things Microsoft showed related to tooling, this was free, which may lead you to ask how and why they do that.\n\n## The Changing Landscape of Developer Tooling and Services\n\nWhile I had this sense already, it became much clearer to me throughout Build that Microsoft is what you might call a \"cloud first\" company. By this I mean that everything, including things like Windows and Office, are moving towards a future whereby they support the core business of Azure.\n\nI don't know enough about Microsoft's financials to know how big a role Azure services play in their current financials, but it is clear that this is where they see the growth and their future. This means that software, hardware and tooling are the three legs of the stool holding up their ever expanding cloud offerings by serving as the hooks that bring you into the ecosystem.\n\nIn my view, even their announcements that didn't even seem to be directly about Azure, were about Azure. Let me show a couple examples.\n\n* There was a lot of talk about AR, VR and drones. In some cases, this seemed to focus on Microsoft's hardware, in particular the HoloLens.\n\n\t<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Microsoft Remote Assist is a really clever and, more importantly, useful looking use of AR using HoloLens. I could see this having broad appeal. <a href=\"https://twitter.com/hashtag/MSBuild?src=hash&amp;ref_src=twsrc%5Etfw\">#MSBuild</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/993533735252312064?ref_src=twsrc%5Etfw\">May 7, 2018</a></blockquote>\n\n\tHowever, it seems clear that Microsoft does not see the HoloLens hardware as the key here. The HoloLens is just a tool that ties into an array of services (machine learning and artificial intelligence) that are the engine allowing the hardware to do anything useful. Today the hardware is from Microsoft - probably to prove the concept - but tomorrow it could be anyone's hardware so long as Azure is the engine that makes it run.\n* There was quite a bit of talk (especially on the day 2 keynote) about Office, however it was all centered around this concept of the \"office of the future.\" This was an office where every meeting and every conversation relied upon machine learning and AI services from Azure. Even seemingly unrelated Office announcements seemed to actually be about Azure.\n\n\t<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Micosoft announcing custom functions for Excel that live in the cloud and written in JavaScript. <a href=\"https://twitter.com/hashtag/MSBuild?src=hash&amp;ref_src=twsrc%5Etfw\">#MSBuild</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/993891768432082945?ref_src=twsrc%5Etfw\">May 8, 2018</a></blockquote>\n\n\tWhy would Microsoft allow you to write Excel functions in JavaScript? Not because they love JavaScript, but because a) they live in the cloud and b) they then connect to other Azure services. Little by little, things like Excel just become containers for building complex, task-based business services that rely on the Azure cloud.\n\n## The Takeaway for Developers\n\nIn my opinion, the important thing for developers to understand here is that Microsoft is headed in directions that may fundamentally change our roles (and where they are going, others are going too). They are no longer purely interested in us building applications on their platforms using their tools. In the old scenario, of tools and platforms, we developers would essentially drive the car off the lot and only come back for the occasional service appointment (via a support subscription or software upgrade).\n\nThey want us building applications that rely on their services, whether we use their tools or not. In this analogy, our car might be off the Microsoft lot or off a different lot altogether, but every time we turn the ignition or turn on the radio or hit the brakes, we depend on Microsoft.\n\nI'm not saying that this is a bad change - not having to build out server infrastructure or reinvent the wheel for many complex code tasks means that we can accomplish things that in the past may have been out of reach. But we should be aware of how these changes in the industry are going to dramatically change what is expected of developers.\n"},{"slug":"mobile-app-ecosystem","category":"blog","title":"Is the Native Mobile App Ecosystem Worth Saving?","description":"The app store ecosystem is slowly failing. Is that ok?","tags":["mobile"],"body":"\nThe native mobile app ecosystem is facing some major challenges. Some have even argued that it is in need of saving. Before we get there, though, let's examine what the problems are.\n\nAbout 5 years ago, we were in the middle of a modern \"gold rush\" with companies eager to establish a presence in the app stores. The iOS App Store opened in 2008 and it had already reached its 10 billionth download by 2011. The Android Market (now called Google Play) reached its 10 billionth download in late 2011 as well, having launched in 2008 as well. It's no wonder that companies felt they had to be there - even if little thought was sometimes given to what value their app actually offered. The presence was enough.\n\nSince that 10 billionth download, the app ecosystem continued to grow. This was driven in part by the fact that the mobile browser lagged far behind the ability of native apps. HTML5 was still seriously incomplete - the first working draft wasn't even published until 2008. Adobe was pushing Flash for mobile, which would have brought the \"app-like\" capabilities of desktop Flash to the mobile browser, but...I don't really need to revisit that, do I?\n\nBy 2013, Apple's App Store alone was raking in $10 billion in annual gross revenue. Yes, that's billion with a b.\n\nApps, it seemed, had won.\n\nSo what's changed?\n\n> Please note that this article represents my personal opinion and not  those of my employer, Progress Software / Telerik.\n\n<!--more-->\n\n## No One's Using Our App\n\nIn his recent post, [Alex Austin makes a strong case](https://medium.com/swlh/mobile-app-developers-are-suffering-a5636c57d576) that the mobile app ecosystems has become over-saturated and tilted heavily towards the top 0.01% of apps. He posted a chart that illustrates this.\n\n![The punishing app adoption power law](/images/posts/adoptionpowerlaw.png)\n\nGiven the dramatic drop off, what chance does your company's app have? As Alex says:\n\n> In the past four weeks, there were 45,000 new apps submitted to the iOS App Store alone. The chances that any of them will ever break into the top 1000 are effectively 0%, and even if they did, they’re still not seeing any amount of traffic to build a successful business.\n\nThis assertion is backed up by industry reports. In a recent [mobile apps survey](http://www.gartner.com/technology/reprints.do?id=1-2JLR2P2&ct=150717&st=sb), Gartner covers how reluctant users are to installing new apps.\n\n> Only 8% (U.S.) [of respondents] said they enjoyed searching for new apps.\n\nAnd in [Comscore's 2015 U.S. Mobile App Report](https://www.comscore.com/Insights/Presentations-and-Whitepapers/2015/The-2015-US-Mobile-App-Report), they note the difficulty in building a mobile app audience.\n\n> Despite growing audiences on apps, the existing digital infrastructure makes it harder to build large audiences on apps than on the web. As evidenced, the mobile web still has 3.5x more web properties with 5 million unique visitors than apps have.\n\nAs if to reinforce Alex's point, they note that the \"list of Top 25 mobile apps is dominated by the leading digital media companies and tends to concentrate within a few categories.\" Add to this other recent studies that have noted that a large majority of users don't download a single new app in any given month (it's around 65%, according to a [2014 Comscore survey](http://www.engadget.com/2014/08/22/comscore-app-downloads/)).\n\nWhile Comscore notes that a company's mobile app audience tends to be worth more because they are more loyal, there are clearly many obstacles in the way of building a substantial and monetizable audience in the app ecosystem.\n\nWell-known venture capitalist Fred Wilson has discussed what he calls the \"mobile downturn\" since 2014. In a [recent post](http://avc.com/2015/11/the-mobile-downturn-continued/), he noted:\n\n> Doing anything in the consumer mobile space these days is super hard. I can’t think of many consumer facing mobile apps that have gained massive traction and sustained it in the past three years. Can you?\n\nIn the [same post](https://medium.com/swlh/mobile-app-developers-are-suffering-a5636c57d576) discussed earlier, Alex Austin shared some ideas of how to save the mobile app ecosystem - more on that later. But first, can't the mobile web offer an alternative?\n\n## The Mobile Web to the Rescue?\n\nSo if apps are hurting, does this benefit the mobile web as an alternative? Yes...and no.\n\nIn a [recent post](https://atavistinsider.atavist.com/goodbye-native-mobile-apps/) discussing why the [Atavist](https://atavist.com/) is dropping its native apps, Evan Ratliff and Jefferson Rabb note that one of the reasons is that the mobile web has finally caught up, in many respects. The situation is not the same one as in 2012. Many of the features available to native apps are now available in the browser - and it is much easier to develop once for the web than to maintain multiple native apps. Because of this, they note:\n\n> The reasons for creating a native experience began to narrow. Not only was there very little we could do in a native app that we couldn’t do on the web, but the strictures of the native app environment made it nearly impossible to design well for both.\n\nAnd the mobile web audience is extremely large and growing. Referring again to [Comscore's 2015 U.S. Mobile App Report](https://www.comscore.com/Insights/Presentations-and-Whitepapers/2015/The-2015-US-Mobile-App-Report):\n\n> A comparison of the Top 1000 Apps vs. the Top 1000 Mobile Web Properties shows a surprising result. Not only do mobile web properties have audiences that are\nmore than 2.5x the size, but these audiences are also growing twice as fast.\n\nSo if the web is nearly as powerful, easier to develop for, has a larger reach and is growing faster, what's the problem?\n\nWell, Comscore did follow up the above stats by noting a lack of engagement by mobile web users. Average engagement has been in a steady decline since late 2014, leading them to believe that much of the growth is what they call \"drive-by traffic.\"\n\nThe other big problem with the mobile web is that, as I've [discussed in detail before](http://developer.telerik.com/featured/whats-wrong-with-the-web/), the mobile web suffers from performance issues and poor monetization capabilities - these are somewhat related as the [performance problems are often caused by the attempts to monetize](http://developer.telerik.com/featured/the-webs-cruft-problem/). This has led to the rise of mobile ad blockers, which, while [apparently very effective](http://www.nytimes.com/2015/10/01/technology/personaltech/ad-blockers-mobile-iphone-browsers.html?_r=0) in improving performance, are expected to cost businesses upwards of [$22 billion in revenue](http://www.nytimes.com/2015/08/20/technology/personaltech/ad-blockers-and-the-nuisance-at-the-heart-of-the-modern-web.html) this year alone. Yes, that's billion with a b.\n\n## So There's No Hope Then?\n\nSo, at this point we've established that the native mobile app ecosystem is potentially broken and the mobile web doesn't currently offer an easy, clear-cut alternative. What can we do?\n\nLet's turn back again to [Alex Austin's article](https://medium.com/swlh/mobile-app-developers-are-suffering-a5636c57d576). He offers a variety of potential solutions to fix the mobile app ecosystem including a better discovery system and, essentially, automatic download/install of apps via intents. He ends with the assertion that \"something must be done.\"\n\nBut must it?\n\nI agree that there is a problem with the native mobile app ecosystem. In fact, I've been arguing this on a personal level for years. Before I go further, I will reiterate that this is _my personal opinion_ and does not reflect those of my employer (i.e. Progress Software or Telerik). Ok, now that that's out of the way, I can say that I think the bigger issue is that **most apps suck**.\n\n## That's Right, I Said Most Apps Suck\n\nYes, I am being hyperbolic here but let me explain.\n\nFirst, apps have to overcome series of inherent issues such as:\n\n* Apps require a download and install process, even if we link to the app via intents. This isn't necessary on the web.\n* Apps eat up space on my device - sometimes needlessly large amounts when you combine the application, cache and data. Web apps use little to no permanent storage (with minor exceptions).\n* Many apps can hurt the performance and battery life of my phone by running background processes. Web apps do not (and despite some claims, ads don't kill your battery and mobile web ad blockers have been shown to offer [minimal improvement on battery life](http://www.nytimes.com/2015/10/01/technology/personaltech/ad-blockers-mobile-iphone-browsers.html?_r=0)).\n* Apps are noisy (and can be annoying) by design and by default. Managing the mess of app notifications is such a pain that we're willing to pay $350+ for a separate device whose primary benefit is [decluttering app notifications](http://www.techrepublic.com/article/the-only-two-reasons-to-buy-an-apple-watch-for-now/).\n* Apps require constant maintenance by the user via updates and app store approvals. Plus it can be difficult, as an app creator, to get your users to update. The web is always running the latest release, no intervention needed.\n\nNone of these problems are dealbreakers and some are more prominent on one platform versus the other. And a good app can make all these issues seem trivial. However, it is important to keep in mind that apps don't inherently offer something of value. The value is what you build into it. Simply being in the app store does not make your app worthwhile to consumers.\n\nLet's look at Comscore's list of the top 25 apps (i.e. the apps that eat up over 99% of all usage):\n\n[![Top 25 Mobile Apps](/images/posts/top25apps.jpg)](https://www.comscore.com/Insights/Presentations-and-Whitepapers/2015/The-2015-US-Mobile-App-Report)\n_Source: [Comscore](https://www.comscore.com/Insights/Presentations-and-Whitepapers/2015/The-2015-US-Mobile-App-Report)_\n\nMany, if not most, of these apps could arguably run equally well on the web and offer equivalent, or nearly equivalent, functionality. Heck, a number of these are simply \"appified\" versions of the web site. However, all of them have the brand power to push them to the front of the line regardless (or even come pre-installed on many phones).\n\nThe point is, unless you have a massive global brand to fall back on, the only way for your app to stick out in a crowded marketplace is to truly focus on the needs of your users. Better monetization and establishing an app store presence are company problems, not a consumer ones, and not reasons to build an app in and of themselves.\n\nIf you already have an app and feel the need to improve adoption via an app install interstitial, it's very likely that you haven't given enough thought as to why your app exists in the first place. Instead of trying to force your web users into your app, focus on making your app more appealing by making it useful. Gartner's advice in their [recent report](http://www.gartner.com/technology/reprints.do?id=1-2JLR2P2&ct=150717&st=sb) speaks to retention, but, in my opinion, applies equally to gaining new users:\n\n> Focus on creating richer, more immersive and personalized app experiences for your apps users to keep them coming back.\n\n### I Did Also Say \"Most\"\n\nI should emphasize that I am not claiming all apps are bad or apps are bad by nature. In marketplaces that each have [over 1.5 million apps](http://www.statista.com/statistics/276623/number-of-apps-available-in-leading-app-stores/), there are probably thousands of fabulous apps. However, the large number of bad apps are crowding out the good ones, making them hard to find or identify.\n\nApps also have some innate benefits. For example ,most of the apps I have installed don't really offer a ton of functionality over their web counterparts, but I use them for the one-click convenience the home screen icon offers or because, in some cases, their push notifications matter to me (Slack for instance). These benefits are not without value.\n\nThese are areas the web needs to catch up. The one-click convenience does not have to be solely the domain of native apps. And [push notifications](http://www.w3.org/TR/push-api/) on the web are coming (and in some cases, they're [already here](https://developers.google.com/web/updates/2015/03/push-notifications-on-the-open-web)).\n\n## The Native Mobile App Ecosystem Doesn't Need Saving\n\nNative mobile apps don't need to be saved because they aren't dying. This pain the ecosystem seems to be going through is not a pain of injury but one of healing. It is a pain caused by misuse - by filling the app store with thousands of apps that don't need to exist.\n\nIt is a pain that, I believe, will cause companies to move from saying \"We need a mobile app\" to asking \"Why do we need a mobile app?\" Answering this question gets at the real value your app intends to bring for the consumer/user.\n\nThere's a famous scene from the Seinfeld episode named \"[The Pitch](http://www.seinfeldscripts.com/ThePitch.htm)\" where George Costanza is pitching his show about nothing to a TV executive:\n\n![George Costanza](/images/posts/the-pitch-picture.jpg)\n\n> GEORGE: The show is about nothing.\n>\n> ...\n>\n> RUSSELL: Well, why am I watching it?\n>\n> GEORGE: Because it's on TV.\n>\n> RUSSELL: (Threatening) Not yet.\n\n\nFor too long, many companies used the George Costanza line of reasoning for their apps - why would anyone want to download this app? Because it's in the app store. And too many apps were about \"nothing\" in the sense that they didn't focus on the value they intend to offer by being an app beyond just claiming a spot in the app store or offering the company that created it an easier route to monetizing than the web offered.\n\nThe current state of the native app ecosystem is forcing companies and developers to come to grips with what value our native apps offer over the web before entering an already overcrowded market. The result, I hope, will be fewer but better apps.\n\nMeanwhile the current state of the mobile web is forcing us to fix the issues we've let fester because of our over-reliance on native apps to solve the ills of the web - namely performance and monetization. The result, I hope, will be a mobile web that better meets the needs of both consumers and companies.\n\nYes, both ecosystems need some fixing but both will survive. And I believe both will be better for their suffering.\n"},{"slug":"more-advanced-jekyll","category":"blog","title":"More Advanced Jekyll/Liquid Template Techniques","description":"Sometimes Jekyll stuff isn't obvious.","tags":["web development","Jamstack"],"body":"\nWorking on a recent project, I've come across several items that were either not well documented or slightly complex - though perhaps calling them \"advanced\" overstates the case. In this case, we'll cover using multiple filters on a single value, using Liquid in Markdown, custom sorting posts and displaying posts by category. I'm sure there may be different (even better) solutions to what I describe here, but I share because these worked for me (and might for you too).\n\n> In case you missed it, I published my original [Advanced Jekyll/Liquid Template Techniques](https://remotesynthesis.com/blog/advanced-jekyll-templates) about a year ago that covers determining if a category has posts (and how many), assigning variables, using variables in an include and, finally, dynamically loading data based on a variable.<!--more-->\n\n## Use Multiple Filters on a value\n\nThis one is kind of trivial and may be obvious to most people, but I didn't see it clearly documented (and most examples show using a single filter). All you need to do is add another pipe and another filter.\n\n```liquid\n{{ mystring | replace: \"-\", \" \" | capitalize  }}\n```\n\n## Use Liquid in Your Markdown Posts\n\nThis one may also be in the category of \"duh!\" but you can use Liquid code in your Markdown. So, in this case, I needed the relative path to an image to work on the remote site and on the local testing server.\n\n```liquid\n![My awesome image]({{ \"/img/my-awesome-image.png\" | prepend: site.baseurl }})\n```\n\n## Sorting Posts by Something Other Than Date\n\nBy default, Jekyll posts come in descending date order. However, I was building a documentation site and using posts as a way to add content to a single page with content separated by anchors (basically, a variation of the [documentation site that I built with Hugo](https://github.com/cfjedimaster/Static-Sites-Book/tree/master/ch4/docsite) for the [upcoming book](http://shop.oreilly.com/product/0636920051879.do) I'm writing with Raymond Camden). In this case, I wanted to be able to specify what order the content would display without needing to fiddle with the post dates.\n\n[Hugo](https://gohugo.io/) has the concept of [weight](https://gohugo.io/templates/variables/), which is helpful - especially since the weight is relative to other items in the category. While nothing like that exists in Jekyll, we can add it and even sort by it (though not in exactly the same manner as Hugo). Assuming that each of your posts has a `weight` value set in its frontmatter, you can do the following:\n\n```liquid\n{% assign posts_list = site.posts | sort:\"weight\" %}\n{% for posts in posts_list %}\n{% endfor %}\n```\n\nYou don't have to sort by weight. You can sort by any frontmatter value - weight just suited my needs in this scenario.\n\n## Displaying Posts Organized by Category\n\nFollowing on the sorting technique above, for this docs site, the left nav is essentially a category name and then a list of the posts within that category. In the below code, I loop through the posts (sorted by weight) and display the category header assuming the post's category is different from the prior post (of course, this assumes that the content is organized properly by weight).\n\nOne other thing you may notice is that I ignore posts with no title. In the case of my single page documentation site, some sections had \"intro\" text that would display in the content but doesn't require a navigation link. Thus, if I left the title blank, I will display it in the main content output but not in the navigation. You can also see that I am using the `post.slug` variable as a way to anchor the links rather than directly link to the page.\n\n```liquid\n<ul class=\"docs-nav\">\n{% assign posts_list = site.posts | sort:\"weight\" %}\n{% assign last_cat = \"\" %}\n{% for posts in posts_list %}\n    {% if posts.title != \"\" %}\n        {% for category in posts.categories limit:1 %}\n            {% if category != last_cat %}\n    <li><strong>{{ category | replace: \"-\", \" \" | capitalize  }}</strong></li>\n            {% endif %}\n            {% assign last_cat = category %}\n        {% endfor %}\n    <li><a href=\"#{{ posts.slug }}\" class=\"cc-active\">{{ posts.title }}</a></li>\n    {% endif %}\n{% endfor %}\n</ul>\n```\n\n## That's All For Today!\n\nI know that none of this may be earth-shattering, but they are all things that I found not obvious (and I've clearly used Jekyll a good amount). If you are curious, this code was for the documentation for an [Angular Multi-Platform Starter](https://jlooper.github.io/angular-starter/) project that I am working on with some of my colleagues."},{"slug":"negativity-bias","category":"blog","title":"The Impact of Negativity Bias","description":"Why we tend to focus on the bad stuff first.","tags":["personal"],"body":"\n[Negativity bias](https://en.wikipedia.org/wiki/Negativity_bias) is a term that describes something that, I think, we all instinctively know - that essentially negative things can overwhelm positive ones because they have more impact on your emotional state.\n\n> Your brain is simply built with a greater sensitivity to unpleasant news. The bias is so automatic that it can be detected at the earliest stage of the brain's information processing.<br> - [Our Brain's Negativity Bias](https://www.psychologytoday.com/articles/200306/our-brains-negative-bias)\n\nSo, what happens when we surround ourselves with media and feedback that is overwhelmingly negative? We get things like the [occupational burnout](https://en.wikipedia.org/wiki/Occupational_burnout) that is seemingly so prevalent in our industry (i.e. development and technology).\n\nWe surround ourselves with platforms that seem biased towards negative interactions (hello Twitter or Reddit or any comment section on nearly any blog with traffic - i.e. not this one ;) ).\n\n> The transition between acceptance and healing was blurry. The more I accepted, the more I allowed myself to heal. Part of this was **turning off the noise**. No notifications on the phone, no smartwatch, no computer, no social media, no regular TV.<br>- [My Personal Burnout Story](http://codingwithempathy.com/2016/04/12/my-personal-burnout-lessons-learned/)\n\nFor me, this was a year of pulling back from the community and from being open. Sure, the election accelerated that, but it started long beforehand for reasons having nothing to do with politics. I have cut back on writing articles (except pure tutorial pieces on occassion), stopped participating in online discussions, stopped tweeting anything but links, backd out of organizing events and meetups (or even attending them). Essentially, I pulled back from a lot and, where I couldn't fully pull back, I removed my feelings and my opinions out of it.\n\nThis year I felt overwhelmed by negative interactions. Not even those directed purely towards me, but of a community that has become bent on criticizing, attacking and public shaming.  Every time I would consider joining a discussion, a quick look at the comments or replies reminded me of why I no longer felt compelled to speak out. (And, to be clear, there are times in my past that I know that I have regrettably contributed to the negativity.)\n\nPart of what drove me _into_ the community was that I felt encouraged and welcomed. I think we need to be careful of focusing too much on negative feedback if we're going to create a community that is as welcoming as the one I found when I first became an active member 12 years ago."},{"slug":"netlify-cms-part-1","category":"blog","title":"A Fresh Look at Netlify CMS (Part 1)","description":"Setting up a new site using Netlify CMS","tags":["Jamstack","web development"],"body":"\nWhen I wrote the chapter on \"Adding a CMS\" for the [O'Reilly static sites book](http://shop.oreilly.com/product/0636920051879.do), which is now two years old, I had the opportunity to check out a brand new project called [Netlify CMS](https://www.netlifycms.org/). It was so new that when I'd reviewed it to write the chapter, it was not even public yet.\n\nSo, I was not surprised when I recently had the chance to check out the project that a lot had changed. I was surprised, though, at how dramatic the change was. For example, I'd spent about five pages of the book walking through the configuration that you can now accomplish with a single button click. So, for this post, let's take a look at what Netlify CMS is and how to get started using a template. Future posts in this series will look at setting this up on an existing site and various configuration options for advanced setups.\n\n## What is Netlify CMS\n\nNetlify CMS is a content management tool designed for [JAMstack](https://jamstack.org/) or static sites. It is created by [Netlify](https://www.netlify.com/), but does not require that you use their services in any way. One of the things that has always made Netlify CMS powerful is that it is designed to work with whatever static site generator you choose - whether it is Jekyll, Hugo, Hexo, or whatever.\n\nOnce added to your site and properly configured, Netlify CMS offers a simple user interface for adding and editing content that will be much more familiar for users who are comfortable in a Wordpress-like WYSIWYG interface.\n\nFor example, below shows the editing and preview for a very simple \"about us\" page with very limited \"front matter\" metadata.\n\n![netlify cms admin wysiwyg](/images/posts/netlifycms/netlifycms-admin.png)\n\n## Setting Up Netlify CMS on a New Site\n\nThe simplest way to set up a fresh Netlify CMS install is to use one of the predefined templates on [netlifycms.org](https://www.netlifycms.org/docs/start-with-a-template/) and use the deploy on Netlify button. You can choose from Hugo, Gatsby or Middleman as the static site engine of your choice.\n\nThe real-time recording below shows how quickly this will set up the basics of a site.\n\n![setting up a new netlify cms site](/images/posts/netlifycms/set-up-new-site.gif)\n\nDuring the deploy process, the template will automatically send an invite to the owner of the Netlify account.\n\n![invite](/images/posts/netlifycms/invite.png)\n\nClick \"Accept the invite\" and you'll be sent to the new site and prompted to create a password.\n\n![creating a password](/images/posts/netlifycms/password.png)\n\nOnce you do, you are dropped into the admin.\n\n![netlify cms admin main page](/images/posts/netlifycms/admin.png)\n\nAll of this works because the template is configured to use the [Netlify identity service](https://www.netlify.com/docs/identity/) to authenticate. If you want to add more users, you would go to your Netlify account admin, click the \"Identity\" tab at the top and then \"Invite users\" (the free account allows you to invite up to five users).\n\n![invite new users](/images/posts/netlifycms/invite-new.png)\n\nThere are a lot of configuration options for the identity service in Netlify. For example, you can even configure your admin to allow authentication via external providers, like Google authentication. Just go to \"Settings > Identity\" within your Netlify admin to configure this service (some options do require a paid account).\n\n## Next Steps\n\nNow that we have the site set up, the next steps would look something like:\n\n1. Pull a local copy the GitHub repository.\n2. Customize the look and feel of the site.\n3. Modify the configuration of Netlify CMS as needed\n\nThe last step requires editing of the `config.yml` configuration file for Netlify CMS. This is always within the `admin` folder for the CMS, but the exact location of depends on which engine you are using. In my case, I used Hugo, so it was in `/site/static/admin/`.\n\n![netlify cms configuration file](/images/posts/netlifycms/config.png)\n\nIn a future post in this series, we'll go into more detail about the configuration as well as how you can add Netlify CMS to an existing site.\n"},{"slug":"netlify-cms-part-2","category":"blog","title":"A Fresh Look at Netlify CMS (Part 2)","description":"Configuring an existing site to use Netlify CMS","tags":["Jamstack","web development"],"body":"\n[Netlify CMS]() is a content management tool designed for [JAMstack](https://jamstack.org/) or static sites created by [Netlify](https://www.netlify.com/) (though it does not require that you use their services). It is designed to work with whatever static site generator you choose - whether it is Jekyll, Hugo, Hexo, or whatever.\n\nIn [part one](https://www.netlifycms.org/), I looked at how easy it was to set up a new site using Netlify CMS. In this post, I want to look at adding Netlify CMS to an existing site. In this case, we'll explore adding it to [my personal blog](https://www.remotesynthesis.com/), which uses a pretty standard Jekyll implementation that is already deployed to Netlify.\n\n## Adding the Admin\n\nThe first thing I need to do to get this working on my blog, is to add the admin files. The location you'd need to use for this depends on which static site engine you are using and, potentially, your settings. The [documentation](https://www.netlifycms.org/docs/add-to-your-site/#app-file-structure) lists out the standard location that you'd place the admin folder and files for many popular engines. Since I am using Jekyll, the admin folder can go in the project root.\n\nInside the admin folder, I needed create two files: `config.yml` and `index.html` and place some basic code in there. So as not to completely repeat the documentation completely, the baseline code that needs go in these files can be found [here](https://www.netlifycms.org/docs/add-to-your-site/#app-file-structure).\n\n> Note that you can install Netlify CMS via npm if you prefer. The instructions I follow here would differ, of course.\n\n## Basic Configuration\n\nPretty much everything you will do for a standard installation of Netlify CMS will be handled in editing the config.yml. There are some advanced features that allow you to create custom widgets and previews in the editor pane that would require additional code, but otherwise it's just about editing the YAML configuration.\n\nLet's take a look at the basic configuration that is already in `config.yml`:\n\n```yaml\nbackend:\n  name: git-gateway\n  branch: master\n```\n\nThe backend here is what will enable my CMS to publish content to the GitHub repository. Since I am hosting this on Netlify, the configuration is simple, but there are [other options and gateways](https://www.netlifycms.org/docs/authentication-backends/) that allow you to use alternatives to GitHub and Netlify if you choose to. The gateway allows these commits to happen without needing to give each user access to the repository itself. Obviously, the branch is the branch where any edits made in the CMS will be committed.\n\nThe next thing I need to specify in the basic configuration is where I want to place images and other media that are uploaded. I have a subfolder within my root images folder to place these, so I'll add the following to my YAML `media_folder: \"images/posts\"` (note that this line should not be indented).\n\n## Configuring Content Collections\n\nNext, I need to configure the CMS so that it knows where my content is. Since this is a fairly standard Jekyll blog, my posts all live in the `_posts` folder and I use fairly standard front matter. Here's an example of the front-matter in a post - this becomes important to configuring the editor.\n\n```yaml\n---\nlayout: $/layouts/post.astro\ntitle: \"Promoting Perceived Performance with Prefetching\"\ndate: \"2019-04-24\"\ntags:\n    - web development\n    - general\ndescription: A look at two libraries designed to help improve the perceived performance of web apps\ncomments: true\n---\n```\n\nThose of you that know Jekyll will recognize that this is pretty much the default front matter, so the collection configuration is similar to the example shown in the [documentation](https://www.netlifycms.org/docs/add-to-your-site/#collections). The one significant addition is the use of multiple categories. This makes use of the [list widget](https://www.netlifycms.org/docs/widgets/#list) in the editor that works for handling multiple items like this. Specifying a widget determines how the field is edited in the editor, and there are a number of [default widgets](https://www.netlifycms.org/docs/widgets/#default-widgets) built into Netlify CMS.\n\nHere's what my final posts configuration looks like:\n\n```yaml\ncollections:\n  - name: \"blog\"\n    label: \"Blog\"\n    folder: \"_posts\"\n    create: true\n    slug: \"{{year}}-{{month}}-{{day}}-{{slug}}\"\n    fields:\n      - {label: \"Layout\", name: \"layout\", widget: \"hidden\", default: \"blog\"}\n      - {label: \"Title\", name: \"title\", widget: \"string\"}\n      - {label: \"Publish Date\", name: \"date\", widget: \"datetime\"}\n      - {label: \"Categories\", name: \"categories\", widget: \"list\"}\n      - {label: \"Description\", name: \"title\", widget: \"string\"}\n      - {label: \"Body\", name: \"body\", widget: \"markdown\"}\n      - {label: \"Comments\", name: \"comments\", widget: \"hidden\", default: \"true\"}\n```\n\n## Enabling Authentication\n\nBefore I can test that my configuration works, I need to enable authentication. Since I am using Netlify to host my site, I'll utilize the [Netlify Identity](https://www.netlify.com/docs/identity/) feature that is already supported in Netlify CMS (again, using Netlify is not required though and other authentication methods are supported).\n\nThe first step is to enable identity in the admin.\n\n![enable identity](/images/posts/netlifycms2/identity.png)\n\nNext I need to make identity invite only under settings. The Netlify free account allows for up to 5 invites (obviously, if you need more you can add them and they will be charged based on usage).\n\n![enable invite only](/images/posts/netlifycms2/invite-only.png)\n\nYou can optionally allow third-party authentication (example: Google authentication) but, since this is my blog alone, I stuck with basic Netlify authentication.\n\nI also need to enable the git gateway that I mentioned earlier in the configuration (this is also under settings).\n\n![enable git gateway](/images/posts/netlifycms2/git-gateway.png)\n\nNext, I need to add identity script to `index.html` for the admin and on my main home page:\n\n```\n<script src=\"https://identity.netlify.com/v1/netlify-identity-widget.js\"></script>\n```\n\nThere is additional script in the [documentation](https://www.netlifycms.org/docs/add-to-your-site/#add-the-netlify-identity-widget) that should also be added to the site's `index.html` page.\n\nOnce I reload the admin now in local testing I get this screen to set the site's URL.\n\n![local testing](/images/posts/netlifycms2/local-testing.png)\n\nHowever, once that is done I still cannot log in because I have not actually invited myself to be an admin in the CMS. I go back in the Netlfiy admin do that (one very minor issue I ran into is that I couldn't accept the invite without pushing the admin live or copying/modifying the URL linked in the confirmation email as the link went to the live URL). I should also note that even local tests will push changes to GitHub and post content live, so be careful (you can enable the [editorial workflow](https://www.netlifycms.org/docs/add-to-your-site/#editorial-workflow) if you want to prevent pages from automatically going live).\n\nTo invite myself I go to Identity in the Netlify admin and \"Invite Users.\"\n\n![invite users](/images/posts/netlifycms2/invite-users.png)\n\nTo complete the process, I register using the invite.\n\n![register](/images/posts/netlifycms2/complete-signup.png)\n\nOnce all of these changes are pushed live, I am already able to add and edit posts!\n\n![editing posts](/images/posts/netlifycms2/posts.png)\n\n## Editing Pages and Data\n\nBeyond just blog posts, I also wanted to edit my \"About Me\" page via the CMS. Since this is the only real standalone page with content on my site I added it using a [file collections configuration](https://www.netlifycms.org/docs/collection-types/#file-collections). The difference between this and the [folder collections](https://www.netlifycms.org/docs/collection-types/#folder-collections) is that I have to specify each file individually. It's perfect for a one-off page like this or for pages that have differing front-matter configurations.\n\nHere's the configuration I used under `collections` in my config to enable editing of my about page - you'll notice that, in this case, it's not that different from the folder configuration above:\n\n```yaml\n- name: \"pages\"\n    label: \"Pages\"\n    files:\n      - name: \"about\"\n        label: \"About Page\"\n        file: \"_pages/about.md\"\n        fields:\n          - {label: \"Layout\", name: \"layout\", widget: \"hidden\", default: \"blog\"}\n          - {label: \"Title\", name: \"title\", widget: \"string\"}\n          - {label: \"Permalink\", name: \"permalink\", widget: \"string\"}\n          - {label: \"Body\", name: \"body\", widget: \"markdown\"}\n```\n\nLastly, my list of publications and presentation are generated from [Jekyll data files](https://jekyllrb.com/docs/datafiles/) consisting of YAML data. This kind of editing can be set up using the files configuration as well.\n\nFor example, the data about my session recordings was fairly simple YAML.\n\n```yaml\nvideos:\n  -   name: \"March 2016\"\n      title: \"Static Sites for JavaScript Developers\"\n      URL: \"https://www.youtube.com/watch?v=TJ3lj-xasdw\"\n  -   name: \"July 2015\"\n      title: \"Not Your Grandad's Static Sites\"\n      URL: \"https://www.youtube.com/watch?v=TJ3lj-xasdw\"\n ...\n```\n \n And to edit this, I set it up as a list widget with the fields you see above.\n \n ```yaml\n- name: \"data\"\n  label: \"Data\"\n  files:\n    - name: \"videoslist\"\n      label: \"Videos\"\n      file: \"_data/videos.yaml\"\n      fields:\n        - name: \"videos\"\n          label: \"Videos\"\n          widget: list\n          fields:\n            - {label: \"Name\", name: \"name\", widget: \"string\"}\n            - {label: \"Title\", name: \"title\", widget: \"string\"}\n            - {label: \"URL\", name: \"URL\", widget: \"string\"}\n ```\n\nYou can see what the editor looks like below once the individual field has been expanded.\n\n![editing simple data](/images/posts/netlifycms2/simple-data.png)\n\nThe preview pane here doesn't look great but it's ok for my own purposes. If you were building this for a client, however, this may be a place that you rely on creating [custom preview widgets](https://www.netlifycms.org/docs/customization/).\n\nMy publications and presentations data lists are a little bit more complex because they have lists within lists.\n\n```yaml\npublications:\n  - name: \"O'Reilly Media\"\n    articles:\n      - title: \"Static Site Generators - Modern Tools for Static Website Development\"\n        URL: \"http://www.oreilly.com/web-platform/free/static-site-generators.csp\"\n      - title: \"Working with Static Sites (co-author with Raymond Camden)\"\n        URL: \"http://shop.oreilly.com/product/0636920051879.do\"\n  - name: \"CSS Tricks\"\n    articles:\n      - title: \"What Really Makes a Static Site Generator?\"\n        URL: \"https://css-tricks.com/really-makes-static-site-generator/\"\n...\n```\n\nLuckily you can nest list widgets within list widgets.\n\n```yaml\n- name: \"pubslist\"\n  label: \"Publications\"\n  file: \"_data/publications.yaml\"\n  fields:\n    - name: \"publications\"\n      label: \"Publications\"\n      widget: list\n      fields:\n        - {label: \"Name\", name: \"name\", widget: \"string\"}\n        - name: \"articles\"\n          label: \"articles\"\n          widget: list\n          fields:\n            - {label: \"Title\", name: \"title\", widget: \"string\"}\n            - {label: \"URL\", name: \"URL\", widget: \"string\"}\n```\n\nThe editor is a bit more complex for obvious reasons.\n\n![editing complex data](/images/posts/netlifycms2/complex-data.png)\n\n> It's worth noting here that during development I often wouldn't see changes like the additional collections listed here in the local admin right away for some reason, even when I'd pushed the changes live as well. This may have just been some sort of caching, but I mention it in case you run into it.\n\n## Finishing Up\n\nI should emphasize that I did not cover anywhere near all the configuration options and features in Netlify CMS. This was all really just the basics. However, all in all, I reiterate the feelings I expressed in the first part of this series - Netlify CMS has really come a _long_ way. For many sites, the editing capabilities it provides are more than sufficient and, as a developer, it was pretty easy to get up and running - both as a new install and adding to an existing site.\n\nImportantly, Netlify is maintaining this as an open source project, meaning that you can [contribute](https://www.netlifycms.org/docs/contributor-guide/) or [fork it](https://github.com/netlify/netlify-cms) (it's under an MIT license). This is already encouraging new tools that utilize the CMS features. In a follow up post to this series, I'll take a look at one of them that has just been released.\n"},{"slug":"netlify-form-javascript","category":"blog","title":"Submitting Netlify Forms Using JavaScript","description":"Submit a Netlify form asynchronously using JavaScript without jQuery.","tags":["Jamstack"],"body":"\n[Netlify Forms](https://docs.netlify.com/forms/setup/) make it incredibly easy to handle form submissions. In many cases all you need to do is simply need to give your form a name, add `data-netlify=\"true\"` to your `form` element and you're done. Netlify will detect the form on build and save any form submissions. You can view the data under the forms tab in your Netlify dashboard and even create triggers to do things like notify you via email of submissions. Easy.\n\nIf you're working with React, there's a [little bit of additional](https://www.netlify.com/blog/2017/07/20/how-to-integrate-netlifys-form-handling-in-a-react-app/) code required, but it's still fairly simple.\n\nSo, what if you are working in plain JavaScript? The docs provide a [jQuery-based example](https://docs.netlify.com/forms/setup/#submit-forms-via-ajax). In my case, the site I was working on did not include jQuery. I couldn't find good examples of doing this without jQuery, so I thought I'd share what worked for me.\n\n## Netlify forms without jQuery\n\nI was connecting a basic form that collects survey responses from users. First of all, I did add the `data-netlify=\"true\"` to the form. This tells Netlify to automatically pick up on the form and added it (with the name `surveyResponses` taken from my form's `name=\"surveyResponses\"`) to my admin.\n\nI did set up an `action` on my form as well, though this also wasn't entirely necessary. In my case, in this current iteration of the site I planned to redirect the person to a submission page after the response is taken. This allows me to determine where the form goes in the form code rather than hard code it into the submission handler. In theory, this would allow me to use this same code for other forms in the future.\n\nAs the [jQuery instructions note](https://docs.netlify.com/forms/setup/#submit-forms-via-ajax), Netlify forms submissions require you to serlialize the form data. jQuery provides a simple `serialize` function. To replace this, I used the `serialize` function [in this CodePen](https://codepen.io/influxweb/pen/ozoYqa):\n\n```javascript\nconst serialize = function (form) {\n\tvar field,\n\t\tl,\n\t\ts = [];\n\n\tif (typeof form == 'object' && form.nodeName == \"FORM\") {\n\t\tvar len = form.elements.length;\n\n\t\tfor (var i = 0; i < len; i++) {\n\t\t\tfield = form.elements[i];\n\t\t\tif (field.name && !field.disabled && field.type != 'button' && field.type != 'file' && field.type != 'hidden' && field.type != 'reset' && field.type != 'submit') {\n\t\t\t\tif (field.type == 'select-multiple') {\n\t\t\t\t\tl = form.elements[i].options.length;\n\n\t\t\t\t\tfor (var j = 0; j < l; j++) {\n\t\t\t\t\t\tif (field.options[j].selected) {\n\t\t\t\t\t\t\ts[s.length] = encodeURIComponent(field.name) + \"=\" + encodeURIComponent(field.options[j].value);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if ((field.type != 'checkbox' && field.type != 'radio') || field.checked) {\n\t\t\t\t\ts[s.length] = encodeURIComponent(field.name) + \"=\" + encodeURIComponent(field.value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn s.join('&').replace(/%20/g, '+');\n};\n```\nMy project already leveraged [Axios](https://github.com/axios/axios) for asynchronous HTTP requests, which I also use to submit the form post request. Here's the code:\n\n```javascript\nfunction formSubmit(e) {\n\te.preventDefault();\n\n\tconst theForm = e.currentTarget;\n\tconst options = {\n\t\theaders: { \"Content-Type\": \"application/x-www-form-urlencoded\" }\n\t}\n\tconst formData = \"form-name=\"+ theForm.name + \"&\" + serialize(theForm);\n\taxios.post(\n\t\t\"/\",\n\t\tformData,\n\t\toptions\n\t)\n\t.then(function (response) {\n\t\twindow.location.assign(theForm.action);\n\t})\n\t.catch(function (error) {\n\t\tconsole.log(error);\n\t});\n}\n\nsurveyForm.addEventListener('submit',formSubmit);\n```\n\nSome notes on what's going on here:\n\n* The `Content-Type` options may not be necessary. I added this when struggling to get it to work, but it doesn't hurt.\n* Even though my form had the `data-netlify` on it and the hidden `form-name` field was being added by Netlify, it was not being serialized for some reason. This is why I just manually add it to the formData being passed. If the `form-name` is not passed, you will get a 404 when trying to submit. With the `form-name` added, it doesn't seem to matter where you post this to. Thus, I post it to just the root.\n* In this case, I just redirect to the `action` of the form. I plan to update this function should I need it for other forms in the future to give more flexibility about what happens after the submit. My survey is in a modal (thus why all this was necessary). In the future I may just allow you to define either an action or a function that is called in response to a successful request.\n* Right now I am not yet handling the case of an error. You definitely should and I definitely will."},{"slug":"oauth-flows","category":"blog","title":"Understanding OAuth Authorization Flows","description":"What happens when you authenticate in an application using OAuth 2.0 implicit and PKCE flows.","tags":["web development"],"body":"\nIf you've used things like Google Sign In, Twitter authentication or GitHub authentication (to name a few common examples), or enabled integrations in other web applications, then you are probably familiar with OAuth.\n\nHowever, even if you've had to fully implement this yourself, if you're like me, you may not have thought too deeply about what is going on behind the scenes - during the OAuth authentication flow. In this post, I'm going to share a high level explanation of the standard OAuth 2.0 flow - called the implicit flow - for web applications. We'll then dig into the PKCE extension (don't worry if you don't know what that is yet) and explain why best practice recommendations today suggest using that flow.\n\n_I should quickly note that I am not an expert on OAuth but have spent some time digging into this topic lately and thought it would be useful to share what I've learned. Please comment on any suggestions for how I can improve the information in this post._\n\n## The Implicit Flow\n\nFrom a user standpoint, the authentication flow is pretty simple. Let's say I click a button that says \"Sign in with GitHub.\" I am then sent to GitHub to sign in and, if this is my first time, grant permissions. Once this is done I am sent back to the original site and - voilà! - I'm logged in.\n\nAs you'd imagine, behind the scenes there's a bit more going on. The basic steps are as follows (yes, this is a simplified version):\n\n![the OAuth 2.0 implicit flow](/images/posts/oauth/sm_implicit_flow.png)<br>\n_The implicit flow expressed entirely in emoji_\n\n1. The application requests authorization from the user\n1. The user authorizes the request\n1. The authorization server issues an access token via the redirect URI\n1. The application uses the token to call the API\n\nThe steps in the implicit flow are pretty straightforward and, if you've implemented OAuth 2.0 in a web application, this is probably the flow you are familiar with. A key aspect to notice is that token necessary to access the API is passed via the redirect.\n\n## Security Considerations Around the Implicit Flow\n\nSecurity on the web is always about trade-offs - more security usually means more complexity. Despite how it may seem above, the implicit flow is actually extremely simple. While this has worked and continues to work for a wide range of web applications, security experts had (and continue to have) concerns that it leaves open some potential attack vectors.\n\nThe primary vulnerability revolves around the fact that a valid access token is returned via the redirect. As [Brock Allen states](https://brockallen.com/2019/01/03/the-state-of-the-implicit-flow-in-oauth2/):\n\n> The aspect of the implicit flow that is most criticized as difficult to protect is also the fundamental mechanic of what defines the implicit flow, namely that the access token is returned from the token server to the client from the authorize endpoint.\n\nSome of the concerns include:\n\n* A \"man in the middle\" attack can intercept the redirect, thereby gaining a valid access token.\n* An access token can be injected into the redirect URL and there is no validation mechanism to ensure that the token wasn't maliciously injected.\n* The redirect in-and-of-itself can be stored in browser history (and even replicate to the cloud) thereby ensuring that copies of a valid access token have the potential to leak.\n\nThat is not to say that the implicit flow is insecure - and there are practices for mitigating these issues. However, some of of these issues were considered acceptable trade-offs in 2012 when the spec was created, largely because browser limitations in cross-domain access back then limited the availability of more secure options.\n\n> A good overview of the potential threats in the implicit flow and the available mitigation strategies are discussed in [OAuth 2.0 for Browser-Based Apps](https://tools.ietf.org/html/draft-parecki-oauth-browser-based-apps-02#section-9.8).\n\n## What is PKCE?\n\nPKCE (which stands for \"Proof Key for Code Exchange\" and is pronounced \"pixie\") was originally developed to solve a problem specific to native mobile apps using OAuth 2.0. The problem was that the application secret could not safely reside in the app. On a web app, this would sit on the server, never accessible to the client before it is passed to the authorization server. However, a mobile app would need to have it reside within the application code, which could be revealed during a decompiling process. In addition, custom URL schemes used in mobile apps for the redirect could potentially be compromised.\n\nPKCE was an extension to OAuth 2.0 that resolved this problem by adding some steps to the process.\n\n![the OAuth 2.0 PKCE flow](/images/posts/oauth/sm_pkce_flow.png)<br>\n_The PKCE flow expressed entirely in emoji_\n\n1. The application requests authorization from the user and \"code challenge\" is created using a random \"code verifier\"\n1. The code challenge is sent to the authorization server and the user authenticates\n1. The authorization server stores the code challenge and returns a code to the application\n1. Application sends the code and code verifier to authorization server via a POST request\n1. The authorization server verifies the code challenge/code verifier and issues an access token via a POST response\n1. The application uses the token to call the API\n\nWhile the PKCE flow is clearly more complicated, there are some key differences to notice. First, there is no preconfigured secret. Instead PKCE uses a cryptographically random code verifier that is generated for each request. There is also no redirect to intercept. A \"man in the middle\" attack could only steal the authorization code but won't have access to a valid token, and because there is no redirect, there is also no browser history potentially containing a valid token.\n\n\n## What's the Recommendation?\n\nIf you have a web application using the implicit flow and all is [hunky dory](https://www.vocabulary.com/dictionary/hunky-dory), then you don't necessarily need to do anything. But for future development you may want to take note of the [OAuth 2.0 Security Best Current Practice](https://tools.ietf.org/html/draft-ietf-oauth-security-topics-13#section-3.1.1) document which states:\n\n> Although PKCE so far was recommended as a mechanism to protect native apps, this advice applies to all kinds of OAuth clients, including web applications.\n\nBasically, it's not that there are new vulnerabilities that have been identified in the implicit flow, just that PKCE offers a more secure alternative that you should use if you have the option. You can find a good, no-nonsense overview of the issues discussed here and solutions in [OAuth2 Implicit Grant and SPA](https://auth0.com/blog/oauth2-implicit-grant-and-spa/) by Vittorio Bertocci.\n\nI hope this overview has been helpful.\n\n\n\n"},{"slug":"offline-data-pt2","category":"blog","title":"Getting Started with Offline Data in Web Apps Pt. 2","description":"Exploring what localStorage is, how it works and how it can be used to store and access data offline.","tags":["javascript","web development"],"body":"\nIn this series of posts, I am looking at some options for dealing with data offline. The [first part](/blog/offline-data-pt1) explored options for determining if the user is offline or has a slow/poor connection. In this part, we'll looking at some options for storing data that we can access when the user is offline or even cache for those with a poor connection. Let's start by storing small(ish) amounts of relatively simple data and explore storing that using [localStorage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage).\n\n## What is localStorage?\n\nThe best part of localStorage is that it is both easy to understand and easy to use. Basically, localStorage is an offline key/value store. The data, unlike `sessionStorage` which has an identical API, will remain saved across browser sessions. Thus it can be useful for accessing data when the user is offline.\n\nIt has some important limitations, however. For instance, it can only hold string values, but this does allow you to store serialized data. It is also [synchronous](https://www.quora.com/Is-localStorage-in-HTML5-always-synchronous). It only allows a storage quota of only about 5MB per domain (the exact amount can differ slightly depending on the browser).\n\n> What happens if you exceed that quota? I couldn't find any recent articles on this topic, but [this article from Raymond Camden](https://www.raymondcamden.com/2015/04/14/blowing-up-localstorage-or-what-happens-when-you-exceed-quota) explored how each browser behaved somewhat differently.\n\nThere is no built-in data protection - any JavaScript code on the domain can access localStorage. In fact, you can simply open your browser tools and see all localStorage values in plain text. You can even edit any value via the console. This insecurity has led some people to suggest [not using localStorage at all](https://dev.to/rdegges/please-stop-using-local-storage-1i04).\n\nDespite its limitations, localStorage can still be useful for storing simple values that maintain the state of an application when it is offline.\n\n## Using localStorage\n\nThe API for localStorage is extremely simple. You set an item with `setItem()` and get an item with `getItem()`.\n\n```javascript\nlocalStorage.setItem('keyName', value);\n\nlet myData = localStorage.getItem('keyName');\n```\n\nYou can also remove an individual item using `localStorage.removeItem('keyName')` or clear all localStorage for your domain using `localStorage.clear()`.\n\nIf you want to use localStorage to store something more complex than just a simple string, you'll need to serialize and deserialize the data.\n\n```javascript\nlocalStorage.setItem('complexData', JSON.stringify(data));\nlet complexData  = JSON.parse(localStorage.getItem('complexData'));\n```\n\nOne other thing to mention is that you can listen for events on localStorage. This will return a `StorageEvent` that provides you details about the key that was modified and the old versus the new value. This won't work on the same page that is making the changes — it is really a way for other pages on the domain using the storage to sync with any changes that are made.\n\n## Example\n\nTo give a simple example of all of these concepts at work, I create a CodePen that calls a remote API to populate a `<select>` list with types of drinks. Because this data is relatively small, I cache it in localStorage so that the list is populated even if the user is offline. If you select an item from the list, it will also store and keep that preference.\n\n<p class=\"codepen\" data-height=\"265\" data-theme-id=\"0\" data-default-tab=\"js,result\" data-user=\"remotesynth-the-bold\" data-slug-hash=\"PrLKPB\" style=\"height: 265px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;\" data-pen-title=\"PrLKPB\">\n  <span>See the Pen <a href=\"https://codepen.io/remotesynth-the-bold/pen/PrLKPB/\">\n  PrLKPB</a> by Brian Rinaldi (<a href=\"https://codepen.io/remotesynth-the-bold\">@remotesynth-the-bold</a>)\n  on <a href=\"https://codepen.io\">CodePen</a>.</span>\n</p>\n<script async src=\"https://static.codepen.io/assets/embed/ei.js\"></script>\n\nThe demo is very simple at the moment, but, in a future iteration, I'll use this selection to pull more complex data from the API and use IndexedDb to store and retrieve this offline. As a sidenote, I feel almost guilty posting a demo this ugly on CodePen seeing all the amazing things folks create there. Saying that design is not my strong suit would be a serious understatement.\n\n## Next Steps\n\nWe've seen that localStorage has a simple API that makes it easy to use to store certain types of data offline. As noted, it has some limitations, both from a functionality and security standpoint, that you need to be aware of. However, what if you need to store larger amounts of complex data offline? That's where we'll want to look at IndexedDb starting in the next part in this series."},{"slug":"offline-data-pt3","category":"blog","title":"Getting Started with Offline Data in Web Apps Pt. 3","description":"A guide to getting started with IndexedDB for storing large amounts of complex data offline.","tags":["javascript","web development"],"body":"\nIn [part 1](https://dev.to/remotesynth/getting-started-with-offline-data-in-web-apps-pt-1-136a) of this series, we looked at APIs to determine the online/offline and connection status of the user. In [part 2](https://dev.to/remotesynth/getting-started-with-offline-data-in-web-apps-pt-2-39o2), we looked at storing small amounts of data offline using LocalStorage. In this part, we're going to begin to look at how you can store large amounts of complex data offline using IndexedDB.\n\n## What Is IndexedDB?\n\nIf you've used a NoSQL data store, you'll feel relatively comfortable with how IndexedDB works. Like LocalStorage, values in IndexedDB stores data in key value pairs, but, unlike LocalStorage which only has string values, the values can be complex objects. As you'd expect, the key must be unique but it can be a property of the object.\n\nI'm going to be honest here, IndexedDB is not the simplest thing in the world. It's certainly far more than I can cover in detail here, but the key things to understand about IndexedDB are that it is:\n\n* **Asynchronous** - Unlike LocalStorage, storing and retrieving data in IndexedDB will not block the UI.\n* **Optimized for storing large amounts of data** - As the name implies, object stores within IndexedDB are indexed, offering a means to quickly retrieve values based upon those indexes rather than iterating over all records using a cursor. I should note that if your index is not unique, you'll still need to open a cursor to get all results for a given index value. Like I said, IndexedDB isn't simple.\n* **Handles complex data** - Typically any site will have a single IndexedDB database, but that database can contain any number of object stores. As the name implies, an object store is designed for storing objects.\n* **Large storage limits** - The exact size of the storage limit is difficult to specify as it is dynamic and dependent on available disk space, but can get into GBs of storage (Raymond Camden has an somewhat dated but still interesting post on [testing the storage limits of IndexedDB](https://www.raymondcamden.com/2015/04/17/indexeddb-and-limits).\n* **Transactional** - Every read and write in IndexedDB must occur within the context of a transaction. For anyone familiar with how traditional transactional SQL databases work, this will seem familiar. In short, transactions ensure that a set of database operations is completed from beginning to end - a failure at any point rolls back the entire transaction. \n* **SQL-less** - IndexedDB has no means of querying using a query language like SQL. To be searchable, a value must be indexed and even then you cannot text search a value using something similar to SQL's `LIKE`. It's also not terribly simple to handle situations where you'll need to search based upon multiple indexes.\n\nSo, my simple and quick overview isn't exactly simple or quick. I recommend reading the [basic concepts of IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Basic_Concepts_Behind_IndexedDB) on MDN if you want to understand more.\n\n## Getting Started with IndexedDB\n\nIn this section, we'll look at some of the basics to get started working with IndexedDB to store data. I'll walk through building a very simple page that loads data from the [Cocktail API](https://www.thecocktaildb.com/api.php) and then stores it locally in IndexedDB so that it can be retrieved faster and/or offline for subsequent page loads.\n\n### Creating the Database\n\nThere is a bit of boilerplate that goes into creating the database.\n\n```javascript\nlet db;\nlet dbRequest = window.indexedDB.open(\"Cocktaildb\", 1);\n\ndbRequest.onerror = function(event) {\n  alert(\"Database error: \" + event.target.errorCode);\n};\ndbRequest.onsuccess = function(event) {\n  db = event.target.result;\n  getCocktails();\n};\ndbRequest.onupgradeneeded = function(event) { \n  const db = event.target.result;\n\n  let cocktailStore = db.createObjectStore(\"Cocktails\", { keyPath : 'idDrink' });\n};\n```\n\nThe `open()` method takes two parameters. The first is the name of the database. The second is the version of the database, which is optional and will default to 1 if the database does not already exist (otherwise it will default to the existing version number). It is important to note that the version must be an integer, so using a version like 1.2 is the same as using 1.\n\nIf the database does not exist or is greater than the existing version, it will trigger the `dbRequest.onupgradeneeded` event. This is where you will create your object stores or perform any necessary updates to existing data. You would also include creating any necessary indexes here.\n\nThe `onsuccess` method will trigger once the connection has been opened and any upgrade completed, if necessary.\n\n> I am not covering a lot of items here, including indexes, which will be important in most use cases where you'd need to find or update records based upon properties other than an id. There are a lot of good resources that dive much deeper into IndexedDB. Start with MDN's guide to [using IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB) or Google's [Working with IndexedDB](https://developers.google.com/web/ilt/pwa/working-with-indexeddb) guide.\n\n### Inserting Data\n\nNow that we've created the database and opened the connection, it's time to populate it.\n\n```javascript\nlet cocktailsStore = db.transaction([\"Cocktails\"], \"readwrite\").objectStore(\"Cocktails\");\ndata.drinks.forEach(item => {\n  cocktailsStore.put(item);\n});\n```\n\nAs noted previously, every interaction with the data must occur within the context of a transaction. The `transaction()` method takes two parameters. The first is an array of object store names that will be used within the scope of the transaction and the second is the type of access, which can be `readonly` or `readwrite`.\n\nSince we are going to be inserting data, we'll need the `readwrite` mode. I then open a connection to the `Cocktails` object store. This is performed on a single line but can be separated to keep a variable reference to both the returned transaction object and the object store object. Finally, I use the `put()` method on the object store to insert the object into the data store. If I were updating a record, `put()` still works.\n\n### Retrieving Data\n\nNow that our object store has been populated, let's get the data back out of it.\n\n```javascript\nlet cocktailsStore = db.transaction([\"Cocktails\"], \"readonly\").objectStore(\"Cocktails\");\nlet getCocktailData = cocktailsStore.getAll();\ngetCocktailData.onsuccess = function(event) {\n\tif (event.target.result.length === 0) {\n\t  // load the remote data\n\t}\n\telse {\n\t  // display the local data\n\t}\n}\n```\n\nThe example gets all the records out of the object store. You still need to work within a transaction, but, in this case, we only need to read the data. The `getAll()` method gets all the records, which we can iterate through to display.\n\nIf you need to get only a single record, use the `get()` method and supply the key. To get based upon an index rather than the key, you would retrieve a reference to that index from the returned object store (i.e. `cocktaildb` in the code above) using `index()` and then use `getAll()` or `get()` on that index.\n\n### Full Example\n\nHere's the complete example to see it in action. I added some additional details to clear out local data and make it more obvious where the data is being displayed from.\n\n<p class=\"codepen\" data-height=\"265\" data-theme-id=\"0\" data-default-tab=\"js,result\" data-user=\"remotesynth-the-bold\" data-slug-hash=\"RXyBeJ\" style=\"height: 265px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;\" data-pen-title=\"IndexedDb Example\">\n  <span>See the Pen <a href=\"https://codepen.io/remotesynth-the-bold/pen/RXyBeJ/\">\n  IndexedDb Example</a> by Brian Rinaldi (<a href=\"https://codepen.io/remotesynth-the-bold\">@remotesynth-the-bold</a>)\n  on <a href=\"https://codepen.io\">CodePen</a>.</span>\n</p>\n<script async src=\"https://static.codepen.io/assets/embed/ei.js\"></script>\n\n## Where to Go From Here\n\nThis only scratches the surface of IndexedDB - again, check out MDN's [using IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB) or Google's [Working with IndexedDB](https://developers.google.com/web/ilt/pwa/working-with-indexeddb) guide as you are ready to dive deeper. If you are caching data for offline or performance purposes, you'll also need to come up with a strategy to synchronize your local data with the remote data. In some cases, you may want to  always do this as soon as the user is back online, but in others where the data may not change constantly or be changed by the user, you may want to set up a means to refresh only periodically. All of that depends on the nature of the application you are building.\n\nAs I said before, IndexedDB is not the simplest thing in the world. However, there are some really nice tools that can make working with it much simpler. In the next part of this series, we'll look at some of those."},{"slug":"on-bullying","category":"blog","title":"The Impact of Bullying","description":"This is about more than just kids.","tags":["general"],"body":"\nI've talked about the [Heavyweight podast](https://gimletmedia.com/heavyweight/) [recently](https://gimletmedia.com/heavyweight/). Today I wanted to briefly discuss [an episode](https://gimletmedia.com/episode/7-julia/) that really had an impact on me - both on a personal level and as it relates to my profession.\n\nThe episode involves, Julia, a woman who was bullied as a young girl back in the 8th grade, to the point that she left her school and clearly carries the emotional impact some 20 years later. It turns out that the bullying had other, even more serious consequences. Some of the more fascinating aspects of this story are how a culture of bullying can become pervasive within a social group to where no one feels safe. In addition, there is an impact on the teachers in this case that I think is rarely ever even considered.\n\nOn a personal level, this episode touched me as I was (to a much lesser degree) bullied as a child. I always struggled with my weight growing up and, at varying times in my childhood, it was the subject of much name-calling and ridicule. It is a topic that I think about a lot, as well, because my kids are currently working through 5th and 8th grades. These are ages not only when kids can be mean but where their behavior can have lasting impact on the recipient of that meanness.\n\nHowever, it also got me thinking about the industry that I work in. I was able to build my career in part through being active in the community and participating in social media. As part of my role on the developer relations team, I continue to maintain a fairly heavy presence in social media as well. It comes with the job.\n\nHowever, the community that was once a source of happiness for me, is now one that I personally am fearful of to some degree. There are portions of the community, and in particular certain outlets, that I could say have a culture of bullying. It is a culture that is all too free to use public shaming as a weapon to get its way (who sets these norms that need to be enforced? I do not know). It is a culture that often is quick to ridicule (look at almost any Hacker News or Reddit thread for example - and often many blog post comment threads). It is a culture that I feel got worse in 2016.\n\nPersonally, I have responded by stepping back to some degree. It is partly why I have tended to speak less frequently and even write less frequently. My writing, in fact, has been mostly confined to these posts, which I choose not to promote. Sure, that means that very few people read my writing, but my fear is that, if they were, I might say something that may cause _me_ to be the target of one of these public shamings...which would then detroy the catharsis I get by feeling free to share my thoughts here, without ridicule."},{"slug":"on-mobile-web","category":"blog","title":"On The Mobile Web in Mobile Web Weekly","description":"Addressing the controversy over the links in Mobile Web Weekly.","tags":["web development","mobile"],"body":"\nThere has been quite a bit of debate stirred lately about the content in the [Mobile Web Weekly newsletter](http://mobilewebweekly.co/) (which I co-edit with Holly Schinsky and is run by Cooper Press). In part, the debate was stirred by a fair question from Paul Irish:\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/remotesynth\">@remotesynth</a> i noticed a distinct lack of &quot;mobile web&quot; in this week&#39;s &quot;mobile web weekly&quot;. what&#39;s goin on?</p>&mdash; Paul Irish (@paul_irish) <a href=\"https://twitter.com/paul_irish/status/768538722220376064\">August 24, 2016</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nYou can see some of my responses to his tweet, but I wanted to discuss it more here as there's more to say than can fit into a tweet or two.\n\nFirst, some background on Mobile Web Weekly.<!--more-->\n\n## How Mobile Web Weekly Began\n\nI start here because it ultimately helps to understand where the initial vision for the newsletter came to be. I initially proposed the idea to Peter Cooper over 4 years or so ago, when I worked for Adobe.\n\nAt the time, I was publishing a lot of content around responsive web design and PhoneGap/Cordova. However, unlike when I published JavaScript content (which had JavaScript Weekly) or CSS content (which had CSS Weekly), there was no obvious place for this content to go. HTML5 Weekly (now Front End Focus) did exist, but was firmly focused on the actual features in the HTML5+ specs, not mobile web or hybrid development.\n\nThe initial plan was that this would even be sponsored by PhoneGap/Adobe. In the end, I was unable to secure the funding, but the idea never died. Eventually, Peter and I decided to move forward with it, and we invited Holly due in part to her expertise in hybrid mobile development.\n\nThe point of this background is that the newsletter always had a focus on _web technologies for mobile development_ and not just mobile web browser development. Peter, Holly and I even debated this when trying to name it, but Mobile Web Tech Weekly sounded awkward and confusing. Mobile Development Weekly sounded like it would cover native development, which felt like too broad a topic to be useful for a newsletter.\n\n## How Things Have Changed\n\n3 years ago when the newsletter started, things were a little different. There was mobile web development (namely RWD) and hybrid development (i.e. Cordova). No one seemed to care that the newsletter often would have a heavy amount of hybrid.\n\nSince then, tools like React Native, NativeScript and others have come about that also use web technologies to build for mobile, but in a decidedly different manner than even hybrid. The result is a native app (a native UI) with web technology hidden from view, underneath the covers.\n\nBut that's not the only change that has happened. The other is that the \"mobile web\" has somewhat disappeared as a thing. Web design is responsive web design nowadays. Many authors don't even make a distinction about whether their topic covers mobile - it's assumed that the web _is_ the mobile web. It's a distinction without a difference in many cases.\n\nExcept, when it isn't. Things like progressive web apps and AMP, both initiatives from Google, are decidedly geared towards the mobile web. We've covered these topics extensively - so much so, that I worried we were over-covering them. For all the debate about [this week's issue](http://mobilewebweekly.co/issues/122), check [last week's](http://mobilewebweekly.co/issues/121), which had a lot of PWA and web-browser focus. In fact, I'd argue that if you [go through the archive](http://mobilewebweekly.co/issues), you'll find that this week's very heavy focus on things like React Native, NativeScript and Cordova is more an aberration than a trend.\n\nBut something else has changed along with the technologies, and that is the audience.\n\n## Technology has Become Much More Partisan\n\nPaul Irish alluded to this somewhat in one of his responses, though he is more focused on the semantics of the newsletter's name and what it implied in terms of content:\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/peterc\">@peterc</a> <a href=\"https://twitter.com/remotesynth\">@remotesynth</a> it the same way: the &quot;app or web&quot; choice. To me, Hybrid/ReactNative feel like a great _alternative_ to the &quot;mobile web&quot;</p>&mdash; Paul Irish (@paul_irish) <a href=\"https://twitter.com/paul_irish/status/768584905924018176\">August 24, 2016</a></blockquote>\n\nMatthewcp laid it out much more straightforwardly.\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/peterc\">@peterc</a> <a href=\"https://twitter.com/remotesynth\">@remotesynth</a> <a href=\"https://twitter.com/paul_irish\">@paul_irish</a> the community has fractured between JS devs and Web devs. JS side more open to the native stuff. Not I.</p>&mdash; matthewcp (@matthewcp) <a href=\"https://twitter.com/matthewcp/status/768635809570385925\">August 25, 2016</a></blockquote>\n\nBack when the newsletter started, no one seemed bothered by its occasionally heavy focus on hybrid. This was probably because hybrid was considered a stopgap - a way to build for mobile and compete with mobile app ecosystems until the web finally caught up.\n\nNowadays, with HTML5 being so ubiquitous it isn't really even a \"thing\" and with efforts like PWAs and AMP, many people feel that the web has nearly caught up and we don't need things like Cordova/React Native/NativeScript to compete. They would argue that we just need to go all in on mobile web to get us across that finish line.\n\nOthers seem to believe that it has been years, and the web, while fractured, is still trying to catch up - and will continue to do so. They would argue something along the lines that we were promised parity with HTML5 but the web seems as fractured or more today - even PWAs, for instance, only target recent Android.\n\n## Can We Serve Multiple \"Communities\"?\n\nThe bigger question I think both Paul and Matthew are getting at is (beyond the specifics of the naming of the newsletter) _can we have a newsletter that serves both audiences?_ Can the two sides coexist? Or, much like TV and news today, do we need to target some micro-community, making a newsletter for mobile web, one for hybrid and one for React Native/NativeScript/Tabris.js/etc?\n\nPersonally, I would love to keep things as is. I think retreating further into a specific technology corner only makes the issues worse. We probably can and should do a better job of balancing the content, making the purpose clear and maybe sectioning the content so that it is more apparent what topic areas are covered. Perhaps we even should rename the newsletter. But I still think that a single newsletter can serve this whole audience and that by doing so we keep developers better aware of the larger ecosystem of tools and issues for using web technologies to target mobile.\n\nObviously, I am not the only voice here. Peter and Holly have been and will continue to be part of this discussion as it pertains to the newsletter. As the audience, I'd also love to hear your opinions."},{"slug":"on-the-shrinking-pc-market","category":"blog","title":"Thoughts on the Shrinking PC Market","description":"The PC market just keeps on declining","tags":["web development"],"body":"\nGartner reported this week that the [PC market hit it's 5th straight year of decline](http://www.gartner.com/newsroom/id/3568420). As Mikako Kitagawa notes:\n\n> \"The broad PC market has been static as technology improvements have not been sufficient to drive real market growth. There have been innovative form factors like 2-in-1s and thin and light notebooks, as well as technology improvements, such as longer battery life. This end of the market has grown fast, led by engaged PC users who put high priority on PCs. However, the market driven by PC enthusiasts is not big enough to drive overall market growth.\"\n\nBasically, we've reached a point where people feel that their current computer is \"good enough\" and PC makers aren't offering any improvements that are compelling enough beyond a small segment of, essentially, power users.\n\nI recall that twenty years ago, it felt as though when you bought your PC, a better, cheaper and faster version was already available before you got it home. We were always acutely aware of the processor speeds on our PCs, and how they didn't stack up to the just released ones. Nowadays, unless you are buying a machine for something like high-end gaming, I doubt that many people even pay close attention to what processor is in their PC or how fast it is. If anything, we just want things like lighter and longer battery life.\n\nMobile phones have probably reached that point (or nearly anyway), technology-wise, but, probably because they are as much accessory as utility, maintain a value as a \"status symbol\" that often compels people to upgrade."},{"slug":"owning-your-content","category":"blog","title":"Own Your Home on the Web","description":"Value the content you create by owning the content you create.","tags":["content strategy"],"body":"\nRachel Andrew had a [short but very worthwhile post](https://rachelandrew.co.uk/archives/2017/01/05/its-more-than-just-the-words/) about how much the web has changed over recent years from people owning their own playground on the web (in large part via personal blogs) to people handing over their content to third parties like Medium and CodePen (to name a couple).\n\nI agree with Rachel completely. Nevermind the fact that [places like Medium don't seem to have a workable business mode](http://www.remotesynthesis.com/blog/broken-content), owning your own content makes from a number of points of view. First of all, these sites never offer any real return for people's content. _At best_, you'd gain some notoriety by virtue of the community they built - but that was even a big if. At worst, you handed over your content in return for nothing to a company to make their own money off of and now have very limited control over it (beyond whatever tools the company may provide you).\n\n> As we move our code to CodePen, our writing to Medium, our photographs to Instagram we don’t just run the risk of losing that content and the associated metadata if those services vanish. We also lose our own place to experiment and add personality to that content, in the context of our own home on the web. - [Rachel Andrew](https://rachelandrew.co.uk/archives/2017/01/05/its-more-than-just-the-words/)\n\nIf you are creating content - be it code or writing or anything else - value it by owning it. Especially today when owning your own blog is both easy and free (may I suggest [Jekyll](http://jekyllrb.com/)!)."},{"slug":"patterns-of-development","category":"blog","title":"Patterns of Development","description":"Yes, I am old. That gives me some perspective.","tags":["web development"],"body":"\nPatterns are something that you cannot view close up - a narrow view obscures the pattern. However, given distance and time, we can begin to make out the sequences that repeat. This is one of the few benefits of being old, which I am compared to many developers.\n\nIn this post, I am not talking about development patterns as in software design patterns (or anti-patterns), but rather patterns in attitudes and behavior among developers that change the way a large number of us approach our work.<!--more-->\n\n## Front to Back to Front to...\n\nI want to discuss a pattern I have noticed throughout my career and has only become more obvious over time. This pattern is the constant shifting in focus from front-end heavy applications to back-end heavy applications. I'm bringing the topic up becuase I believe we're seeing a shift again, which becomes clear in recent [controversies over AngularJS](http://www.quirksmode.org/blog/archives/2015/01/the_problem_wit.html).\n\nBasically the pattern is that every 5 to 10 years (or so), developers seem to shift in attitude and opinion on where to place much of the burden of the application - moving from placing much of the application and business logic on the front-end, to placing it on the back-end. I think a little history might make this pattern seem clear (though you can feel free to disagree with me).\n\n## Back in My Day...\n\nAs an old person, let me give a very oversimplified history.\n\nSo, I'm not that old - really I am not. But even when I went to college it was still fairly common for many applications, especially in the enterprise, to simply be a lightweight terminal-type interface to a mainframe that had the power to run the actual application logic. In this case, obviously, the \"front-end\" application was little more than a text entry interface for entering commands into and receiving data back from the mainframe (which was effectively the server in this case).\n\n### Rich Client Server Desktops Applications\n\nAs PC's became more powerful, development tools (PowerBuilder was a popular one) helped developers create more complex and interactive native applications for the desktop. While the back-end might retain a good chunk of logic, the interface itself contained a lot of interactivity and the flow of the application was based upon certain business rules. Basically, many aspects that previously had to be kept on the back-end could now be pushed to the front.\n\n### Early Web Applications\n\nThe rise of the web changed this. Why? Well, the early web was slow and limiting in many ways. It was powerful in the sense that I no longer needed to deploy applications across multiple desktops, make sure they were updated and so on. It allowed us to interact with our applications from anywhere. However, the capabilities of the browser meant that our applications were closer to the dumb terminals of earlier days than the rich applications on the desktop. Sure, they may have looked pretty with forms and tables and blinking text, but they were mostly dumb - the application logic residing almost entirely on the server.\n\n### Flash, Flex, Silverlight...\n\nThis didn't change because browsers improved - at least not initially. Plugins like Flash built upon the initial attempts (like Java Applets) to give browsers the ability to create rich, desktop-like experiences on the web. Soon Flex and Silverlight were hot and much of the application and even business logic was moving back onto the client. Sure, we had to build portions of our business logic and validation twice, but the experience for the user was much improved. We called these Rich Internet Applications in part to recognize them as an attempt to recreate the interactivity of desktop applications but served in the browser.\n\n### HTML5\n\nThis focus on the front-end didn't change with the death of Flash and the growth of HTML5. Actually, if anything, it increased. The primary difference was that now we were writing complex, desktop-like applications in JavaScript rather than ActionScript. In fact, many back-ends became so lightweight that, in many cases, applications would connect directly to data on the cloud or in NoSQL databases.\n\n## A Shift (imo)\n\nI actually wondered if we might be hitting a point where this pattern would break, but a couple of things changed as I see it.\n\nFirst, there's the rise of JavaScript on the back-end using things like Node.js (or io.js if you now prefer). This isn't because JavaScript is so awesome, but because it allowed us to write business logic and validation and such in one language and it could run on both ends - meaning, for example, I don't have to write data validation in JavaScript on the front-end and Java (or PHP or whatever) on the back. Also, these servers are fast and built for running the types of web applications people seem to be building today.\n\nHowever, that isn't the big reason. The major shift is because of mobile (of course!). As you may have seen in some of the recent AngularJS debates (among other related topics), placing too much burden for processing and logic on the front-end can make an application run poorly on mobile. And nevermind writing things like writing validation rules twice, we certainly don't want to have to write our applications once for the desktop and then for each mobile platform. Thus, we need to move some of the code that we'd perhaps become accustomed to placing on the client back onto our back-end server...and so goes the cycle.\n\nNow, perhaps this trend will cease. Mobile devices are rapidly becoming very powerful computers in their own right. Or perhaps I am old and my mind is causing me to see patterns that don't exist. But given the back and forth on this that I have witnessed over my career, I suspect we may be in the midst of yet another shift."},{"slug":"picking-the-right-speakers","category":"blog","title":"Picking the Right Speakers for Conferences","description":"My take on the right process for choosing speakers.","tags":["conferences"],"body":"\nI have been involved in events for some years, ever since running Flex Camp Boston back in 2007 and as recently as handling many aspects of the planning, in particular the speaker lineup, for this year's TelerikNEXT event. I've also served on conference committees for events like QCon New York and Fluent. In my personal experience, the hardest part of running events are getting the word out and choosing the right speakers. Arguably, choosing the right speakers can heavily impact your ability to get the word out - after all, your content is the biggest selling point of your event.\n\nYesterday, [Lea Verou posted](http://lea.verou.me/2015/08/on-the-blindness-of-blind-reviews/) an opinion piece saying that blind reviews for technical conferences is a broken model. You should read the [full post](http://lea.verou.me/2015/08/on-the-blindness-of-blind-reviews/).\n\nIn summary, she believes that while the goal is to reduce bias and allow unknown speakers an opportunity, it ends up leading towards choosing \"safe\" topics. This is because the fear is that the more advanced or atypical topics, in the hands of the wrong speaker, could totally bomb (I'm paraphrasing - these are my words not hers).\n\nI agree with her, and while I laud the goals of making the speaker selection more egalitarian, there is simply not enough information in a typical abstract to know how successful a presentation will be as the text doesn't indicate the speaker's ability to communicate effectively in the format of a session (and requiring a prior session recording already starts making the process less open to fresh faces).\n\nHere's the [response](http://lea.verou.me/2015/08/on-the-blindness-of-blind-reviews/#comment-2191109856) I added to her post:\n\n> I totally agree with this. When I ran a conference for 5 years, I was of the mind that who gave the talk was generally more important than what they were talking about. There are people whose talks I want to see regardless of what the topic is - they are engaging, thought provoking and I always come away learning something. Other people could pick the best topic and even have the best slide deck and bomb.\n\n> I chose to have invite-only speakers list. That being said, I always set aside a certain amount of slots for speakers I'd never seen or who were new. The trouble with invite only events is the tendency to invite from within the same group every time.\n\n> To me the best option is to have a committee that you trust and who represent a diverse set of experiences, backgrounds and views. Have this committee be conscious of efforts to be inclusive and make sure there is room for some fresh faces (even acknowledging that some of these will inevitably bomb).\n\n> As you say, each method has its flaws and potential for bias, but even the blind review (as you point out) has bias, just of a different kind."},{"slug":"prettier-eslint","category":"blog","title":"Conforming to JavaScript Code Styles","description":"A quick tip on integrating Prettier with ESlint in VS Code.","tags":["web development"],"body":"\nIn recent years, the code I have written has been mostly solo work, so I have not had to conform to any coding style guide. This can lead to some bad habits. Recently, however, I began contributing some code as part of the [Kinvey](https://www.kinvey.com/) team and needed to conform to their style guide.\n\nHere's the thing though - writing code according to a style guide isn't easy. Taking the [AirBnB JavaScrpt style guide](https://github.com/airbnb/javascript) as an example (which Kinvey's is largely based on), I understand all the rules but following them means breaking a lot of old habits and learning new ones.\n\nFor those of you already on teams that follow best practices, these tips may seem obvious. But for those of us making the transition, hopefully this is useful.\n\n## Linting Helps\n\nFortunately, tools like [ESLint](https://eslint.org/) will tell me where I messed up and didn't follow the style guide. This lets me write code as I normally would, but then clean it up to follow the style guide. Running `eslint --init` will even allow you to configure ESLint to follow some popular style guides beyond the default ESLint recommended styles.\n\nThe nice thing is that ESLint let's you [share configurations](https://eslint.org/docs/developer-guide/shareable-configs), allowing the team to all easily abide by the same standard. A lot of teams post their rules publicly including:\n\n* [Google](https://github.com/google/eslint-config-google)\n* [AirBnB](https://www.npmjs.com/package/eslint-config-airbnb)\n* [Walmart Labs](https://github.com/walmartlabs/eslint-config-walmart)\n* [FormidableLabs](https://github.com/FormidableLabs/eslint-config-formidable)\n\nThis is great, and once installed, using `eslint --fix` can even automatically fix many problems, but wouldn't it be nice if this just worked in your code editor to let you fix style issues as you code?\n\n## Prettier is Easier\n\n[Prettier](https://prettier.io/) is a code formatter the supports multiple languages and editors, including a [Visual Studio Code extension](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode) (my editor of choice).\n\nPrettier has default styling rules but is configurable. However, since I already have rules defined for ESLint that I want to follow, I can just [configure it to use those](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode#user-content-vscode-specific-settings).\n\nTo do this, first click the little gear in the lower-left corner of the editor and choose \"Settings\".\n\n![VS Code Settings](/images/posts/vscode-settings.png)\n\nOr type `cmd/ctrl+shift+p` and search for \"Open user settings\".\n\n![VS Code Settings](/images/posts/vscode-usersettings.png)\n\nAll of the Prettier default settings are prefixed by `prettier.` if you want to see what they are. However, in this case, I just want to configure a user setting for this project by adding the following line to my Workspace Settings.\n\n```javascript\n \"prettier.eslintIntegration\": true\n ```\n\n So that it looks like so (assuming you don't have any other workspace settings).\n\n![VS Code Workspace Settings](/images/posts/vscode-workspace-settings.png)\n\nYou can change your user settings if you want this setting to be used across the board in your projects, but this seems more like a project by project type of setting to me.\n\nNow that this is set, I use `cmd/ctrl+shift+p` and search for \"Format Code\" and it  automatically formats my JavaScript according to the ESLint style guide I configured previously."},{"slug":"remote-working","category":"blog","title":"On Remote Working","description":"Living the dream.","tags":["general"],"body":"\nI've worked from home, on and off, since I joined Universal Mind back in 2008. That job was fully remote. My following position was remote 2-3 days a week. My first year at Adobe was fully in the office, but the following two years were fully remote. Now, my role with Telerik/Progress for the past 3 years (almost!) has been fully remote.\n\nHonestly, for me personally, I am not sure I could ever go back. Sure, I occassionally miss the interaction you get in an office, but it is something that works for me and my way of life. I enjoy being around for the kids when they get home from school or being able to live a healthy lifestyle because I am not stuck in an office all day. My recent move to the Orlando, Florida, area was completely made possible by the fact that I work from home.\n\nIf you work from home or are interested in working from home (or are interested in becoming a freelancer), [Dan Gough](https://twitter.com/dandgough) started a site where he interviews freelancers and remote workers called [Remotely Interested](http://www.remotelyinterested.co/). Check it out. It's worth a read."},{"slug":"resources-for-first-time-speakers","category":"blog","title":"Resources for First Time Speakers","description":"Unfortunately, getting the courage to submit is probably the easiest step.","tags":["conferences"],"body":"\nSpeaking at a conferences or even a meetup for the first time can be both intimidating and difficult to achieve. Even if you have the courage to submit a talk to a conference, getting accepted can be tough and the first experience can be nerve-wracking.<!--more-->\n\nMy first experience as a public speaker came at the cf.Objective conference in Minneapolis. I was speaking about a Flex framework called Cairngorm. Cairngorm was notoriously difficult - so, perhaps not the best topic for a first time speaker. Anyway, my timing was off - I spoke way too fast - and I screwed up here and there - which wasn't helped by the fact that I was intimidated by some people in the audience who knew their shit about Cairngorm. Plus, I made the rookie mistake of staying out drinking too much the night before my session. Suffice it to say, I am certain it was pretty bad.\n\nI did keep trying though. Not because I loved speaking, but because my jobs didn't pay for conferences, so this was a way to cut down the personal expense of attending (at least I'd get the entrance and maybe a hotel room paid for). It took years and many, many sessions for me to feel comfortable speaking.\n\nOne of my personal projects that I am working on involves offering some assistance to first time speakers in tech. I'm not ready to talk much about it yet, but, in the course of researching it, I've come across a handful of resources that I wanted to share. I know there are plenty of others (and I'd really love to hear about them), these just happen to be some I've personally come across.\n\n### Resources\n\n[Jen Myers](http://jenmyers.net/), a well known technology speaker and author, offers [virtual mentoring](http://jenmyers.net/mentoring/) for anyone from an underrepresented group.\n\nBrenna O'Brien, another frequent speaker on JavaScript and development, offers [paid speaking coaching](http://brennaobrien.com/coaching/).\n\n[We Are All Awesome](http://weareallaweso.me/) is a site that offers links and other resources for first time speakers at tech conferences (not new, but still relevant).\n\n[Technically Speaking](http://tinyletter.com/techspeak) by Chiu-ki and Cate is a great weekly newsletter that not only provides links to open CFPs, but also offers tips and shares articles with advice for first-time speakers.\n\nWhile not necessarily targeting new speakers, [We Speak Too](http://wespeaktoo.org/) is an interesting initiative to help promote individuals from underrepresented groups who speak. Currently, it has listings for DC and Austin."},{"slug":"review-cfp","category":"blog","title":"Want to Speak at Conferences in 2019? I'll Help Review Your CFP Submissions","description":"Need some help with your session abstract for a conference call for papers? I'm here to assist.","tags":["general"],"body":"\nI consider myself a decent speaker. I've had my better moments (and ones I'd rather forget), but I wouldn't call public speaking one of my natural strengths (it's one I continually work at). What I am pretty good at, though, is writing sessions abstracts and submissions for conference call for papers.\n\nWriting a good CFP submission can be difficult, even for many seasoned speakers. What I always recommend is that you have another set of eyes review your submission before you send it - but you may not have someone readily available who has experience writing and reviewing CFPs. That is why, as a service to the community, whether you are a potential first-time speaker or a seasoned veteran, I am making myself available to review your CFP submission.\n\nBefore you entrust a stranger with feedback on your hard work, let me share some of my qualifications:\n\n* I have been a speaker at [over 60 conferences and events](https://www.remotesynthesis.com/presentations/) starting back in 2007.\n* I have served on the conference committee for major conferences such as O'Reilly's Fluent and QCon New York.\n* I have run (both independently and for my job) over a dozen conferences since 2007.\n\nIf you'd like to have me review your CFP, I've opened my dm's on [Twitter (@remotesynth)](https://twitter.com/remotesynth). Reach out to me there. My only ask of you is that you give me a day or two to review and respond (I can't guarantee that I'll be available for last minute, time sensitive reviews). So, if you have never been a speaker and want some help or you have been a speaker but need another set of eyes on your CFP submission, I'd love to help. "},{"slug":"royalty-free-images","category":"blog","title":"5 Options for Free Stock Images","description":"Great options for high quality images.","tags":["general"],"body":"\nImagery is important to creating good content, but it can also be expensive. If you have the budget, please, by all means, go for the Getty Images or other sources. These images are usually extremely high quality and you'll almost always find a photo that perfectly suits your needs.\n\nBut what if you don't have that budget? Well, thankfully, there are some really great options. The ticky part is you may have to get creative because your options are limited - making it tough to find the perfect image - but all of these sources offer high resolution, high quality images that are free for personal or commercial use.<!--more-->\n\n## [Pexels](http://pexels.com)\n\nI only learned about Pexels recently and so far I'm impressed. The photos are high quality and there seems to be a pretty extensive selection. You can search based on keywords, making it relatively easy to find what you need. However, keep in mind that you may not find a perfect match, meaning you'll often need to get creative with your keywords. It's important to note here that the images require no attribution either (though it's always nice, if you can).\n\n> My tip, when I am having trouble finding an image, do a Google images search and see what comes up - then search based on some of the keywords you can identify in the images that it finds. Often this will lead you towards related keywords by seeing the images that other people used to illustrate your topic.\n\n## [Unsplash](http://unsplash.com)\n\nUnsplash has been my go to site for a while (especially before I discovered Pexels). It's library isn't as deep as Pexels, but it is still pretty extensive and high quality. This seems especially true when it comes to landscape or nature images, if those suit your needs (though they have photos for pretty much any keyword). A tip for this site is that, if you can't find what you want in the photos, dig through the collections - oftentimes this comes up with images that somehow didn't show up in the initial search. Unsplash images do not require attribution.\n\n## [Pixabay](http://pixabay.com)\n\nI'll admit to not using Pixabay much since I usually find what I want on the prior sites, but it does have a good selection of images that also do not require attribution. Some of the images are more graphics than photos, which can be useful too (and not typically found on the prior sites). That being said, the quality is much more mixed in my personal opinion.\n\n## [Splitshire](http://splitshire.com)\n\nOnce you get past the slightly deceptive ads (for example, beware the search box that isn't really a search for the site - that is found via the magnifying glass in the top navigation), Splitshire has some good imagery. Even more interesting, it has some (though very limited) stock video.\n\n## [Flickr](http://flickr.com)\n\nWhen all else fails, Flickr can be useful. There are thousands of images and the search let's you refine to just images that are licensed for commercial or other uses (Google images does the same, but I've found it to be unreliable or just return Wikimedia images). The quality varies on Flickr, especially when you get to free to use images, but it can be especially useful for hard to find topics/keywords that the other sites simply don't have. Keep in mind that, in my experience, the typical license on Flickr _does require_ some sort of attribution.\n\n## Others?\n\nKnow any other good resources for images? Please share - I'm always on the lookout."},{"slug":"running-a-conference","category":"blog","title":"So You Want to Run a Developer Conference","description":"Some tips and advice based on my experiences running conferences for more than a decade.","tags":["general"],"body":"\nYou love the developer conferences you've been to. You learn a lot, meet great people and come back feeling energized to try out new ideas. You think to yourself, we should have a developer conference in _my town!_\n\nThat was me circa 2007 when I ran my first conference in Boston. Thankfully it was a success and I've run a lot of developer conferences since then in Boston, Miami, New York City and even Sofia, Bulgaria.\n\nRecently, a friend reached out thinking of planning his own developer conference and this post is based upon the advice I gave him about running your own developer conference. My advice assumes you are relatively new to running events and are running one out of your own pocket or with a limited budget from your company. Obviously, it is based upon my experiences, so I'd love to hear from any of you who have run events if you agree or disagree with any of my advice. Also, if you are thinking about running an event, I'm happy to answer additional questions, so ask away in the comments.\n\n![jsMobileConf 2018](/images/posts/conferences/jsMobileConf.jpg)<br>\n_jsMobileConf in Boston in 2018_\n\n## How Big Should My Event Be?\n\nThe size of the event has been, in my experience, a complicating factor that can really impact how you proceed with your planning. Obviously, you should consider the topic (is it broad or niche? how big is the community you are targeting?), but, beyond that, you should really think about the size of the event in terms of how it can impact the cost and difficulty of planning.\n\nWhat I've found in multiple cities is that any event over 250-300 won't fit in a venue other than a hotel conference center or convention center. While these venues are nice and can take care of a lot of logistical details during the event that other venues may not, they are also exponentially more expensive. Typically you have to use the venue's catering and often even their A/V. Sometimes you may even have to purchase WiFi or guarantee a number of rooms are sold. All of these increase you or your employer's financial risk, which you'll likely want to limit for your first event, unless you have a significant budget being provided to you.\n\nA smaller event opens up some unique and interesting alternative venues. For example, universities or theaters (either stage or movie) generally have seating no more than the 300-350 range, but come with a much lower rental cost and fewer other requirements. Many provide things like WiFi and A/V at no additional cost and often even let you choose your own catering. The trade off is that you may need to handle a lot of logistics that the expensive venues would handle for you. For example, for one event in Boston I couldn't ship items so I had them all waiting at a colleague's house nearby and I ended up dragging a vat of coffee from the Starbucks down the street each morning to the event.\n\nWhile I love these \"alternative venues\", the other aspect to considering them is that you may need to have an open mind about the structure of your event. Personally, I love single track events, but if you are looking for multi-track, it can limit your options a bit. Or if you need classroom style rooms for hands-on workshops, that will likely also be harder to find. Sometimes you can get creative and find interesting workarounds, but you will need to be flexible.\n\n![TelerikNEXT in Boston in 2015](/images/posts/conferences/TelerikNEXT.jpg)<br>\n_A boat ride with speakers and colleagues at TelerikNEXT in 2015_\n\n## How Many Speakers Should I Have?\n\nAs you would expect, this is going to depend on a bunch of factors including the number of days, number of tracks, how long the day lasts and how long the sessions are. Once again, a big factor here is budget. The value of your event largely comes from the quality of your speakers, so, even if you are a low-priced community event, none of your speakers should have to pay their way to speak. Plan to cover airfare and hotel at a minimum for every out-of-town speaker. Some speakers whose jobs support or require them to speak will sometimes not need you to cover their travel, but it's best to budget as if you'll be covering everyone.\n\nSo, the cost of bringing speakers factors heavily into not how many speakers you _need_ so much as how many you can _fairly bring_. In terms of schedule, I personally don't recommend more than 40-45 minutes for standard sessions, though a keynote may be longer. This means that typical day with breaks, lunch and time between sessions means that you'll need 6-7 speakers per track per day.\n\n## How far out to plan?\n\nMy first event was planned and completed in under 60 days. It worked but I would not recommend it. Some venues can start to get booked up as early as a year in advance. You can generally put a free hold on a date, meaning if someone else comes asking for the same date you'll have the right of first refusal. Thus, there's no harm in planning early (though some stage theaters sometimes don't know their show schedule that far out and so may not be willing to fully commit to dates that far out).\n\nSpeakers also tend to get booked up pretty early. Many larger conferences have CFPs that are 6-8 months before the actual event. The sooner you get started, the better (though, once again, starting too soon can make it hard for some folks to commit that far out).\n\nI've generally started by finding the right venue first as much as a year out, though 4-6 months is generally plenty. Venue availability will impact your dates, which you'll want to be sure to research as best you can for competing events, holidays and even school schedules to be make sure you pick the date that gives you the best chance for success. Once you have a venue at the very least on a hold commitment for specific dates, you can start to talk to speakers or open a CFP. You can also begin to create a sponsor prospectus.\n\n![DevReach 2017](/images/posts/conferences/DevReach_2017.jpg)<br>\n_Christian Heilmann keynoting DevReach 2017 in Sofia, Bulgaria_\n\n## When Should You Start Promoting?\n\nI generally don't announce until I have the venue secure (with a contract signed and approved) and some initial speakers lined up. For my [latest event](https://cfe.dev/events/flashback-conference-2020/), I already started promoting it a good 7 months in advance, but most people aren't going to be ready to commit until 4-5 months in advance. In fact, in most cases the majority of your ticket sales will come during the final month before the event, if not even the final couple weeks. I know this pattern and yet I pull my hair out every time and freak out about 2 months prior. I'd stop freaking out, but conference planning is such that I cannot determine clearly whether things worked out _because I freaked out_ or _in spite of my freaking out_. To play it on the safe side, unless by some miracle my event is sold out well in advance, I plan on freaking out again in the future.\n\nWhy I freak out gets me to the next question.\n\n## What's the Most Difficult Part?\n\nThe single most difficult part of planning every event I ever planned has always been the same: getting the word out. Especially if you are running on a limited budget, there are no easy routes. I've tried throwing money at ads on social media and elsewhere, but the costs add up and, while I can't claim to be an expert at utilizing them, I've had little to no success with them. Some newsletters can be a valid route if they target your specific audience, but they may be out of reach in terms of budget and don't allow for the regional targeting that is more effective (as you may have guessed, the further away from your event you get, the more difficult it is to convince someone to attend).\n\nYour speakers can help you spread the word but it isn't really fair to demand or expect too much from them (they are already your best promotion simply by speaking and providing valuable content someone will pay to see).\n\nReally, the most effective method I've found it basically grassroots groundwork. Reach out to your friends and connections. Reach out to relevant newsletters and sites and see if they'll include it for free (but don't go in with any presumptuous expectations). Reach out to local and regional meetup organizers and see if they might be willing to share it with their members or, better yet, show up at those meetups if you can. Reach out to employers in the region who may have groups of employees they might want to send.\n\nWhen it comes to promotion, there is literally no idea that isn't worth considering. Just be kind and always stay above board.\n\n## What are Some Memorable surprises?\n\nI've been very fortunate never to have to deal with anything major. Some of my early events were in early December and mid-November in Boston, so I had a few years where we had an early winter snow or ice storm. While weather is something out of your control, obviously, it is a good reminder to consider the risk of weather during certain times of the year.\n\nI've also had speakers need to cancel last minute due to a personal emergency. That will happen from time to time. Be understanding even if you are under a lot of stress.\n\nYou may find a final surprise in the end after planning your first event. You started this journey because you enjoyed attending conferences and learned a lot from the experience. However, running a conference is not attending a conference. I've rarely had the opportunity to sit through many sessions at my own events - there are a lot of demands on my time, most of them dealing in managing logistics. Nevertheless, it can be a hugely rewarding experience that is mostly about the the opportunity to interact with both speakers and attendees. Enjoy it and good luck!"},{"slug":"running-free-events","category":"blog","title":"What I Learned from a Year of Running Free Developer Events","description":"Running developer events can be tough but rewarding, exhausting but thrilling.","tags":["general"],"body":"\nI have been involved in running events and meetups for developers for some time. Starting with a ColdFusion (😱 for those old enough to know and probably 😕 for everyone else) user group in Boston, to a 350 person annual Flash/Flex/Web development conference in Boston (which, interestingly enough is still alive having evolved into Web Unleashed in Toronto), to a number events for Telerik/Progress (my employer) including last year's DevReach event in Sofia, Bulgaria and this year's [jsMobileConf](https://jsmobileconf.com/) in Boston. All in all, I've been running events for developers on some level for about 15 years I guess.\n\nDeveloper events are like trendy restaurants though. They tend to seize on a trend (i.e. topic area) and, assuming it works, run until it is no longer relevant. When the topic/trend runs out of gas, the event often closes and reopens with a new concept. There's nothing inherently wrong with that, but it doesn't jibe with how I, personally, like to learn. I don't just want one topic area, I want to know about many different things at once! I want to be exposed to stuff outside my wheelhouse - technologies that I may never be exposed to in my day-to-day job.\n\nIt was with that in mind that I launched an effort in August of 2017 that I called [Certified Fresh Events](http://certifiedfreshevents.com/). In the past year, I've run [12 free events](https://certifiedfreshevents.com/recordings/) (as well as one paid event so far which is now available to watch for free as well). All of them have been online. In this post, I wanted to share some of what I learned during my first year running these events. I know that this post is a bit long winded - I've put a lot of myself into this effort. I'll forgive you if you want to just [skip ahead](#conclusion) and learn more about my [upcoming events and how to support them](#conclusion).\n\n## Online Events Can Be Surprisingly Interactive\n\nSo, I'll be honest. My initial concept for this effort was not going to be focused on online events. I have always had trouble keeping focus and attention during an online event. I also have felt that the level of interaction was generally too low to keep me engaged. I chose to start with online events as a matter of expediency rather than a firm belief that this was the way to go.\n\nHowever, after a year, I will admit to having been extremely surprised at how much interaction an online event can have. I've run panels where we have interaction between speakers, of course, but beyond that, the engagement with attendees on the chat during the event is surprising. The conversations generally start before the event even officially kicks off and remain active throughout. This was true even for the full-day paid event that ran 8 hours - the conversation continued the full day.\n\nSure, it's not the same as meeting someone in person, but I also didn't have to invest thousands of dollars in conference fees, travel and lodging to join. This also means that I can take a chance on topics that I may not invest to travel to an event about. It's not a replacement for in-person events if you can attend them, but it can offer some different possibilities.\n\n## Past Performance is Not Indicative of Future Results\n\nMy [first event a year ago](https://certifiedfreshevents.com/events/javascript-2017/) was hugely successful - we had over 250 live attendees and almost 700 people total including those who watched the recording. It was more than I ever anticipated (I even had to sign up for the more expensive streaming service due to the response).\n\nNonetheless, a year later, I have never reached that level of success again. Sure, many of the events have been popular, but nothing like that. Each event seems to be its own adventure, from a promotional perspective. One event will get 30 live attendees and the next 150.\n\nI think this is indicative of the challenges of switching topics fairly significantly each month. While many of my events have focused on web technologies, I have often have run other topics outside that focus. The channels open to me for promotion (especially free promotion) are limited, so when I venture outside my wheelhouse, I can't even leverage my own limited personal audience on social media.\n\n## Beware of Burnout\n\nIt would be fair to say that I've had months where I've been on the verge of just giving up. When you get a well-known speaker to agree to give a talk, and invest time and effort (and the money to run everything) only to find it difficult to get an audience, it can be disheartening - especially when the job that pays the bills gets busy.\n\nThis isn't specific to these events. Running community events can be really, really tough and stressful. The hardest part is always getting the word out. So while an online event may logistically be easier, it doesn't alleviate the need to promote it. In some ways, it can be tougher as many channels dedicated to events and meetups don't cater toward online meetups.\n\nKeep in mind that people who run community events for developers, even paid ones, are rarely in it for the money. Events, even ones like monthly meetups - whether online or in person - take a ton of time and effort to organize. Even if an event is profitable, it rarely makes enough to make it worth the effort unless you really care about it for reasons beyond the money. For my part, the rare paid event is only enough to subsidize the cost of running the free ones.\n\nBut the key to fighting burnout in these events, for me at least, is that I invite people that I really want to hear speak on topics that I am really interested in. These are an opportunity for me to learn alongside the audience and it has been awesome.\n\n<a name=\"conclusion\"></a>\n## Help Me Keep This Going!\n\nOver the past year, I've had over 2,300 people register for my free online events/meetups. I know a lot of those people keep coming back. I am already looking forward to another year of events, but _I need your help_. If you have benefited from one of them or think you will in the future, here's how you can help:\n\n* Attend this month's [free meetup on IoT, Bots and AI](https://certifiedfreshevents.com/events/bots-iot-ai/) featuring Tomomi Imura and David Simmons.\n* If you can afford it (at $250), sign up for the [half-day, hands-on IoT training](https://certifiedfreshevents.com/events/building-iot-apps/) being taught by Burke Holland and Brandon Satrom. This includes all the hardware you need (which usually costs $89)\n* If you qualify, apply for one of the 10 [diversity scholarships](https://certifiedfreshevents.com/contact/iot-scholarship/) for the IoT training sponsored by [Microsoft Cloud Developer Advocates](https://developer.microsoft.com/en-us/advocates/index.htm). The scholarship also includes the hardware.\n* Watch one of the [13 free, recorded events](https://certifiedfreshevents.com/recordings/).\n* Follow [Certified Fresh Events on Twitter](https://twitter.com/fresheventsfl). Seriously, I could use the follow as, despite the 2,300 attendees, I am at under 150 follows. As a famous, orange-haired clown might say, \"Sad!\"\n* If you would like to speak at an upcoming meetup or have topic ideas for one, email me at brian[at]certifiedfreshevents[dot]com.\n\nThanks in advance!\n\n "},{"slug":"running-ssl-localhost","category":"blog","title":"Running SSL on localhost","description":"Some strategies for local testing with SSL","tags":["web development"],"body":"\nBefore I get started with the how, I assume some of you may be asking, \"Why do I care about running SSL on my localhost?\" Well, there are some specific situations that you may care. Here are just a few:\n\n1. You are enforcing SSL in production and want to ensure that you can test for errors that may pop up in production when working locally. For example, errors related to non-secure resources being loaded and causing security warnings or errors related to potentially broken links when redirecting to SSL.\n2. You are making an ajax call to an API that uses SSL and are running into a [same origin policy](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy) error due to the different protocol. This should be solvable via [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) if you control the endpoint, but you may not.\n3. You are developing a PWA, which requires SSL. While you should be able to ignore warnings related to SSL for local testing, you may prefer to more closely replicate your production app locally for testing.\n\nThere may be others, but these are some that I have run into myself.\n\nNow that we have some reasons _why_ you might want to run your localhost on SSL, let's look at how to do it. In this post, I'll look at some examples when using a simple Node web server, running Jekyll and running Wordpress. All of my examples are running on MacOS. Obviously, there are a ton of other local web server setups that I won't get to cover.\n\n## SSL with localhost on a Node Web Server\n\nFor many local web development tasks, I rely on simple HTTP servers built on Node. There are a ton of them available in npm. It turns out that many of them support SSL. One of the options that I have installed, [local-web-server](https://www.npmjs.com/package/local-web-server), even comes with a certificate that you can use to automatically launch localhost on SSL with just a command line option.\n\n```bash\nws --https\n```\n\nThe problem is that, by default, you'll get this lovely error.\n\n![Not safe error](/images/posts/ssl-localhost/error.png)\n\nYou can, of course, proceed to localhost but you won't see the \"secure\" icon in Chrome, which may obscure other security issues (like insecure resources on a secure page). If you want the secure checkmark, they offer [detailed instructions](https://github.com/lwsjs/local-web-server/wiki/How-to-get-the-%22green-padlock%22-using-the-built-in-certificate) on how to do this for Mac OS.\n\nThe instructions generally work for me running MacOS Sierra (yep, I'm still avoiding High Sierra until someone convinces me of a compelling reason to switch). I will note that I could not easily navigate to the installation folder that contains their built-in certificate (in my case, this is `/usr/local/lib/node_modules/local-web-server/node_modules/lws`) from within Keychain Access. Instead, I located it via Finder and then simply dragged the certificate into my \"login\" keychain.Once you do that, click on it to open it.\n\n![trusting the lws cert](/images/posts/ssl-localhost/trust-lws.png)\n\nExpand the \"Trust\" section and set \"Secure Sockets Layer (SSL)\" to \"Always Trust.\"\n\nIf you prefer not to use the web server's included certificate but want to use your own, the [instructions](https://github.com/lwsjs/local-web-server/wiki/How-to-get-the-%22green-padlock%22-using-the-built-in-certificate) also demonstrate how to do that, though it wasn't a critical issue for me, personally.\n\n## SSL with localhost with Jekyll\n\nI have used Jekyll to build a number of sites, including [my blog](https://www.remotesynthesis.com/) which enforces SSL. When building Jekyll locally, you'll typically use the built-in web server that builds the pages and allows you to test them in the browser. The good news is that it is fairly easy if you want to do this and test the page locally using SSL.\n\nThe first step would be to generate a certificate for your localhost. [This guide](https://letsencrypt.org/docs/certificates-for-localhost/#making-and-trusting-your-own-certificates) from Let's Encrypt offers good instructions that you can just copy/paste into the Terminal.\n\n```bash\nopenssl req -x509 -out localhost.crt -keyout localhost.key \\\n  -newkey rsa:2048 -nodes -sha256 \\\n  -subj '/CN=localhost' -extensions EXT -config <( \\\n   printf \"[dn]\\nCN=localhost\\n[req]\\ndistinguished_name = dn\\n[EXT]\\nsubjectAltName=DNS:localhost\\nkeyUsage=digitalSignature\\nextendedKeyUsage=serverAuth\")\n```\n\n![generating a certificate](/images/posts/ssl-localhost/generate-cert.png)\n\nI placed the generated certificate and key file into a folder named ssl in my documents root. However, as [this issue](https://github.com/jekyll/jekyll/issues/5046) points out, Jekyll's SSL support expects the certificate and key to be inside the site's files. That makes sense, and you could easily just place them there if you like. Since I have a number of projects that would potentially use the same certificate, I didn't do that and instead created a [symlink](http://osxdaily.com/2015/08/06/make-symbolic-links-command-line-mac-os-x/) to the ssl folder in Documents from within the project root.\n\n```bash\nln -s /Users/brinaldi/Documents/ssl /Users/brinaldi/Documents/projects/remotesynth.github.io/ssl\n```\n\nAs a side note, you'll want to make sure you don't check this symlink in with your project, so you may want to add it to your .gitignore.\n\nNow you can launch the Jekyll server specifying the certificate and key locations using the symlink.\n\n```bash\njekyll serve --ssl-key ssl/localhost.key --ssl-cert ssl/localhost.crt\n```\n\nOf course, you'll need to go through the process I discussed earlier to avoid the security warning in Chrome. Drag the certificate into Keychain Access, click on it and then set the \"Secure Sockets Layer (SSL)\" setting to \"Always Trust.\"\n\n![trusting the localhost certificate](/images/posts/ssl-localhost/localhost-cert.png)\n\nNow you'll get the \"Secure\" icon.\n\n![secure localhost](/images/posts/ssl-localhost/secure.png)\n\n## SSL with localhost using ngrok\n\nThere are a number of other scenarios that I personally run into where I may potentially need to test SSL locally.  For example, Hugo, the other static site server I build locally, does not support SSL via its built-in web server. Or I also still occasionally work on a Wordpress site, which involve going through a [long list of instructions to update the Apache config](https://gist.github.com/jonathantneal/774e4b0b3d4d739cbc53).\n\nA quick and easy solution to this is to use a service like [ngrok](https://ngrok.com/). For basic local testing, the free account should suffice, but it is a paid service if you are looking for more options.\n\nThe first step, of course, is to [download ngrok](https://ngrok.com/download). Once you run it, you’ll need to connect it to your ngrok account – the tool will walk you through the process. I find it easier to add ngrok to my PATH variable as well so that I can access it via the command line from anywhere.\n\nOnce you are all set up (and assuming you have it on your PATH), you can launch the HTTP port forwarding service. For example, to port forward my built-in Hugo server (which, by default, uses port 1313), I just use the following:\n\n```bash\nngrok http 1313\n```\n\nNow I can access the site running locally using SSL via the provided URLs.\n\n![ngrok](/images/posts/ssl-localhost/ngrok.png)\n\nIf you're looking for a quick and easy way to test SSL locally, and are ok with signing up for an ngrok account, then this is definitely the simplest option."},{"slug":"running-technical-conferences","category":"blog","title":"Running Great Technical Conferences","description":"What makes a great technical conference? I share my thoughts.","tags":["conferences"],"body":"\nAs some readers may know, for five years I ran a small (about 350 people) conference here in Boston. Originally called Flex Camp Boston (and obviously focused on Flex), it was renamed RIA Unleashed and subsequently [Web Unleashed](http://fitc.ca/event/webu14/). The event still exists, run by FITC and occurring this September in Toronto.\n\nI loved running this event, and generally enjoy running events overall. This is why I was interested in reading [How To Plan And Run A Great Conference Experience](http://www.smashingmagazine.com/2014/08/15/plan-and-run-a-great-conference/) by Zach Inglis. It’s a very good article and you should definitely read it if you have interest in the topic. However, I had several points I thought needed adding and one I disagreed with. Much of this was mentioned in my [comment](http://www.smashingmagazine.com/2014/08/15/plan-and-run-a-great-conference/#comment-1220564) there but not I’ve edited it and amended it a bit.<!--more-->\n\n1. **On paying speakers** - One complication I came across (at least for US based conferences) was paying international speakers. There may be legal/tax laws that complicate paying international speakers (especially over certain dollar amounts), and this may vary from country to country, depending on where you are running your event. I don’t know the specifics but it’s worth noting.\n\n1. **Promotion** - In my experience, getting the word out was the hardest part of running any event. It’s common for first time organizers to think they can rely on high profile speakers to get out and promote your event, but they are usually mistaken (nothing against the speakers as I’ve been one many times). Promoting the event required a lot of research on things like relevant user groups or mailing lists and the use of targeted discounts (I used codes) to figure out which avenues worked best and double-down on them.\n\n1. **WiFi, WiFi, WiFi** - It’s so hard to get this right (because you are often at the mercy of the venue or vendors) but so important for a technical conference. Complaining about WiFi at tech conferences is like complaining about the weather, everyone does it from time to time. It never seems to be perfect, but pay close attention to this as it can really ruin the experience if your WiFi is unusable by a large portion of your audience.\n\n1. **Expect to lose money?** - The author states that you should and it is the one area I disagree with. I nailed down sponsors to cover the guaranteed costs from day one - before the conference was even announced. I learned quickly (an;d through trial and error) where you can cut costs and minimize risk. Things like find out what the minimum guarantees are to secure your preferred venue and only guarantee that (they can always up food or other expenses but they will never lower them once you sign); and plan on a range of 10-20% no shows (regardless of how much you charge - for free events this is much higher) and plan food and swag accordingly (you’ll learn your percentage range over time and this can be useful even to carefully oversell seats, which can really improve profitability).\n   \n   The point is, with careful planning, this doesn’t have to be a money loser. I always had the expectation that I would not make money but I also was not going to lose money (not including time spent, obviously). Organizers who lose money are less likely to run the event again, which, in and of itself, does a disservice to their attendees.\n   \n1. **Be prepared to be scared** - My first year I sold out quickly. However, this is not necessarily the norm (and wasn’t in subsequent years). In fact, a majority of tickets will be sold during the last 2-3 weeks. A month before, you may be scared out of your mind that the event will be a failure only to find that you sold out or hit your targets in the end. This became a pattern every year after the first and is something I have confirmed with many conference organizers.\n\n    However, you cannot be reactive, relying on last minute promotions to salvage things. Start any big promotional push early enough that it can have an impact in those final two weeks because, most likely, any promotion you start in the last two weeks doesn’t have enough time to get the traction it needs to succeed. (A side note on this topic, it seems that many people make the decision to attend early but wait until the last minute to make purchases - I’ve done this many times myself, and can explain why last minute promotions don’t have a great impact).\n\nIf you’ve run an event and have tips and opinions to share, I encourage you to comment on the [article](http://www.smashingmagazine.com/2014/08/15/plan-and-run-a-great-conference/)."},{"slug":"running-virtual-events","category":"blog","title":"Tips for Running Virtual Meetups and Events","description":"I share tips and advice from my experiences running online meetups, workshops and events.","tags":["general"],"body":"\nThe spread of the Coronavirus has caused a lot of events to cancel and has forced event and meetup organizers to consider moving their events online. But many of the skills and tools that people use to run IRL events don't easily translate to online events. In addition, there are a myriad of options out there to host your event, but each has costs and/or limitations.\n\nAs it turns out, I have been running online trainings and meetups for about 2.5 years via my [CFE.dev](https://cfe.dev/) site. I most frequently run a monthly virtual meetup with one or two speakers discussing a developer-focused topic, but I have also run various virtual trainings and even a [full day online JavaScript event](https://cfe.dev/events/knowjs-2018/) back in 2018.\n\nIn this post, I wanted to share what I've learned over those years. If you're thinking of hosting online meetups or events, hopefully my experiences will help guide you. \n\n## Choosing Your Software\n\nThis is usually the first issue folks face - where can I host my online event? I've looked at a number of options. I'll be up-front and say that what works best may depend on your specific event's needs. Part of that may depend on budget, part of that may depend on the need for registration or payment, or it may depend on some other factors entirely. There are so many options out there, I can't cover them all.\n\nOne option is to live stream via many of the existing social sites like YouTube, Facebook, Twitch and even LinkedIn. Those options are generally free. However, some require that the user have an account with that social network and, as far as I am aware, they don't offer options for pre-registration or payment. You also don't have access to emails or other information about who attended. The benefit is that you can leverage the social network for reach.\n\nOnce you get past the social networks, most of the options I am aware of cost money. This can be an issue for a meetup (who is already typically shelling out Meetup.com fees) or other free events. For instance, Zoom is free for under 100 participants but scales up in cost after that. There are a myriad of other similar options. Some things you might consider are:\n\n* What features does the software have to support attendee participation?\n* Do I need to support paid attendance?\n* Am I ok with attendees needing to install software to attend?\n* How many attendees do I need to support? If I reach or exceed attendees in my plan, how is that handled?\n* Do I want the ability to multi-stream to other platforms like YouTube and Facebook?\n* How does the software manage playbacks? Can I have access to the the raw video if I want it?\n\nI have chosen to use a system called [Crowdcast](https://www.crowdcast.io/) for the past 2.5 years. It has generally served me very well. It has live chat and Q&A features that have worked pretty well (often the chat is quite active during meetups). It does support paid events. Attendees don't need to install anything (and speakers only need the Chrome extension). It does allow me to go over plan, with a small charge per attendee over that. It does support multi-streams though I've often had issues getting this to work properly with YouTube. Playbacks are available immediately following the sessions via their service and I can download the raw video recording as well.\n\nCrowdcast has worked well for me, but do your research and find the platform that best fits your needs.\n\n## Scheduling\n\nTiming your event can be tough because, in my experience, some typical times and lengths for events may work less well in a virtual setting. For instance, an evening event (often with food provided) works well for many IRL meetups, but that timing works far less well for a virtual meetup. Once a person is in a virtual setting, it can be much tougher to avoid distractions including meal preparation and family obligations.\n\nI have found that daytime events seem to work better online. I tend to favor lunchtime, but factor in whether you need to accommodate different time zones. While some people may still find it tough to get away from work responsibilities or distractions, there is far less time commitment for an online meetup than an IRL one. This is because there is no commute, no time required for networking or eating and so on.\n\nIn my experience, it is not a good idea to schedule long events as you would a typical full-day conference. Anything over 2 hours should be broken up with a break. I don't suggest scheduling more than 4 hours in a single day. Conferences have opportunities to stand up, chat with people, grab a drink, etc. These things break up the monotony of sitting for a full-day watching sessions. It can still be tough to sit through a full day and yet online events are that much more difficult. If you are planning a full or multi-day conference, consider breaking it up into more but shorter days.\n\n## Registrations\n\nAnyone who has run an IRL conference or meetup knows that there is a last minute surge for registrations. For conferences it tends to occur 2-3 weeks prior. For meetups, it's typically 2-3 days prior. These may seem last minute, but, for online events, the surge can happen as little as 20-30 before an event.\n\nFor my meetups, I tend to get a burst of people in the final 10 minutes prior and even within the first 5-10 minutes of the event. Even for an online conference, the surge may happen only hours prior. Keep in mind, no one needs to schedule travel or manage a commute, so the decision to attend can be made at the very last second. So don't get overly discouraged if sign ups are weak in the weeks before your event.\n\nThis can make virtual events tough to gauge as you don't know how successful they may be until the last moment. So, adjust how you market your event. Rather than weeks before, plan your big push in the days, if not the day, before the event. Continue this right up to the start of the event and even try to draw people in once the event started.\n\n## Shipping Materials\n\nThis is something that probably only applies to a small fraction of virtual events and mostly to virtual workshops, but it is something that can go very badly if not planned properly. Trust me, I speak from experience. Basically, if you have a virtual meetup that requires the attendees have some sort of materials that you'll need to provide to them, ensure that you plan ahead if shipping is required. Domestic shipping in the US can be done usually the same week, but international shipping can be a mess.\n\nThe best solution if your virtual workshop requires materials to be shipped is to ship them out as folks register so as to prevent any backlog. Set a cutoff of two-to-three weeks for any sort of guaranteed arrival (I can say that 2 weeks is probably still cutting it close for international shipments). And be prepared to address issues as there are factors out of your control that may cause individual attendees not to get their materials in time.\n\n## Test Every Time\n\nRegardless of how foolproof whatever system you choose to host on may seem, be sure to set aside time to test with each and every speaker, each and every time. For my meetups, I generally arrive in the green room 30 minutes prior to allow speakers time to come and test the screen share, video and audio. This works but has caused a couple of close calls. Preferably, especially if you will have a number of consecutive speakers, set up time with each individual prior to your event to walk through testing and give them a rundown of the system.\n\nIf you are going to host multiple speakers/sessions back-to-back across multiple recorded sessions, be sure to arrange a test of handling the transitions. Most online conference software allows you to create private events. This can be a useful way to test scenarios. Invite a couple friends or speakers and walk through how you can handle transitioning between multiple sessions. The last thing you want is to lose your attendees in the middle of an event due to a mistake on your part.\n\nAlso, remain on, watching and listening to the entire virtual event because even the best test can't anticipate every situation...which leads me to my last point.\n\n## Expect the Unexpected \n\nThis is true for any kind of event planning, but for virtual events, the types of issues tend to be different and equally difficult to plan for. For instance, in 2.5 years, I had speakers have random connectivity loss, very serious family emergencies occur during an event, have their power go out for 2 full hours during a hands-on workshop and more. I've had issues occur on my end as well where I've had to scramble to find someone to monitor the event on my behalf while I went to take care of an urgent situation.\n\nAttendees are generally very understanding of these sorts of unexpected issues. So, don't freak out. Be ready to jump on at any point in the event of an issue, explain the situation and try to address it. It's also very helpful if you have ways outside the software to connect with your speaker, preferably text or phone, but DMs or Slack can work in a crunch.\n\nThat said, have fun. These sorts of issues are rare, but running virtual events can be rewarding. I was a skeptic when I started doing them but I've gotten to see some amazing speakers, learned a ton and helped a lot of other people learn as well. That's a win!\n\nAlso, if you are looking to host your online meetup or event, I am available to help host via my [cfe.dev](https://cfe.dev/) site if you'd like or just for advice if you need it. My [DMs are open](https://twitter.com/remotesynth).\n"},{"slug":"serverless-edge-hype","category":"blog","title":"Does the Serverless Edge Live Up to the Hype?","description":"A lot of promises have been made about the serverless edge. Does it meet them?","tags":["serverless"],"body":"\nAs developers, we've become accustomed to broken promises. The more hype that surrounds a technology, the more likely we are to find the end result doesn't quite live up to its initial promises. And, let's be honest, serverless edge technologies have gotten a lot of hype lately. Here's just a sampling.\n\n![serverless edge headlines](/images/posts/edge-hype.png)\n\nI wouldn't blame you for being skeptical of these claims, as serverless arguably has a history of broken promises. Corey Quinn, a very well known expert on AWS and serverless, [wrote in November 2021](https://www.lastweekinaws.com/blog/the-unfulfilled-promise-of-serverless/):\n\n> Say what you will about serverless, it’s failed to live up to its promise and hasn’t proved to be particularly lucrative for anybody.\n\nHe went on to illustrate three key areas where serverless has failed to meet lofty expectations. Personally, while I'm a big believer in serverless in general, I won't argue that in many cases it hasn't lived up to the hype.\n\n## Jamstack gets edgy\n\nCDNs (Content Delivery Networks) have been around for a long time, but the first time I personally encountered the concept of deploying an actual application to a CDN was via the Jamstack. The idea was that each user would get the static assets for the site from the CDN closest to them, reducing latency and making your app faster.\n\nThis worked great when Jamstack was heavily focused on pre-rendered (i.e. static) assets, but the equation became more complex when your application made a lot of data calls. [As Chris Coyier points out](https://chriscoyier.net/2022/05/04/it-doesnt-much-matter-how-cdny-your-jamstack-site-is-if-everything-important-happens-from-a-single-origin-server-edge-functions-are-probably-part-of-the-solution/), your data is probably still tied to a specific location or region.\n\n> But don’t fool yourself into thinking you’re really a CDN-hosted site and you’re being as fast as you can be worldwide. Your Australian users are still hitting some server in metaphorical-Oregon (US-WEST-2 or whatever) for the data-that-matters and it will be slow.\n\nChris goes on to talk about how edge functions may help to resolve this problem. It is core to the promise of edge functions, so let's review.\n\n### Edge Function Basics\n\nA typical web application would get deployed to a single server region. For example, in AWS terms, I might choose to deploy my application to us-east-1. Every user that connects to that application would then receive it from that location, regardless of where in the world they are connecting from.\n\n![application deployed to a single region](/images/posts/region.jpg)\n\nJamstack moved the assets up close to the user at the CDN level, but the serverless functions and data would still typically be deployed to a single server region. In this case, API calls made from the frontend still need to traverse the distance to the server region where the functions and data are deployed. This means that the static assets load fast, but latency still exists populating the page data.\n\n![a typical jamstack site](/images/posts/jamstack.jpg)\n\nEdge functions aim to solve this problem, by bringing some (or all) of the backend processing up to the CDN level in proximity to the user. So it's no longer just static assets on the CDN but actual compute is being performed there as well. In an ideal world, it might look something like this image from the [Remix blog](https://remix.run/blog/remix-and-the-edge), where every user request has static assets fulfilled by the CDN and backend content and data also fulfilled by the CDN via edge functions.\n\n![ideal edge solution architecture](/images/posts/edge-remix.png)\n\nSource: https://remix.run/blog/remix-and-the-edge\n\n## Does the edge live up to its promises?\n\nHow does serverless edge live up to this promise of reduced latency? What about other promises about the edge that you may have read? Let's dig into these.\n\n### Promise: Reduced latency\n\n* ✅ Backend calls go to the CDN geographically closest to the user.\n* 🤔 Geographic latency may not be the critical issue in your site's performance\n* ❌ Your database or other backend APIs may still be region locked\n\nSo the biggest selling point of edge functions is that they will automatically improve the performance of your app simply by reducing the latency of any backend API or server-side rendering (SSR) calls. They do actually achieve that promise in terms of the actual function call, which will now hit the CDN closest to the end user rather than a function deployed to a single region that may be across the globe.\n\nThe first thing to consider is that, unless you are building games or IoT, latency caused by distance, while not worth ignoring, may not be the critical aspect to improving your site's performance. Things like reducing the JavaScript you send to the client, improving image size and compression or removing third-party scripts are all other optimizations that may gain you more traction.\n\nI'm not trying to dismiss the cost of geographic latency as it can add up. As [this article points out](https://www.snapt.net/blog/how-geographic-distance-affects-latency), data going from US West to Central Asia, for example, could take up to a few seconds. So this is a legitimate selling point that edge functions can live up to *when used properly*.\n\nWhat do I mean by \"used properly\"? Well that gets at the biggest potential drawback to edge functions when it comes to reducing latency: if your edge function needs data, that data may still be region locked.\n\n![the edge and your data](/images/posts/batman.png)\n\nFor example, if your edge function calls an API or database and that API is region locked, you may not see the performance gains you are expecting. This is why it is critical that, when thinking about what processing you are moving to the edge, you also think about where the data this processing depends on exists. There are some solutions to these (ex. edge KVs, databases and caching), but these may involve larger changes to your application than you anticipated.\n\nWhich brings us to promise number two.\n\n### Promise: It's easy\n\n* ✅ It's just JavaScript, so there's a low barrier to entry and lots of framework support\n* 🤔 Runtimes are often not Node-based, so you may not have all your favorite tools\n* ❌ Every provider is unique and choosing one isn't easy\n\nAnother promise you may hear about edge functions is that it's super easy to get started – and there's definitely truth to this. First of all, on nearly every provider, you can just use JavaScript, while some providers support other languages as well. There are also a growing number of frameworks and tools that can help you build for the edge.\n\nYou need to be aware that the edge runtimes are mostly not Node-based, so you can't always bring your npm-based tools with you. If you are trying to migrate existing code to the edge and that code relies on npm tooling, this may require a more extensive refactoring than you may have expected. Plus, most providers have different runtimes and APIs, so there's definitely a learning curve as you get aquainted with their offering and quirks. This also means that your code is likely not easily portable across providers.\n\n### Promise: Additional capabilities\n\n* ✅ Edge functions can intercept the request or response \n* 🤔 Um...actually, this is just cool\n* ❌ I got nuthin\n\nWhere I get more excited about edge functions from a developer standpoint is where it can actually allow me to do things that previously were much more difficult. Edge functions offer the capability of intercepting the request and response, which can be incredibly powerful.\n\nYour edge function - or middleware as some frameworks call it - will be called when the request comes in before it hits the origin server. It can modify that request, redirect it - so no need for slower server-side or client-side redirects or you can even handle access and authentication at this point.\n\n![intercepting the request](/images/posts/edge-functions-request.jpg)\n\nThe edge function can even fulfill the response itself. For example, if you have static assets like HTML, CSS, images and more cached on the edge, you can simply respond without hitting the origin server.\n\n![fulfilling the response at the edge](/images/posts/edge-functions-request-response.jpg)\n\nIf you haven't redirected or fulfilled the request, it continues to the origin server to be fulfilled.\n\n![request goes to the origin server](/images/posts/edge-functions-origin-server.jpg)\n\nWhen that response comes back, your edge function can intercept it again. In this case, you can do things like modify the response. For example, you might add headers that have user specific information or, in most cases, you can even modify the HTML of the response.\n\n![intercepting the response](/images/posts/edge-functions-request-completed.jpg)\n\nThis enables you to do some really cool things, like make a dynamic, user-specific response based upon a completely static HTML asset or modify the response for A/B testing at the edge with no flash of content. For some examples, check out Salma Alam-Naylor's [post on using Netlify's edge functions to add personalization](https://whitep4nth3r.com/blog/add-personalization-to-static-html-with-edge-functions-no-browser-javascript/). \n\n## What can I do with edge serverless?\n\nNow that we've covered some of the key benefits and limitations of the edge, here are some of the things you might consider doing using edge functions: \n\n* **A/B Testing** – You can replace out HTML content for A/B tests without any flash of rendering.\n* **Updating/Modifying/Custom HTTP headers** – You can add custom http headers that might be used for adding CORS to certain requests or control access to content.\n* **Conditional routing** – You can route user's to a new location for instance if they are not authenticated or route them to the appropriate localized version of the site.\n* **SEO** – You can serve a version of the page that is optimized for being read by search crawlers when they are detected.\n* **User authentication/authorization** – You can handle validating authentication and authorization at the edge and redirecting or limiting access if necessary.\n* **IoT/Gaming** – Latency is critical for IoT or gaming applications, and edge functions can help remove that latency.\n* **Personalization** – You can personalize the output of the page based upon user information. For example, you can show the user's login state without any flash of rendering. \n* **Compliance** – You can serve up different versions of the page depending on the user location to meet location specific compliance issues. For example, you can show cookie acceptance to users specifically in the EU.\n\nThese are just a handful of ideas. There's plenty more possibilities with serverless edge functions. While I have discussed some areas that edge functions may not live up to the promises that you've been hearing or reading about, I am definitely a believer in their capabilities and think they will become an important part of modern application architecture going forward.\n\nSo how can you get started? That'll be the topic for my next post."},{"slug":"should-I-build-it","category":"blog","title":"Should I Build It?","description":"A look at the ethical dilemmas facing today's developers.","tags":["general"],"body":"\nThose of us who began our coding career in the late 90's grew comfortable asking ourselves \"Can I build it?\" Programming, especially for the web, was defined by its limitations back then. What we wanted to build and what we could feasibly create were often light years apart.\n\nToday, there are few limits to what we can build, but also a growing consensus that \"[the internet is broken](https://www.washingtonpost.com/opinions/congress-knows-the-internet-is-broken-its-time-to-start-fixing-it/2019/06/04/accc84b4-86fe-11e9-98c1-e945ae5db8fb_story.html?noredirect=on&utm_term=.afbc35cebc6f)\" (the internet, of course, being the backbone of so many of these technologies). This presents an entirely different dilemma. It's no longer a matter of whether it can be built but whether it should be built.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A brief history of the tech industry 1999-present:<br><br>1999 - We&#39;re going to change the world!<br>2009 - We&#39;re changing the world!<br>2019 - We changed the world, but we don&#39;t think we like the result.</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1096409737263005698?ref_src=twsrc%5Etfw\">February 15, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n## Our Tools Can Be Misused\n\nWe know that the things we build can be misused largely because so many of the things we've built have already been arguably misused. But is that experience reflected in the decision-making of most developers? A [recent study by NC State](https://news.ncsu.edu/2018/10/software-developer-ethics/) says no. It seems to show that awareness of the [Association for Computer Machinery Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics) had no impact on the way participants responded to certain real-world ethical situations faced by developers. And, the fact of the matter is, very few of us (including me) have ever heard of that or any other code of ethics for our industry.\n\n> Technological professionals are the first, and last, lines of defense against the misuse of technology.\n\nThe above quote is from [Cherri M. Pancake](http://theconversation.com/programmers-need-ethics-when-designing-the-technologies-that-influence-peoples-lives-100802) when discussing why the Association for Computing Machinery (of which she is currently serving a two year term as president) decided to update their code of ethics. I think she has it right in that developers today need to think about the potential impact of what they are creating but also how the things they have created are actually being used - i.e. it's both forward and backward looking.\n\nLet's think about a simple example. 10 years ago, developers were building simple face tracking tools for the web using Flash. I remember seeing an incredible demo at a conference that had all kinds of fun with this technology. Should we have foreseen that this same technology would eventually enable the modern-day [surveillance state](https://en.m.wikipedia.org/wiki/Mass_surveillance)? And what is our obligation now that we know the tools we helped create are being used in morally questionable ways?\n\n## No Easy Answers\n\nI' not writing this post because I have any answers to those questions. In many ways, I am insulated in my role from some of the more difficult moral dilemmas...or, at least, like to believe I am. I do think about them a lot. This is especially true given calls to break up big tech, which, regardless of how effective you think it will be, only addresses the problem in hindsight - as in, it is in part an attempt to repair the fact that the things we helped build were misused but doesn't help address the issue of the things we are currently building (which is what the code of ethics is hoping to do).\n\nAt the risk of dragging you down the rabbit hole with me, what are your thoughts on the ethical considerations that developers face? Have you faced an ethical dilemma? How did you handle it?"},{"slug":"stack-overflow-developer-survey","category":"blog","title":"Thoughts on the Stack Overflow Developer Survey Results","description":"Lots of interesting details to unpack","tags":["general"],"body":"\nStackOverflow released the results of its [2017 Developer Survey](https://stackoverflow.com/insights/survey/2017). The survey covers a ton of ground including where developers work, how they feel about their pay, which languages and frameworks they like or dislike and much more. I am not going to go into all of the results but wanted to share some thoughts that I had while reading the results.\n\n## A Significant Number of Developers are Relative New to the Job\n\nTaking a look at the number of years coding professionally, it becomes clear that a significant portion of developers are very new to the job.\n\n![Years Coding Professionally](/images/posts/so_survey_years_coding.png)\n\nJust over 20% of all developers in the survey have been working as a developer for less than 2 years. Over 40% have less than 4 years professional experience. It is possible that this means that there is a lot of demand for beginner/intermediate content and tools to help developers learn new skills as, in my experience, this is often a bigger focus early in a developer's career (obviously we can never stop learning, but often the types of things we tend to focus on learning differ as we get further in our careers).\n\nWhile the survey doesn't specifically get into age, it's reasonable (in my opinion) to also  infer that this 40% tilts younger as those starting out new careers tend to be younger. Why do I care? Well, mostly because I focus on content and I've tended to find that developers with more experience, like myself (aka _old_), tend to prefer written content, while younger developers tend to enjoy learning via interactive and/or video content.\n\n## The Results are Heavily Tilted Towards Web Developers\n\nOne thing that we need to consider when analyzing these results is that it is primarily a survey of web developers - even if it isn't entirely pitched that way.\n\n![developer type](/images/posts/so_survey_dev_type.png)\n\nYes, over 72% of respondents identify as web developers even though Stack Overflow would not be exclusively a web-development-focused site. I only mention this as it is probably something to take into consideration when reviewing some of the \"headline stats\" like which are the [most popular technologies](https://stackoverflow.com/insights/survey/2017#technology) or which are the most [loved and dreaded](https://stackoverflow.com/insights/survey/2017#most-loved-dreaded-and-wanted). For instance, it's important to have in mind when you read observations like [this one](https://dev.to/walker/diving-into-the-results-of-the-2017-stack-overflow-developer-survey) on the survey - it doesn't in any way negate the perspective at all, just is a nuance to consider on things like shifting language priorities.\n\n## Not US-centric\n\nOne of the things that stood out to me was the geographical makeup of the respondents. Given StackOverlow's gloabl reach, I suppose that shouldn't be a surprise. However, I have seen many developer surveys, and they all tend to get a large majority of their responses from North America, specifically the US.\n\n![geographic region of respondents](/images/posts/so_survey_geography.png)\n\nWhat’s interesting to me about the above is the way they break out the demographics by region where Europe is split into numerous regions. I only note that because typically I see surveys either lump the UK and Europe together, or split them up, but rarely have 4 regions representing the UK and Europe. Also interesting that if you take it as a whole, Europe and the UK represent over 20k of the 51k responses to North America's 13k and Asia’s 11k. So pretty widely distributed, and nowhere near as North-America-centric as other surveys I've seen.\n\n## UGH!\n\nThe survey seems to ask people for their racial/ethnic background as a combination question (I only mention because as someone who identifies as hispanic, it does not signify race - which could be hispanic white or black for instance). Anyway, while men in general don't look great on the topic of diversity, white men did themselves no favors in this survey by being the group who apparently cares the least about diversity (by a fairly substantial margin even).\n\n![who values diversity](/images/posts/so_survey_diversity.png)\n\nNow this leaves out those who \"somewhat agree\" but c'mon (plus, arguably, \"somewhat agree\" in this case is the equivalent of indifferent).\n\nStack Overflow's commentary notes that the number of people who somewhat agree, agree or strongly agree that diversity is important went up significantly. However, we still have 11% who either strongly disagree or disagree that it is important on what seems like an obvious, easy \"agree.\" No one is even asking you to _do anything_ about it, other than say it has value in a generally meaningless survey and even that is too much to ask...ugh!"},{"slug":"stack-overflow-survey-2018","category":"blog","title":"Some Things You May Have Missed in the Stack Overflow Developer Survey","description":"Let's dig into the data a little bit.","tags":["general"],"body":"\nYeah, I know what you are thinking, \"The [Stack Overflow Survey](https://insights.stackoverflow.com/survey/2018/) was last month's news!\" True. But there was so much data to digest in there that, honestly, it takes a lot of time to process. This meant that many of the early posts focused on headline info, like the [most loved/dreaded/wanted languages](https://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted). Now that I've had a little bit of time to sift through all the information, I wanted to share some things that struck me as important, even if they didn't necessarily catch the biggest headlines.\n\nI should note that in all cases below, when I refer to developers, I mean respondents. Obviously, even though over 100,000 people took the survey, it probably has some bias due to the fact that it is [heavily tilted towards at least somewhat regular StackOverflow users](https://insights.stackoverflow.com/survey/2018/#community-visiting-stack-overflow).\n\n## We are not diverse - like, at all!\n\nThe demographics section overall was disappointing overall. This isn't helped by the fact that a substantial number of developers [don't think diversity is a priority](https://insights.stackoverflow.com/survey/2018/#work-how-do-developers-assess-potential-jobs) (including both [men and, surprisingly, women](https://insights.stackoverflow.com/survey/2018/#work-differences-in-assessing-jobs-by-gender). The net result is that the prototypical developer is a white, male under the age of 35 with no children.\n\n### We are almost all men\n\nDevelopers are, sadly, a very homogenous group - almost [93% male](https://insights.stackoverflow.com/survey/2018/#developer-profile-gender), over [74% white](https://insights.stackoverflow.com/survey/2018/#developer-profile-race-and-ethnicity), and over [93% straight](https://insights.stackoverflow.com/survey/2018/#developer-profile-sexual-orientation). Compare that to the general population that is obviously slightly over 50% female.\n\nAnd all the diversity efforts to bring more women into the industry doesn't appear to be changing things in any real noticeable fashion. Looking at just students, the numbers shift by less than a percent. The only potential bright spot is that [women represent a growing share of developers with less than 5 years experience](https://insights.stackoverflow.com/survey/2018/#developer-profile-experience-and-gender).\n\n### We are mostly white\n\nThe racial breakdown is especially disappointing since, <strike>as best I can guesstimate, only a [bit more than 50% of the respondents are from North America and Europe](https://insights.stackoverflow.com/survey/2018/#geography)</strike> [63% of the respondents are from North America and Europe](https://insights.stackoverflow.com/survey/2018/#methodology). Nonetheless, over 74% of all developers identify as white or of European descent. The geographic breakdown leads one the conclusion that, in North America and Europe, the breakdown would be significantly more white than the overall percentage. This bears out in the commentary, which notes that \"7.4% of professional developers in the United States identified as black, Hispanic or Latino/Latina, or Native American\" compared to over 30% of all respondents. On a positive note, this number improves slightly when reducing to only students - so change is happening in this area, but very slowly.\n\n### We are mostly young, without children\n\nAlmost [73% of developers are under the age of 35](https://insights.stackoverflow.com/survey/2018/#developer-profile-age). Personally, I am on the cusp of falling into the 45 or older category, which represents slightly less than 7% of developers - and I can attest to my age already coming up at most every developer event I have attended over the past 5 years. Slightly more than [71% have no kids](https://insights.stackoverflow.com/survey/2018/#developer-profile-children-and-other-dependents), which matches pretty closely with the under 35 category.\n\n## Web technologies rule everything...\n\n### ..but the paycheck \n\nJavaScript, HTML and CSS rule the [top languages used by developers](https://insights.stackoverflow.com/survey/2018/#technology-programming-scripting-and-markup-languages) making up more than two-thirds of respondents, with JavaScript being the most prevalent of the three (the numbers even go up slightly for all three when filtered for just professional developers). Also, a [combined 64% are using either Angular or React](https://insights.stackoverflow.com/survey/2018/#technology-frameworks-libraries-and-tools) (with Angular showing up as modestly bigger) and almost 50% say they are using Node.js.\n\nHowever, popularity doesn't translate into pay. Web technologies are at the [bottom of the pay scale](https://insights.stackoverflow.com/survey/2018/#technology-what-languages-are-associated-with-the-highest-salaries-worldwide) (both globally and in the US where only JavaScript makes the list at second to last). If you want to make money, it appears to be in the less widely used back-end languages like Erlang, Scala, Ocaml and F#. Front-end developer as a title sits somewhere in the middle of the [salary stack](https://insights.stackoverflow.com/survey/2018/#salary) overall.\n\n### Mobile is still a (large) niche\n\nThe [native mobile contingent](https://insights.stackoverflow.com/survey/2018/#technology-programming-scripting-and-markup-languages) wasn't quite as large as I expected. Swift is at 8.3% and Objective-C is still at 7.3%, which, when keeping in mind that this category allows overlap, means that very likely less than 10% overall are doing iOS development (which would fit with the [XCode numbers](https://insights.stackoverflow.com/survey/2018/#technology-most-popular-development-environments) which sit around only 10% and the [correlated technologies](https://insights.stackoverflow.com/survey/2018/#correlated-technologies) section shows there is indeed some overlap), although 15% did say that they are developing for iOS as a platform overall. Android isn't broken out of Java in the languages section, but the [IDE section](https://insights.stackoverflow.com/survey/2018/#technology-most-popular-development-environments) shows Android Studio at 19.3% and platforms show it at 29%, which is a bit unusual given the dearth of native iOS developers. Since well over 50% of respondents doing mobile were doing Android, I wonder if there might be a bit of a Java/Android bias to the StackOverflow audience.\n\nOther mobile-focused development technologies were also relatively small, with Xamarin and Cordova showing a combined 15% (since I'd assume minimal overlap between the two). Tools like React Native or NativeScript did not make the list. Unfortunately, for Xamarin and Cordova is that they also both [top the most dreaded tools/frameworks list](https://insights.stackoverflow.com/survey/2018/#technology-most-loved-dreaded-and-wanted-languages).\n\n### Back-end development is all over the place\n\nJava is still the king when it comes to back-end development, but Python and C# are not that far behind. A lot of people (31%) still do PHP, and it isn't just Wordpress (less than 16% use WordPress). Significant numbers of developers do C and/or C++ while small but not insignificant percentages do Ruby and Go. The numbers would indicate that many developers work with multiple back-end languages.\n\n### Rust and Kotlin developers really love their languages\n\nRust and Kotlin developers are clearly a small but passionate group. Rust didn't even make the language list and Kotlin came in at only 4.5%, but they significantly outpace most ever language in terms of the developers who use it [wanting to continue working with it](https://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted). Rust knowledge is fairly high up on the [global pay scale](https://insights.stackoverflow.com/survey/2018/#technology-what-languages-are-associated-with-the-highest-salaries-worldwide), so perhaps that is a factor.\n\nOverall, developers generally want to learn Python or JavaScript/TypeScript and want to get away from some older .NET technologies in particular. However, both Python and JavaScript are among the lowest paying languages.\n\n## Developers generally like their jobs\n\nThis is a [bright spot](https://insights.stackoverflow.com/survey/2018/#work-how-do-developers-feel-about-their-careers-and-jobs). Over 70% of developers are at least slightly satisfied with their career with a majority (55%) moderately or extremely satisfied. Those numbers are essentially unchanged in terms of satisfaction with their current job. However, a significant number of developers [changed their job in the last year](https://insights.stackoverflow.com/survey/2018/#work-how-long-ago-did-developers-last-change-jobs) and a majority (56%) within the last two years. So, perhaps that job satisfaction number is ephemeral.\n\nPerhaps part of the reason developers are happy is that the job pays well overall. Even the lowest paid [category in salary by developer type](https://insights.stackoverflow.com/survey/2018/#work-salary-by-developer-type) in the U.S. is paid about $20k more than the [average salary of a person with a four-year college degree](https://smartasset.com/retirement/the-average-salary-by-education-level) even though just about [75% of professional developers have a college degree](https://insights.stackoverflow.com/survey/2018/#developer-profile-educational-attainment).\n"},{"slug":"stackoverflow-survey","category":"blog","title":"Some Things You May Have Missed in the Stack Overflow Developer Survey (2019 Edition)","description":"A quick look at some highlights from the latest edition of StackOverflow's survey","tags":["general","web development"],"body":"\nWith over 90,000 responses, the Stack Overflow Developer Survey is the largest survey targeting the developer community. This doesn't mean the results are perfectly reflective of the developer community (something, StackOverflow themselves acknowledge), but they are a useful metric to gauge certain aspects of the community - from changes to the make up of the community itself to interests and job focus.\n\nLast year, I took a look at some items that [stood out to me](https://dev.to/remotesynth/some-things-you-may-have-missed-in-the-stack-overflow-developer-survey-40lo), and following the recent release of [this year's results](https://insights.stackoverflow.com/survey/2019#developer-profile-_-social-media-use), I'd like to do the same.\n\nPlease note that these are only the items that struck me. I invite you to share your own insights in the comments or in a post of your own.\n\n## Some Changes in Methodology This Year\n\nStackOverflow has received its fair share of criticism over the years regarding its community. Last year they started to make a public effort to [respond to those criticisms](https://stackoverflow.blog/2018/04/26/stack-overflow-isnt-very-welcoming-its-time-for-that-to-change/). I'm not here to judge the success or failure of those efforts on a larger scale, but it did impact the way they handled the survey results.\n\nFirstly, they acknowledge the issue up front:\n\n> Despite our survey’s broad reach and capacity for informing valuable conclusions, we acknowledge that our results don’t represent everyone in the developer community evenly. We have further work to do to make Stack Overflow the welcoming, inclusive, and diverse platform we want it to be, and this is reflected in our survey sample.\n\nSecondly, they decided to release weighted results that attempt to correct the demographic skew. Thus you get results like the unweighted [developer roles](https://insights.stackoverflow.com/survey/2019#developer-roles) in the United states...\n\n![developer type unweighted](/images/posts/stackoverflow2019/developer-type-unweighted.png)\n\n...and weighted:\n\n![developer type weighted](/images/posts/stackoverflow2019/developer-type-weighted.png)\n\nIn some cases, the results don't change much but in others it can give interesting insights. For instance, above you'll see some slight changes in the overall percentages of the top 5 items. However, after that, the weighting actually changes the order, with designer moving above both database admin and DevOps, even if the overall percentage change is still relatively small.\n\nA big part of the skew is [gender-related](https://insights.stackoverflow.com/survey/2019#developer-profile-_-gender). Yes, the industry-wide numbers are bad (with [some data](https://www.evia.events/info-women-in-technology) putting women at less than 20% of tech jobs overall and many reports showing those numbers declining) but StackOverflow's responses are over 91% men overall and just 11.7% women even in the US.\n\n![gender makeup](/images/posts/stackoverflow2019/gender.png)\n\n## Whoa! Visual Studio Code!\n\nA whopping 50.7% of all respondents use Visual Studio Code for their [development environment](https://insights.stackoverflow.com/survey/2019#development-environments-and-tools). The next closest is the full Visual Studio at 31.5%.\n\n![developer environments](/images/posts/stackoverflow2019/dev-environments.png)\n\nWhen splitting out web, mobile and SRE/DevOps, the popularity of Visual Studio Code only increases, with mobile being the only category where it just barely doesn't hold the top spot (falling just behind Android Studio but, surprisingly, above XCode).\n\n### Web tech still dominates\n\nThis probably shouldn't come as a huge surprise though, seeing as StackOverflow seems to be [dominated by JavaScript/front-end developers](https://insights.stackoverflow.com/survey/2019#technology-_-programming-scripting-and-markup-languages).\n\n![most popular technologies](/images/posts/stackoverflow2019/technologies.png)\n\nStill, web technologies still sit on the [bottom end of the pay scale](https://insights.stackoverflow.com/survey/2019#technology-_-what-languages-are-associated-with-the-highest-salaries-worldwide), particularly in the United States.\n\n## Most Developers Are Employed By Small Businesses\n\nExcluding self-employed individuals, a full 58.8% of developers on StackOverflow are [working at companies with less than 500 employees](https://insights.stackoverflow.com/survey/2019#work-_-company-size).\n\n![company size](/images/posts/stackoverflow2019/company-size.png)\n\n### And most like their jobs\n\nOver 65% like their [current jobs](https://insights.stackoverflow.com/survey/2019#work-_-how-do-developers-feel-about-their-careers-and-jobs), at least slightly. Even a lot of those who don't necessarily like their current jobs, are still at least somewhat happy with their choice of career - nearly 3/4 of developers are happy with their choice of career.\n\n![job satisfaction](/images/posts/stackoverflow2019/satisfied.png)\n\nPerhaps they are so happy in their jobs because they are not (nor, largely, want to be) managers. 😉\n\n![want to be managers](/images/posts/stackoverflow2019/managers.png)\n\n## PHP Doesn't Pay\n\nWhile Scala, Clojure and Go developers are [paid well regardless of their years of experience](https://insights.stackoverflow.com/survey/2019#work-_-salary-and-experience-by-language), PHP developers are paid the least (and seemingly by a lot) regardless of their experience.\n\n![pay correlated to experience](/images/posts/stackoverflow2019/pay-experience.png)\n\nDespite this, PHP still remains popular, being the [8th most popular language](https://insights.stackoverflow.com/survey/2019#technology-_-programming-scripting-and-markup-languages) at 26.4% of all respondents and still over 25% of professional developers.\n\n## Developers Love Reddit\n\nSocial media is a key part of the roles I've had in DevRel, community management and marketing, so I was interested to see social media usage.\n\n![social media](/images/posts/stackoverflow2019/social-media.png)\n\nThe differences between the all respondents and US respondents is pretty significant. Reddit still wins, by a lot more, but Twitter jumps from 5th to 2nd.\n\n![social media in the US](/images/posts/stackoverflow2019/social-us.png)\n\nA notable absence, though, is Twitch. Perhaps it wasn't included as an option on the survey, which is surprising given the popularity lately of live-coding streams.\n\n## What Struck You?\n\nWhat did you think of the survey? How does it compare to your experience, whether you are a StackOverflow user or not? I'd love to hear different perspectives."},{"slug":"starting-anew","category":"blog","title":"Starting Anew","description":"My blog - starting over from scratch.","tags":["general"],"body":"\nAlmost 10 years ago, on January 1, 2005, I started a blog called Remote Synthesis. The name came from synonyms for \"Cold\" and \"Fusion\" as ColdFusion development was my primary focus back then. A lot has happened in 10 years.<!--more-->\n\nThe blog gained a good deal of popularity during the years that I was working on my popular ColdFusion code generator and posting the ColdFusion Open Source List. It remained somewhat popular during my years working with Flex and running the Flex Camp Boston conference (later RIA Unleashed and now Web Unleashed). Eventually, when joining Adobe, my focus started to drift from that blog to publishing elsewhere - on the Adobe Developer Connection that I was helping to run and other writing responsibilities.\n\nIn 2013, I started a site called [Flippin' Awesome](http://flippinawesome.org) (now part of The Modern Web). While it included the contributions of many authors, including myself, it took most of my free time and effort to keep it going. It became very popular (and still is). I kept trying to blog, but found my focus and interest waning. Compounding this was the fact that my blog ran on a severely outdated version of ColdFusion and old CF-based blogging software and that it looked hideous on mobile.\n\nWhile nearly 10 years of content has some value, most of the content was outdated and I had no intention of fixing this. Thus, I decided it was time for a fresh start...which is what you are looking at. I don't plan to blog frequently, but occassionally. I know my audience will be limited, but...so what?! My audience back in 2005 was 1 - just me."},{"slug":"state-of-js","category":"blog","title":"Thoughts on the State of JS Survey","description":"A look at the latest edition of the largest JavaScript developer survey.","tags":["javascript"],"body":"\nThe [latest State of JS survey results](https://2019.stateofjs.com/) are out. As always, survey results need to be taken with a grain of salt. There is always a bit of [selection bias](https://en.wikipedia.org/wiki/Selection_bias) involved in these sorts of surveys whereby certain groups tend to be far more likely to respond. These concerns are somewhat reinforced by the survey's own reporting wherein almost 70% of respondents came from 3 sources.\n\n[![State of JavaScript response source](/images/posts/state-of-js-2019/source_sm.png)](https://2019.stateofjs.com/demographics/#source)\n\nAs another example of this, the survey was [91.3% male](https://2019.stateofjs.com/demographics/gender). While people who identify as women or non-binary are severely underrepresented in our industry, the [latest information](https://www.inc.com/laura-garnett/women-in-tech-what-s-the-status.html) would put the percentage more likely in the 15-17% range.\n\nAll those caveats aside, this is the largest survey focused exclusively on JavaScript, with 21,717 responses, so it can be interesting to parse the results and see how they align with your own opinions and perceptions of the community. Not a ton surprised me this year, but here are some somewhat random things that stood out to me when reading it.\n\n> For a very different take, check out [this post by Jerod Santo](https://changelog.com/posts/7-insights-from-the-state-of-js-2019).\n\n## We Overstate Our Expertise\n\nThe survey does not seem to have asked people to state their JavaScript proficiency, but, considering the target audience, it's probably safe to assume they lean advanced or expert with JavaScript. So it is a bit surprising that 56.4% of respondents consider themselves to be either advanced or expert in CSS, including about 40% saying they are a CSS expert.\n\n[![CSS Proficiency](/images/posts/state-of-js-2019/cssProficiency_sm.png)](https://2019.stateofjs.com/demographics/cssProficiency)\n\nIn addition, 64.9% say they are advanced or expert in back-end, though trending slightly towards advanced over expert.\n\n[![Backend Proficiency](/images/posts/state-of-js-2019/backendProficiency_sm.png)](https://2019.stateofjs.com/demographics/backendProficiency)\n\nThese results would indicate that a majority of respondents likely see themselves as advanced or expert in JavaScript, CSS and backend development. The survey laid out pretty high standards for these definitions (as seen in the images above). Even accounting for just over 50% of respondents having over 5 [years of experience with JavaScript](https://2019.stateofjs.com/demographics/workExperience) (which, for the record also seems unusually high), color me extremely dubious.\n\n## Rankings? 🤔\n\nThe survey displays a section it calls \"rankings\" for frameworks. The way this is displayed shows Vue (87%), Svelte (88%) and React (89%) sitting almost even for frontend frameworks.\n\n[![front end framework rankings](/images/posts/state-of-js-2019/front_end_frameworks_experience_ranking_sm.png)](https://2019.stateofjs.com/front-end-frameworks/front_end_frameworks_experience_ranking)\n\nThis struck me as odd. Sure, Svelte has had a lot of momentum lately, but having it ranked almost tied with React, above Vue and well above Angular seemed off. However, the problem wasn't the data here so much as the terminology and the choice of how to display it. I think it can lead to misunderstandings, as it did initially with me.\n\nThe results above are only for a \"satisfaction\" ratio. There is a menu of options that, at least to me, wasn't initially obvious that allows you to switch to interest and awareness ratios. I believe the choice of \"rankings\" for the heading was chosen because these stats were grouped together, but I think it only compounds the initial confusion and potential misinterpretation.\n\nOnce I understood the way this was displayed, there were few surprises in the results. Same for back end frameworks.\n\n[![backend framework rankings](/images/posts/state-of-js-2019/back_end_frameworks_section_overview_sm.png)](https://2019.stateofjs.com/back-end/back_end_frameworks_section_overview)\n\nPerhaps the only surprise was the popularity of Next.js and how quickly Meteor has fallen out of favor. In fact, my biggest surprise was in the [mobile and desktop](https://2019.stateofjs.com/mobile-desktop/) rankings.\n\n[![Mobile and desktop](/images/posts/state-of-js-2019/mobile_desktop_experience_ranking_sm.png)](https://2019.stateofjs.com/mobile-desktop/)\n\nNativeScript isn't even on the list. Perhaps I have a bias there myself since I worked at the company that makes it, but the [other tools](https://2019.stateofjs.com/mobile-desktop/other-tools/) results seem to show it was a major missed inclusion as were others including, arguably, PWA even if it encompasses a range of tool solutions. Flutter may have been a big miss as well since the target audience seems to be partly JavaScript developers as it's not like there's a State of Dart survey.\n\n## Where Do We Go to Learn?\n\nAs someone who focuses on creating developer content, it's always interesting to me to see where developers are going to learn and keep up with their field. CSS Tricks has a substantial lead over everyone else with Dev.to coming in second. I was a bit surprised to see both beating out JavaScript Weekly as getting a top link in that newsletter seems to bring in large amounts of traffic, but maybe folks think of it as more of a secondary source since the content resides elsewhere.\n\n[![blogs and magazines](/images/posts/state-of-js-2019/blogs_news_magazines_sm.png)](https://2019.stateofjs.com/resources/blogs_news_magazines)\n\nMedium received a lot of votes in the freeform answers, even despite the dreaded paywall. I was also still surprised that almost 20% still consult W3Schools, barely trailing MDN which is a far better resource. There are lots of folks that seem to be using Udemy, Egghead.io and FrontEndMasters. That doesn't surprise me, but no mention of Pluralsight at all? That does.\n\n## Opinions on JavaScript\n\nMost of the data in the [opinions](https://2019.stateofjs.com/opinions/) section didn't surprise me. Folks seem to think things are headed in the right direction, though they feel less strongly about it than in years prior. I was a little surprised that most respondents do not agree that building JavaScript apps has gotten too complex now - only 40.3% either agree or strongly agree.\n\n[![JavaScript too complex](/images/posts/state-of-js-2019/building_js_apps_overly_complex_sm.png)](https://2019.stateofjs.com/opinions/building_js_apps_overly_complex)\n\nI thought the percentage would be higher. But I suppose we've already learned that a big chunk of respondents area apparently experts in everything related to the web, so maybe I shouldn't have been surprised.\n\nNotably, the percentage of folks who think JavaScript is changing too fast has dropped, even though technically the language changes every year now. This doesn't terribly surprise me. ES6 was a major shift that took folks time to adjust to. However, recent changes are much less dramatic. I also feel as though the sense that there is a new framework every week has cooled.\n\n[![Ecosystem rate of change](/images/posts/state-of-js-2019/js_ecosystem_changing_to_fast_sm.png)](https://2019.stateofjs.com/opinions/#js_ecosystem_changing_to_fast)\n\n## What to Make of It?\n\nIt is fun to delve into these and, despite any complaints, am grateful for the folks who put this together. It is a lot of work. It can be useful to challenge some assumptions you may have, learn about new technologies you perhaps hadn't heard of and try to pick up on trends. However, I don't think there is anything in here that should cause anyone to make major changes to the way they do things or the tools that they use."},{"slug":"static-site-generator-rising-starts","category":"blog","title":"Rising Stars for Static Site Generators in 2016","description":"Probably not who you're expecting.","tags":["Jamstack"],"body":"\n[Best.of.js](http://bestof.js.org/) published its list of [rising stars for 2016](https://risingstars2016.js.org/). This list uses the number of GitHub stars added on a project over the course of the year to determine which projects are trending the most for the year. This may be an imperfect measure, to be sure, but it is at least illustrative of interest on some level in a project.\n\nSo who were the [rising stars for static site generators](https://risingstars2016.js.org/#ssg)? Probably not who you'd expect.\n\n![Rising static site generators](/images/posts/rising_ssg_2016.png)\n\nInterestingly, for a type of tool where we seem to see a new project almost daily, the majority of these are not new. Hexo, Metalsmith and Harp have all been around for quite some time now. Harp was the most surprising to me since it first appeared in 2012 and hasn't seen a meaningful update in years (it still works as advertised though, in my experience). Gatsby and Phenomic are relatively new (both appearing in 2015) but their appearance is less surprising since they both are based upon the React framework which was what all the cool kids used in 2016 (though, they've since moved on to Vue apparently).\n\nThis is also a measure of the fact that users seem to want tools written in the language they use - in this case, JavaScript. Every one of these tools in written in JavaScript (as you would expect from Best of JS). I've personally used Hexo, Metalsmith and Harp (they are part of my [static site samples](https://github.com/remotesynth/Static-Site-Samples)). I hate to offend anyone, but, based upon my personal experience, if you value using the best tool for the job over the language (or framework) that it is written in, these would not be the tools that I'd most recommend. I recommend [Jekyll](http://jekyllrb.com/) (built with Ruby) or [Hugo](http://gohugo.io/) (built with Go).\n\nIf you _insisted_ on using a JavaScript-based tool, Hexo is certainly a worthwhile choice. But I would ask, why are you insisting? Certainly, there are legitimate reasons. For example, there is very specific custom functionality that you require and intend to add via an extension of some sort (and which isn't supported by any existing extensions for the tools I suggest). However, these exceptions are rare.\n\nObviously, I haven't used every tool on this list (or the literally [445 others](https://staticsitegenerators.net/) that exist as of today), but I have used more than most. I'm always willing to give a new tool a shot. It can be fun. But if I am starting a legitimate project, I'd stick with the best available and most established tools for the job."},{"slug":"static-sites-book","category":"blog","title":"Working with Static Sites Officially Available from O'Reilly","description":"If you like the feel of print, you got it.","tags":["Jamstack"],"body":"\nI'm happy to announce that the book that I wrote with [Raymond Camden](https://www.raymondcamden.com/), [Working with Static Sites](http://shop.oreilly.com/product/0636920051879.do) is 100% official. As of today, you can even order the print copy, if that's what you prefer.\n\nThe goal of the book was to go deeper than the typical examples by showing \"real world\" uses for static sites as well as delving into a variety of services and deployment options. If you're curious about exactly what we cover, here's the TOC:\n\n- Chapter 1: Why Static Sites?\n    - Benefits of Static Sites\n- Chapter 2: Building a Basic Static Site\n    - Welcome to Harp\n    - Your First Harp Project\n    - Working with Layouts and Partials\n    - Working with Data\n    - Generating a Site\n    - Building Camden Grounds\n    - Going Further with Harp\n- Chapter 3: Building a Blog\n    - Blogging with Jekyll\n    - Your First Jekyll Project\n    - Writing a Post\n    - A Quick Introduction to Liquid\n    - Working with Layouts and Includes\n    - Adding Additional Files\n    - Working with Data\n    - Configuring Your Jekyll Site\n    - Generating a Site\n    - Building a Blog\n    - Going Further with Jekyll\n- Chapter 4: Building a Documentation Site\n    - Characteristics of a Documentation Site\n    - Choosing a Generator for Your Documentation Site\n    - Our Sample Documentation Site\n    - Creating the Site\n    - Going Further\n- Chapter 5: Adding Dynamic Elements\n    Handling Forms\n    Adding Comments\n    Adding Search\n    Even More Options\n- Chapter 6: Adding a CMS\n    - CloudCannon\n    - Netlify CMS\n    - Jekyll Admin\n    - More Options\n- Chapter 7: Deployment\n    - Plain Old Web Servers\n    - Cloud File Storage Providers\n    - Deploying with Surge\n    - Deploying with Netlify\n    - Summary\n- Chapter 8: Migrating to a Static Site\n    - Migrating from WordPress to Jekyll\n    - Other Migration Options\n    - Go Forth and Be Static"},{"slug":"tech-layoffs","category":"blog","title":"The Constant Stream of Tech Layoffs","description":"This industry can be brutal.","tags":["general"],"body":"\nThe word today is that [Microsoft is laying off about 700 people](http://www.businessinsider.com/about-700-microsoft-employees-to-be-laid-off-sources-say-2017-1) next week. Last week, my employer [laid off about 450](http://www.rttnews.com/2733472/progress-software-q4-loss-widens-coo-jerry-rulli-to-step-down-to-cut-jobs.aspx). (Of course, on a percentage basis, our layoff was significantly bigger than Microsoft's upcoming one as it was about 20% of the company.)\n\nThose of who work in the tech industry are often very fortunate. We are generally paid well and have good benefits. Many, like me, have lots of flexibility in their jobs.\n\nThat being said, this industry can be brutal in its own way. Having worked in tech for about 20 years now, I have been through numerous companies that no longer exist, too many reorgs and restructuring, and too many layoffs. I've been on both sides of these. It can be a damaging experience, obviously for those who are laid off, but even for those who are not.\n\nIt's also something that I cannot get used to. I wish that I had some words of wisdom or guidance on how to survive layoffs - whether you remain or leave - but I do not. Each one has been terrible in a unique way."},{"slug":"technical-debt","category":"blog","title":"Technical Debt is Not Just Technical","description":"Many factors can influence technical debt and many of them have nothing to do with code.","tags":["general"],"body":"\nI'm going to admit something kind of embarrassing here. Looking back on my career, I believe that there were times relatively early in my career when I was probably difficult to work with. I believe I've learned from those mistakes. Let me explain.\n\n## Technical Debt\n\nDevelopers often refer to the concept of [technical debt](https://martinfowler.com/bliki/TechnicalDebt.html). Essentially technical debt is the \"cruft\" that gets leftover in an application due to some poor initial decisions about how it was built. These choices are sometimes made deliberately and sometimes unintentional. The thing about technical debt is that it often builds upon itself - poor choices initially limit the choices down the line so that it can ultimately become extremely painful, difficult and, yes, costly to correct.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">“This technical debt can wait. I have a feature to deliver!” <a href=\"https://t.co/OrUZgGUbwV\">pic.twitter.com/OrUZgGUbwV</a></p>&mdash; Changelog (@changelog) <a href=\"https://twitter.com/changelog/status/1103511794855936000?ref_src=twsrc%5Etfw\">March 7, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThe other thing about technical debt, it is often much easier to see when you are new to a company or project - especially the unintentional kind.\n\n## Misdiagnosis\n\nSo, here's me, circa 2005 or so, armed with the confidence of some years as a developer under my belt. My newness to the companies (yeah, I bounced around a bit at this time in my career) made it relatively easy to recognize technical debt. From a technical standpoint, I had enough knowledge to diagnose the issues.\n\nBut here's the thing about technical debt which I only learned through years of painful experience - despite its name, technical debt is not just technical. It is organizational, institutional, political and, yes, often personal.\n\nBehind every bit of technical debt, there is a story. Sometimes the story can be simple like, \"Oh crap! I didn't realize it should be done this way.\" More often though, there is a much more complex story that involves people whose egos may be on the line, organizations who pushed for solutions for reasons that aren't technical (an example would be \"[dogfooding](https://en.wikipedia.org/wiki/Eating_your_own_dog_food)\" or software choices mandated by a purchase a senior manager made from a buddy). Sometimes technical choices can be wrapped up in such a complex history that it can become difficult to unravel exactly how the choice was made.\n\n[![The other infinite loop that all coders fear](/images/posts/infinite-loop.jpg)](http://www.commitstrip.com/en/2014/09/08/the-other-infinite-loop-that-all-coders-fear/)\n\nThe point here is, 2005 me had learned enough to diagnose and, perhaps, even fix these issues at the companies I was joining from a technical standpoint. Armed with technical knowledge I jumped in head-first only to land on powerful blockers that were not technical in nature. My failure was in not being able to see and diagnose the non-technical aspects of the technical debt and this failure left me often frustrated.\n\n## Learning to Listen\n\nBasically, I had a \"code first ask questions later mentality\" when the answer was simple - take the time to ask questions and listen. Find out why certain choices were made. Doing so gives me the knowledge I need to diagnose the technical problem (and to my surprise, sometimes better understanding the non-technical reasons made me realize I was actually misdiagnosing something as technical debt). But, more importantly, it enabled me to offer solutions that work not just from a code standpoint, but work for the people I have to work with and the company I am working for.\n\nRemember that asking questions and listening takes time and patience. You cannot come in thinking you have all the answers, as I did. The best analogy I can think of is going to a doctor to treat pain. The doctor can quickly treat the symptom and the pain will subside, but can leave the problem to fester undetected. However, a good doctor will take the time to understand you, your issues and investigate the underlying causes of the pain and treat it holistically. Be the good doctor that circa 2005 me was not."},{"slug":"thats-already-been-done","category":"blog","title":"That Topic Has Already Been Covered!","description":"Don't let this intimidate you into not sharing!","tags":["general"],"body":"\nThe other day Chris Coyier tweeted something I wholeheartedly agree with:\n\n<blockquote class=\"twitter-tweet\" data-partner=\"tweetdeck\"><p lang=\"en\" dir=\"ltr\">Write the article you wish you found when you googled something.</p>&mdash; Chris Coyier (@chriscoyier) <a href=\"https://twitter.com/chriscoyier/status/925081793576837120?ref_src=twsrc%5Etfw\">October 30, 2017</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThis is great advice. However, I read, write and edit a lot of developer-focused content. In the course of this, I've seen a a frequent criticism of content along these lines which is that this topic has already been sufficiently covered - and usually not stated as diplomatically. These comments are along the lines of this one from a recent article I published (but didn't write):\n\n> Oh boy, another one of these articles. No thanks.\n\nI wanted to briefly discuss why I think that this criticism is, in almost all cases, misplaced.\n\n## 1. Each Developer Brings Their Unique Problem Solving Skills\n\nOne of my favorite parts about being a developer is that every problem has nearly infinite possible solutions. Even within similar solutions there are often creative variations. That problem-solving and creativity is part of what drew me to the field.\n\nEvery author brings their own thought into the problem solving process and their own creativity into the solution. Even if the topic isn't new to me, the reader, I may learn something from the particular developer's approach.\n\n## 2. Writing is About the Learning _and_ the Sharing\n\nI believe that the process of writing is as much a learning process as a sharing process. Even if a topic has been covered many times, it may be _new to me_. In the process of learning, I may want to think through and write out my thought processes. For me, this can be a very productive process, reinforcing what I learned and perhaps forcing me to think through in a more direct manner some of the choices I made in the development process. The sharing is, in part, just a side effect - if I found this useful, maybe someone else will.\n\n## 3. Every Author has a Unique Perspective\n\nOne of the things you learn when you edit a lot of content is how unique each developer's writing voice is. Some are funny while some just focus on the code with as little discussion as necessary. Some give insights into their thought processes while others stick to research.\n\nEven if the code were identical, every individual adds their voice and perspective to the content. You never know what will end up resonating with someone else. Perhaps your unique take  - so, don't be afraid to add your voice to the conversation, even when someone tells you its been done before."},{"slug":"the-web-is-boring","category":"blog","title":"The Web is Boring","description":"I think the web has lost its luster lately due to a lack of innovation.","tags":["general"],"body":"\nWhen I was growing up, flying was fun. This wasn't the kind of fun that a kid finds in simply new experiences - it was a legitimately enjoyable experience. The airport was a much less stressful place than it is today, with far less security and fewer lines. The planes seemed more spacious (though perhaps that part was really just that I was a kid). They served you food on most flights - with a real, metal fork and knife. Perhaps it wasn't the greatest food, but wouldn't we just love to get something, anything, nowadays? They'd even let kids go into the cabin and meet the crew, often handing them a junior crew member pin to wear.\n\n![twa pin](/images/posts/twa_pin.jpg)\n\nI fly more nowadays than I did back then, but flying is generally painful. The airport is stressful. The airline customer service is generally awful. There are few, if any, meals or snacks served. Flying has become something I need - for work, to visit family, to get to somewhere for vacation - not something I enjoy. Even on vacation, flying is something we power through to get where we want to be rather than being part of the vacation experience.\n\n## The Web, Too, Has Lost Its Luster\n\nMuch like the joy of flying, I am finally ready to openly admit that the web is no longer fun. Just like flying, I use it more today than I ever did back when it was fun, but it is purely out of necessity rather than desire. On a personal level, I use web sites to get news and to keep up with friends and family. The web is, obviously, an integral part of my work too, for news and information as well as the focus of my actual job. All of these things I need, but none of them bring the joy and exitement that the web used to bring.\n\nPerhaps you are not old enough to remember when the web was fun. If so, you may even think that it *is* fun. But back in the mid-to-late-90s, the web had the power to amaze us. New sites and new businesses would launch regularly and everyone had to try them out because each one seemed to bring something new and creative to the table. Sure, many didn't survive long (and we had tons of useless accounts), but they all seemed to be part of an inexorable path towards something special - a future where the web would make our lives more enjoyable, easier and, yes, more fun. Many of us firmly believed that the web was the future of computing - who'd need a desktop or operating system when the web was eventually going to replace the need for either.\n\n## That Didn't Happen\n\nLet's be honest. None of that ever happened. You may be thinking, \"But what about my streaming movies or my streaming music or my multiplayer games? Aren't those fun?\" To which I'd say, \"Don't confuse the internet with the web.\" The internet enables each of these, but they are rarely done via the web (yes, they all have web interfaces, but I'd bet the majority of people do not access them this way).\n\nThere's been a lot of talk about how the [web is losing](http://www.quirksmode.org/blog/archives/2015/05/web_vs_native_l.html) some unofficial battle for survival. Much of that has focused on the overwhelming amount of tools for web development and the way these tools are impacting the performance of the web. I am not disagreeing with those, per se, but I can say that the web was actually much more fun back when it was also horribly slow (most of us were on dial-up after all).\n\nI feel that the thing holding the web back is a lack of real, creative innovation. I read every day about new little features of the web platform, but I can't remember the last time I read about something built on the web that really excited me. Until then, I'll keep passionlessly reading my news and blog posts or getting my gmail and hating myself for checking Facebook for lack of something more interesting to do. Sorry, web, but you bore me."},{"slug":"the-webs-failure-as-information-platform","category":"blog","title":"The Web's Failure as an Information Platform","description":"The once Information Superhighway has become jammed with ads and lies.","tags":["general"],"body":"\nThe web as an \"Inforamation Surperhighway\" (a term generally [attributed to Al Gore](https://en.wikipedia.org/wiki/Information_superhighway)) was a common phrase twenty-five or so years ago. Back then the web was a nascent application platform, incapable of truly competing with desktop applications, but was a burgeoning information platform - democratizing access to information in a way no other platform could.\n\nTwenty-five years later and we rarely mention the \"Information Superhighway.\" We tend to focus more on the web as an application platform. There's no doubt that, while the experience can sometimes be less than optimal (especially on mobile), we've made great strides towards making the browser a fully functional application platform.\n\nUnfortunately, as an information platform, today's web is being destroyed by lousy, obtrusive and disproportionate ads (see [Walt Mossberg's great post from today](http://www.theverge.com/2017/1/18/14304276/walt-mossberg-online-ads-bad-business)) on the one end and by misinformation on the other (the so-called \"fake news\" problem and the social platforms such as Twitter and Facebook that promote its spread).\n\nAs Mr. Mossberg notes in his article (and I've discussed plenty [before](http://www.remotesynthesis.com/blog/broken-content)), there's little viable business model currently in producing quality content. Good content takes time, effort and money. Advertising networks on the web are not truly designed to reward the quality of the content but rather the number of clicks. By that measure, fast and cheap content that brings in lots of clicks is just _good business_ - and, thus, fake news is simply [all about income](https://www.nytimes.com/2016/11/25/world/europe/fake-news-donald-trump-hillary-clinton-georgia.html).\n\nEven as the future of subscription-based sites like the New York Times and Wall Street Journal seem to be improving (even if not to the degree of their print heyday), this isn't a viable plan for new outlets. These are long established brand names with huge existing audiences, and even they struggled to find their way in this environment. What chance does anyone else have?\n\nEv Williams has vowed to [find a different model](https://blog.medium.com/renewing-mediums-focus-98f374a960be#.2b33r71zm). I have my doubts about his ability to do that. When you have a hugely popular site that runs on free content and still can't make money off it...?\n\nI'm also dubious that there will come a day when we are all willing to pay for content on the web. As [illustrated by a recent study](https://www.nytimes.com/2017/01/18/upshot/researchers-created-fake-news-heres-what-they-found.html), We're more than content consuming fake news that confirms our biases, regardless of its relationship to the truth.\n\nMy only thought is that perhaps there are enough of us who care about quality content that we can contribute to some form of organization that can offer grants for creating quality content. Sort of like a Kickstarter for quality content. Rather than individually subscribing, we would donate to this non-profit that would, like many non-profits do, dole out grants for individuals or organizations who create content (chosen by some sort of voting or board or something) and who thereby agree to abide by some sort of ground rules regarding advertising (not _no_ ads, just non-disruptive ads).\n\nBut the skeptic in me thinks that even that sounds like an unrealistic fairy tale."},{"slug":"thinking-in-jamstack","category":"blog","title":"Thinking in Jamstack","description":"One of the more difficult things a new Jamstack developer can face is a change in mind set about when to render content.","tags":["Jamstack"],"body":"\nI feel like one of the difficulties that many developers face when considering adopting the Jamstack is that it requires a change in your mental model of how to build an application. This often results in a potentially misapplied belief that Jamstack is just for building simple applications. You'll hear comments along the lines of a comment on my [recent post](https://dev.to/remotesynth/what-is-the-jamstack-in-2021-1p1n):\n\n> I'm sure static sites are awesome when building a site but most of what I build is a webapp that requires a lot of dynamic info.\n\nThe thing is, Jamstack is all about building sites with a lot of dynamic info! But it also requires you to retrain your brain a bit. In this post, I want to share how I like to think about it in the hopes that it might potentially help others get over that mental hurdle.\n\n> On a side note, if you're interested Jamstack, make sure to join me and 20 amazing speakers at [TheJam.dev](https://thejam.dev/), a Jamstack community conference being held on January 28-29.\n\n## The Traditional Server-side Application Model\n\nI'm going to age myself here but, having worked for decades building these types of applications, they were really easy to understand. Essentially everything happened on the server side (usually within an application server like PHP, for example). The user would interact with the web application, which would make a request to the server. The server would parse this request and then assemble the page, which meant the entire HTML/CSS/JavaScript, and send back the response which would then render for the user in the browser.\n\nWhat we called Web 2.0 in the early days made some changes to this process, but, in many cases, it was cosmetic. The asynchronous JavaScript call would still make a request to the application server. This might send back XML or, in many cases, it would still send back a rendered HTML snippet.\n\nThe important point here is that there was never a need for a developer to give much thought about when to access data. It was always just accessed on the server following a request. Whether populating the content of a blog post or the user's account details, it all happened the same way.\n\n## The Modern SPA Application Model\n\nThe SPA model changed this quite a bit. The application was no longer sending the full HTML/CSS/JavaScript of a page to the client. Instead, it sends an application shell that the application lived in, made of HTML/CSS/JavaScript, and would populate the content and data on a page via a series of API requests to the backend. This backend was not typically monolithic as in the case of the traditional model, but instead each API call could be using my own API on a server (perhaps using Node though not necessarily), a service running as a cloud function, a third-party API, etc.\n\nIn this case, what was returned was JSON data rather than rendered output. While developers were now making all kinds of client-side calls to these various backends, the mental model was still fairly simple. The data that populated a page was generally loaded on the client in response to an asynchronous request, though you may choose render some complex or sensitive pieces on the server. However, even when something was rendered on the server, it was in response to an asynchronous request.\n\n## The Jamstack Model\n\nThe reason both of these two models remain easy to grasp is that it always follows a \"client requests x => application gets x and returns it to the user.\" A developer doesn't need to think about _when_ it makes sense to get something as it is always in response to a specific request. One might think that, since it is dependent on APIs, that the Jamstack model and the SPA model would be essentially the same, but, in my opinion, pre-rendering changes the entire mental model. Pre-rendering content is about much more than just loading some Markdown files and determining what to pre-render and what not to takes some thought.\n\nThere are two points in time that you can integrate dynamic content into a Jamsack application, and when each is appropriate may differ across pages or even in different parts of a single page:\n\n* **Build time** - A Jamstack application may load data from files, APIs, third-party services or even a database at build time. If you're used to the SPA model this may seem like just a place for the application shell plus long form content from Markdown files, but it can be much more than that. Already it has become common for Jamstack applications to use headless CMS and headless ecommerce systems to populate content or product listings at build time. However, this is relevant for any content from any API that a) applies to all users and b) persists for a substantive amount of time (what is \"substantive\" is kind of flexible, and costs may factor into it as it impacts your monthly build time). You can think of it like a content cache that applies to all your site's users. Parts of the cache may need to be refreshed at specific intervals - that could be once a month, once a day or even multiple times a day dependent on the type of content. For example, if I'm building a site about Orlando, where I live, I might want to include the daily local weather forecast. I _could_ call that on the client, but it would be more efficient to simply call it at build time and update the build each day to refresh it. \n* **Run time** - This is similar to an SPA whereby the Jamstack application calls an API that returns JSON from the client using JavaScript and populates the page content in the browser. This should typically be content that is user specific, needs to update frequently, or is in response to a specific user action. For example, an ecommerce site may have product details populated at build time, but things like the current inventory, shipping options/prices based upon the user's location, or the user's shopping cart would all be populated at run time in the browser. As you may notice, in this example, the content on a single page (product details) may be a combination of both pre-rendered (build time) content (i.e. the product name, photo and description) and run time content (i.e. the product inventory and shipping options based on location).\n\nTo further complicate things, new tools like Next.js allow the addition of a third option, which is SSR for specific routes, but if you're building a \"static first\" Jamstack site, that should be the exception rather than the rule. The addition of things like [Netlify Edge Handlers](https://css-tricks.com/netlify-edge-handlers-2/) make the story even more complex from a mental model perpective, but the end result of all of these changes is that a Jamstack site can be incredibly dynamic - it's just a matter of determining *when* that dynamic content needs to be rendered.\n\n## Wrapping Up\nThe point here is that dynamic data isn't just a client-side thing in a Jamstack application and Jamstack developers need to think about each piece of content/data in terms of when it should be retrieved and rendered. I think Cassidy Williams summed this up much more succintly in a recent tweet:\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I admit personally I didn&#39;t really &quot;get&quot; what the big deal was about Jamstack until I started thinking of it this way. Data really can be pulled in whenever, it&#39;s more about the decoupling/separation of concerns.</p>&mdash; Cassidy (@cassidoo) <a href=\"https://twitter.com/cassidoo/status/1351590001675563008?ref_src=twsrc%5Etfw\">January 19, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThe key word there is _whenever_. Without taking into account things like SSR and edge handlers, to me, the critical distinction in thinking about \"whenever\" when it comes to a Jamstack app is determining whether that data should be pulled  _whenever the site is run_ or  _whenever the site is built_.\n\n\n\n\n"},{"slug":"tools-for-writing-markdown","category":"blog","title":"Tools for Writing and Converting Markdown","description":"Some useful tools for when you need to convert other formats to Markdown.","tags":["web development","Jamstack"],"body":"\nBy now, most developers are familiar on some level with [Markdown](http://daringfireball.net/projects/markdown/). It's become a somewhat ubiquitous part of developer tooling, probably in no small part due to it's usage for documentation in GitHub. It also plays a big part in nearly all the major static site engines.\n\nThe power of Markdown and probably a significant reason for its success is in its simplicity. But this is also its biggest weakness. Developers love Markdown because it offers a shorthand for probably 80% of their writing use cases - things like blog posts and basic documentation. For the other 20%, developers have no problem switching to straight HTML, which, of course, you can include in a Markdown file without issue.\n\nFor writers and the general public however, this presents a huge obstacle. They cannot use the tools they are comfortable in writing with and they not only are forced to learn Markdown syntax, but they must learn those cases that Markdown doesn't cover and the HTML to use in these cases. It's multiple layers of complexity for the sake of simplicity.\n\nThat being said, as Markdown becomes more widespread in its use, the tooling around it is slowly improving. I use Markdown daily and below are some of the tools that I've found useful in my own experience.<!--more-->\n\n## Desktop Editors\n\nMost code editors such as [Brackets](http://brackets.io/) or [Atom](https://atom.io/) already include some level of Markdown support. However, if you're looking for an editor with richer functionality geared specifically towards Markdown, then there are a number of options.\n\n[Mou](http://25.io/mou/) is my current go to option for writing Markdown. As with pretty much every Markdown editor out there, you write in Markdown and have a live preview available. There is currently no option that I am aware of where you write in rich text and have it converted to Markdown.\n\nMou offers syntax hinting and highlights as well as keyboard shortcuts, but my favorite feature (and why I prefer it) is the export. I rely heavily on the export to HTML feature and, in my experience, it has the most reliable of the editors I have tried. The only quirk I find is that it often stumbles when using backticks for code blocks (and doesn't recognize the GitHub-flavored Markdown syntax for indicating the type of code within a code block).\n\nCurrently Mou is still free, though a 1.0 looks to be forthcoming that will be paid.\n\nAnother free option is [Macdown](http://macdown.uranusjr.com/), which was created when Mou appeared to be ceasing development. I found it to be quite buggy, personally, but have not tried it much since its initial release.\n\nIf you are on Windows, some options I've heard recommended include [Texts](http://www.texts.io/) and [MarkdownPad](http://markdownpad.com/), though I have limited experience with either.\n\nLastly, while not technically an editor, [Markdown Live](https://github.com/mobily/markdown-live) is a useful tool for live-previewing Markdown as you write it. Once installed, you simply change directory into the folder you want to serve up and enter `mdlive` and it will open a preview in the browser that will update as you type - without the need to save the file. This can be useful if you prefer to use a plain text editor for writing Markdown.\n\n## Web-based Editors\n\nIf you are looking for a free web-based option, [Dillinger](http://dillinger.io/) is a free (and open source) Markdown editor for the browser. It includes a live preview as well as the ability to import documents from numerous sources and export them to various formats.\n\nHowever, one of the things lacking in both desktop and web-based editors is collaboration. If you are working on a team, the ability to share, comment and collaborate on a document is not just useful, but necessary. [Beegit](https://beegit.com/) is a commercial offering that includes a number of collaboration features. My team uses it mostly for the ability to share and comment on documents as they are being developed, much as you would within Google Drive.\n\n## Converters\n\nWhen you are working with a number of contributors, it's not always possible to force everyone to use Markdown. While Markdown's simplicity makes it simple to manually convert short documents, converting long documents or groups of documents could get tedious and time consuming. While they aren't perfect, in these cases, a converter can be enormously helpful.\n\nOne converter that I rely on frequently is the [Word to Markdown web app](http://word-to-markdown.herokuapp.com/). Simply choose your local file and hit convert. The site will post you the Markdown it generates from the file as well as a live preview. For good or for bad, it even embeds images in the document using Base64 encoding. Personally, I find this can be difficult to clean up and replace with external images, so I often remove them from the source document first and put placeholders.\n\nWord to Markdown is also available as an [open source project and command line tool](https://github.com/benbalter/word-to-markdown). In my experience, I couldn't get the command line tool to work properly for some reason, while the web app worked perfectly.\n\nIn other cases, you may encounter rich text that you need converted to Markdown, such as text copy/pasted from the web or some other editor. In these situations, I've found [Mark It Down](http://markitdown.medusis.com/) to be both reliable and helpful (it is also [open source](https://github.com/bambax/markitdown.medusis.com)). Simply paste in the rich text and hit the convert button to get back nice, clean Markdown.\n\n## Other Tools?\n\nThis is by no means a comprehensive list of Markdown tools - just the ones that I've personally come to rely on at some level or another. Are there any others that you recommend? Be sure to share in the comments as I'm always looking for new ones."},{"slug":"top-posts-developer-2018","category":"blog","title":"14 of My Favorite Developer Blog Posts in 2018","description":"In 2018, we focused on performance, mobile and how tough it can be to be (or become) a dev.","tags":["general"],"body":"\nThere was truly so much great content in 2018, it was hard to limit this list (thus why I ended up with 14 in a post originally intended for 10). In reviewing articles for this, some themes stuck out. 2018 was a year when developers seemed to focus on things like performance, making the transition to mobile (and specifically this was the year of the PWA) and, finally, making the often difficult choices about which technologies to focus on (especially when faced with so many options).\n\nI went through a years worth of articles that I shared and picked out my favorites (listed in reverse chronological order). It goes without saying that they reflect my own biases as well as my personal focus on JavaScript and front-end development. If you have some time over the holidays, it'll be well used to give any one of these posts a read.\n\n## All About Prefetching by Katie Hempenius\n\nAs I said, one of the focus this year seemed to be on improving performance, often as it relates to mobile. Katie Hempenius took a deep dive into how you can use a prefetching strategy to improve perceived performance. This is a great overview of a topic that is rarely covered.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A great overview of what prefetching is, how it can improve perceived performance, how to use it and when to use it by <a href=\"https://twitter.com/katiehempenius?ref_src=twsrc%5Etfw\">@katiehempenius</a> <a href=\"https://t.co/kHe8PL6HvK\">https://t.co/kHe8PL6HvK</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1073584645839745030?ref_src=twsrc%5Etfw\">December 14, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n## Faster than AMP (author unidentified)\n\nAMP was a topic of much controversy in 2018. However, what I love about this post is that it doesn't offer another perspective on the same controversy, but, rather, digs into how AMP works (or doesn't in some cases) to improve performance. The author (whose name I cannot find) promises more in this series, and I hope they follow through.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A good post (1st in a series) looking at the slowest AMP page and examining why performance is failing to better understand what AMP does to try to address performance. It&#39;s not trying to pitch you AMP, just understand what&#39;s going on under the covers. <a href=\"https://t.co/md2cXaRaC4\">https://t.co/md2cXaRaC4</a> <a href=\"https://t.co/K50EgSZS7C\">pic.twitter.com/K50EgSZS7C</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1072132796506873856?ref_src=twsrc%5Etfw\">December 10, 2018</a></blockquote>\n\n## Elements To Ditch Or Repurpose On Mobile by Suzanne Scacca\n\nBy 2018, most sites have made a transition to mobile in one way or another, however, this is not always a smooth transition. Often sites have taken their desktop mindset and brought it - along with unusable desktop design elements - to their mobile site. This post covers some of the worst offenders and, better yet, offers strategies to fix them.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A great post by <a href=\"https://twitter.com/SEScacca?ref_src=twsrc%5Etfw\">@sescacca</a> on some web design elements that need to be scrapped or rethought for mobile. Couldn&#39;t agree more, especially with modal popups and oversized content. <a href=\"https://t.co/NUgNr0FlOk\">https://t.co/NUgNr0FlOk</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1070701310423560192?ref_src=twsrc%5Etfw\">December 6, 2018</a></blockquote>\n\n## Reluctant Gatekeeping: The Problem With Full Stack by Heydon Pickering\n\nThis post stuck with me because it makes a similar case to [one I have been making](https://www.remotesynthesis.com/blog/full-stack-developer) about the issues with the title \"full stack developer.\" Heydon focuses on the unintended consequences of accepting that one person can do all the things.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">This is a very good post on some of the often unspoken implications of the rise of the title of &quot;full stack developer&quot; by <a href=\"https://twitter.com/heydonworks?ref_src=twsrc%5Etfw\">@heydonworks</a>. I like that it gets at some of the economic aspects of the title, which I&#39;ve argued, are really what drives the it. <a href=\"https://t.co/acJNJ4Fh3X\">https://t.co/acJNJ4Fh3X</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1070082148563107842?ref_src=twsrc%5Etfw\">December 4, 2018</a></blockquote>\n\n## An Extensive Guide To Progressive Web Applications by Ankita Masand\n\n2018 was definitely the year that everyone seemed to decide that they needed to take a closer look at building progressive web applications, driven largely by improved browser support for PWA features. There were a lot of PWA-focused tutorials in 2018, but Ankita's was definitely one of the most extensive and helpful.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">This is a really thorough guide To Progressive Web Applications by <a href=\"https://twitter.com/AnkitaMasand?ref_src=twsrc%5Etfw\">@AnkitaMasand</a>. If you haven&#39;t yet explored PWAs or if you are just looking for details and examples on some of the key parts of a PWA, keep this one for reference. <a href=\"https://t.co/pIAExCoT1F\">https://t.co/pIAExCoT1F</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1067532645658181634?ref_src=twsrc%5Etfw\">November 27, 2018</a></blockquote>\n\n## Making music with magenta.js by Monica Dinculescu\n\nSoemtimes it is great to just build something because it is fun - it helps us reconnect with why we love to code in the first place. I also love reading posts when developers do these sorts of project because their passion for the idea comes through clearly. In this post, Monica Dinculescu experiments with generating music using machine learning. Will I use this is my day-to-day work? Unlikely. Was it fun to read and learn? Absolutely!\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I love fun and creative tutorials. It&#39;s great to learn and reengage with your love of code. This tutorial on making music with magenta.js by <a href=\"https://twitter.com/notwaldorf?ref_src=twsrc%5Etfw\">@notwaldorf</a> is a perfect example! <a href=\"https://t.co/gN45X5NCjb\">https://t.co/gN45X5NCjb</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1067078606797635586?ref_src=twsrc%5Etfw\">November 26, 2018</a></blockquote>\n\n## Methodologies for measuring project health by Nadia Eghbal\n\nThis is an extremely difficult topic that tackles an issue developers face - knowingly or not - on a consistent basis. That issue is whether a particular open source project is healthy enough to adopt and use. There are no easy answers, but Nadia Eghbal explores some options in this well-researched and detailed post.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Should we measure the health of an open source project by its contributors, by the rate and recency of changes or some combination? A good look at methodologies for measuring open source project health by <a href=\"https://twitter.com/nayafia?ref_src=twsrc%5Etfw\">@nayafia</a>. <a href=\"https://t.co/RGzos3ByGu\">https://t.co/RGzos3ByGu</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1034543394809360384?ref_src=twsrc%5Etfw\">August 28, 2018</a></blockquote>\n\n## The Bullshit Web by Nick Heer\n\nAnother performance-focused post that looks at the useless cruft we often include on web pages unthinkingly. Nick argues that this cruft has impaired the progress we have made with the power and speed of our hardware, and with little tangible benefit.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The speed of the web has not kept pace with the speed of our internet connections because we&#39;ve loaded pages with useless cruft that often has little to do with the actual content being displayed, argues <a href=\"https://twitter.com/pxlnv?ref_src=twsrc%5Etfw\">@pxlnv</a> <a href=\"https://t.co/qAL1EwWVg0\">https://t.co/qAL1EwWVg0</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1025103901144608768?ref_src=twsrc%5Etfw\">August 2, 2018</a></blockquote>\n\n## Leveling up: why developers need to be able to identify technologies with staying power (and how to do it) by Matt Biilmann\n\nIt can be difficult for a developer to know what to focus on for their long-term health of their career these days. There are not only so many options to choose from, but everyone is out there pushing their own agenda it seems. Matt, one of the founders of Netlify, offers a ton of excellent advice in this post on what to focus on and how to see it in the context of the bigger picture of the overall trajectory of your career and development as a coder.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">This is some truly fantastic career advice for developers from <a href=\"https://twitter.com/biilmann?ref_src=twsrc%5Etfw\">@biilmann</a> to be able to identify technologies with staying power. <a href=\"https://t.co/VqCKQkIQSq\">https://t.co/VqCKQkIQSq</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/1005126817781637121?ref_src=twsrc%5Etfw\">June 8, 2018</a></blockquote>\n\n## A Guide to JavaScript Regular Expressions by Flavio Copes\n\nI'm sure there are developers out there who _love_ regular expressions. I am not one of them. RegEx is something that I often _need_ and then _need to look up_. And if I ever need to look up anything related to RegEx in JavaScript, this is exactly the post I'd refer to. It is extensive, detailed and is the perfect reference guide to bookmark.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Everything you ever wanted...ok, needed (but never wanted) to know about JavaScript regular expressions. <a href=\"https://t.co/UQDsvXVYSz\">https://t.co/UQDsvXVYSz</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/991056848697610241?ref_src=twsrc%5Etfw\">April 30, 2018</a></blockquote>\n\n## Loading Third-Party JavaScript by Addy Osmani and Arthur Evans\n\nThis is another performance-related (and security-related) post that gets at an issue many front-end developers face consistently: third-party scripts can be extremely helpful in providing added and necessary functionality, but they come with inherent risks. This post tries to help you mitigate those risks by measuring the impact of third-party scripts on your site and finding ways to offset the risks.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A guide to finding and fixing issues related to loading third-party JavaScript by <a href=\"https://twitter.com/addyosmani?ref_src=twsrc%5Etfw\">@addyosmani</a> &amp; <a href=\"https://twitter.com/DevDocDude?ref_src=twsrc%5Etfw\">@devdocdude</a> <a href=\"https://t.co/TR4npCQt9r\">https://t.co/TR4npCQt9r</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/971810532633300992?ref_src=twsrc%5Etfw\">March 8, 2018</a></blockquote>\n\n## Everything Easy is Hard Again by Frank Chimero\n\nIf you've ever felt like things move so fast that it is difficult to keep up with the constant need to learn new skills necessary just to keep your head above water, then Frank Chimero's post may strike a chord with you (as it did with me). He discusses how we've managed to make the simple things difficult in many cases, and made learning (and keeping up with( web development in the process. His message of developing a personal philosophy towards change and learning is an important one for developers of all skill levels.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Everything Easy is Hard Again by <a href=\"https://twitter.com/frank_chimero?ref_src=twsrc%5Etfw\">@frank_chimero</a>. I relate to so much of this. Especially the sense that we&#39;re solving the same problems 20 yrs later but in increasingly complex ways. The common refrain is that the problems are new but I&#39;m old &amp; can&#39;t adapt <a href=\"https://t.co/s3lCRDawjS\">https://t.co/s3lCRDawjS</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/964491485763850240?ref_src=twsrc%5Etfw\">February 16, 2018</a></blockquote>\n\n## Native And PWA: Choices, Not Challengers! by Aaron Gustafson\n\nThings are often presented to developers as binary choices. You either learn web or native. You must learn Angular - and not React - to succeed or vice versa. The truth is that these rarely are as binary as they seem, and this is especially true when it comes to choosing PWA or app for mobile. You are free to choose which best suits the needs of what you are creating - or you are free to choose both. Aaron lays out the options nicely.\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">The choice of Native And PWA is not zero sum. As <a href=\"https://twitter.com/AaronGustafson?ref_src=twsrc%5Etfw\">@AaronGustafson</a> explains, it is a matter of understanding the needs of your project and matching that to the strengths of each solution. <a href=\"https://t.co/v9YNdjMpBS\">https://t.co/v9YNdjMpBS</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/962017756819308544?ref_src=twsrc%5Etfw\">February 9, 2018</a></blockquote>\n\n## Advice to the newish programmer by Tom MacWright\n\nAnother post that discusses the difficulties of working in a fast-changing industry with a lot of competing demands (and voices) pushing you in a variety of directions. While Tom MacWright directs this post at \"newish\" programmers, it is an excellent reminder for any of us of the challenges we face (and maybe gets us thinking on how to address them).\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Some interesting (and basically spot on) advice for new(ish) programmers. <a href=\"https://t.co/12Ts85mVbd\">https://t.co/12Ts85mVbd</a> <a href=\"https://t.co/uNWYH9WUCO\">https://t.co/uNWYH9WUCO</a></p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/961703854806102016?ref_src=twsrc%5Etfw\">February 8, 2018</a></blockquote>\n"},{"slug":"troll-culture-goes-mainstream","category":"blog","title":"Troll Culture Goes Mainstream","description":"It's more than just Washington.","tags":["general"],"body":"\nThe New York Times had an interesting article last week called \"[How the Trolls Stole Washington](https://www.nytimes.com/2017/02/28/magazine/how-the-trolls-stole-washington.html?_r=0)\". Beyond the political discussion, what fascinated me was this idea that trolling was a form of counterculture movement that goes beyond the individual troll.\n\n> Mr. Bungle was a lone wolf, but trolling could also be a communal activity. \n\nI'd always looked at internet trolls as an individualized activity purposefully connected with the outside world only inasmuch as it was intended to incite others and garner attention, regardless of how negative. However, I left this article with the impression that there is a connection between those who operate within this troll culture that I'd never considered. And that a variety of factors, both political and otherwise have arguably taken troll culture mainstream, in a sense.\n\nThe more I thought about it, the more I realized that trolling has become so \"accepted\" (for lack of a better term) that we often see trolling techniques and behavior used as tools for enforcing more widely accepted norms. The tactic of public shaming of people who are deemed to have offended some norm, for instance, seems to me a trollish technique often applied recently for enforcing more mainstream cultural beliefs. And we celebrate individuals who use trollish techniques against those we oppose - even I admit I've enjoyed things like John Oliver posting ads on Fox News designed primarily to incite an angry response from the other side. Or Jimmy Kimmel [trolling Donald Trump at the Oscars](http://www.theverge.com/2017/2/26/14747770/oscars-2017-jimmy-kimmel-donald-trump-tweets-watch).\n\nBut I'm beginning to wonder if we've given up too much by accepting the means by which trolls operate, even if we still generally don't accept the anarchic counterculture that trolls stand for. Did we end up empowering the trolls by accepting the legitimacy of their techniques? As Amanda Hess notes in her article, these are techniques designed to be divisive, to prey on those who care. Those of us who do care can only mimic the behavior but never truly wield it with force. If we fight on their terms, we will continue to lose."},{"slug":"twitter-abuse","category":"blog","title":"Twitter Tries to Rein in Abuse","description":"Let's hope this works.","tags":["general"],"body":"\nTwitter has apparently finally laid out a [real plan](http://mashable.com/2017/02/07/twitter-abuse-updates-safe-search/#S_pYmsoWHSqu) to combat abuse on its site. It's been a long time coming. (Rumor was that rampant abuse even scuttled the potential Disney buyout.)\n\nOne of the interesting aspects of this is that Twitter claims that they will somehow work to prevent serial abusers from simply opening a new account with a different email. They were vague on the details of how they intend to prevent this (I suspect that they will need to remain vague so as not to make it that much easier to bypass).\n\nI've been fortunate in that I have not ever been the target of abuse on social media. I assume that this is partly because I am not a particularly high profile individual and also not a woman. However, the tone of social media has [taken a toll on me](http://www.remotesynthesis.com/blog/on-bullying) nonetheless. I truly wish Twitter success in their efforts on this."},{"slug":"twitter-failure","category":"blog","title":"The Continued Failure of the Web as an Information Platform","description":"Twitter's slow failure is yet another example.","tags":["general"],"body":"As I have harped on many times recently, making money off of content on the internet is hard. The advertising model supporting free content that has worked for decades for television simply isn't working on the web. Even the subscription that is subsidized by advertising (the traditional print content model for newspapers and magazines) only seems to work in very limited cases.\n\nEven if you are Twitter, apparently, you are not immune. As the [New York Times points out](https://www.nytimes.com/2017/01/31/technology/daily-report-the-revolution-will-be-unprofitably-tweeted.html), despite being front and center in the ongoing controversies, activism, celebrity discussion that is constantly in the news, Twitter appears unable to find a workable model using advertising.\n\nThe interesting thing to me here is that Twitter is more than just a content platform - it is really more of a communication platform. However, by trying to monetize it via advertising, it was essentially being treated as a content platform. While this fails to leverage their dedicated users, who primarily depend on Twitter as a communication platform (a service they may be willing to pay for), it also means that they cannot take advantage of the controversy that helps drive their reader traffic (because controversy is not what big paying advertisers want to be associated with)."},{"slug":"updating-jekyll-ffi-error","category":"blog","title":"Update Fails on ffi Install in Ruby","description":"Saving you the headaches I had.","tags":["Jamstack"],"body":"\nFile this one as a niche issue, but in case someone else ends up losing a morning to this issue, I figured I'd post it.\n\nI was trying to update my blog to a newer version of Jekyll. However, my attempts at running `bundle update` kept running into this error:\n\n```bash\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\n\ncurrent directory: /usr/local/lib/ruby/gems/2.3.0/gems/ffi-1.9.18/ext/ffi_c\n/usr/local/opt/ruby/bin/ruby -r ./siteconf20170421-40871-1dh28zu.rb extconf.rb\nchecking for ffi.h... *** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\n...\n\n/usr/local/Cellar/ruby/2.3.1/lib/ruby/2.3.0/mkmf.rb:456:in 'try_do': The\ncompiler failed to generate an executable file. (RuntimeError)\nYou have to install development tools first.\n\n...\n\nMake sure that \\`gem install ffi -v '1.9.18'\\` succeeds before bundling.\n```\n\nTrying to run the suggested `gem install ffi -v '1.9.18'` failed as well. The actual solution is in the error but isn't necessarily obvious. They key is this part: `You have to install development tools first.` I'm on a Mac, so that means XCode. However, just going to the App Store and getting XCode isn't enough, the key is in step 2 below.\n\n1. Install XCode\n1. _Open XCode_\n1. `bundle update`\n\nI should note that after I did all this, I was still getting warnings when I ran Jekyll.\n\n```bash\nUnresolved specs during Gem::Specification.reset:\n      rb-inotify (>= 0.9.7, ~> 0.9)\n```\n\nThese went away after running a `gem cleanup`.\n\nLastly, I was getting a bunch of additional warnings like the following:\n\n```bash\nwarning: already initialized constant JSON::VERSION\n```\n\nThese went away after running `bundle clean --force` and then rerunning `bundle update`.\n\nThis may seem obvious to some of you (especially those more comfortable in the Ruby environment), but I found a ton of people with similar problems (some specific to Jekyll, others to different Ruby gems), so I figured I'd post it."},{"slug":"using-netlify","category":"blog","title":"Using Netlify to the Fullest","description":"Finally taking advantage of some of the platform's more advanced features.","tags":["Jamstack","web development"],"body":"\nSome tools make getting started so simple that it becomes easy to overlook all the features it offers. When everything \"just works\" out of the box, there's nothing necessarily pushing you to dig deeper. Take, for example, [Netlify](https://www.netlify.com/).\n\nI've been using them for years now, most importantly for my online meetups and training site called [Certified Fresh Events](https://cfe.dev/). The original site launched about two years ago was built with [Hugo](https://gohugo.io/) (the newly launched version is also built with Hugo). Building the site took some time and effort, deploying it to Netlify took all of 5 minutes. However, outside of a limited use of their [form handling](https://www.netlify.com/docs/form-handling/), I really wasn't using any Netlify features other than continuous deployment.\n\nHowever, with the recent re-launch of the site built from the ground up, I have finally started to use some of the real power of Netlify. In this post, I want to discuss some of those features.\n\n> NOTE: Yes, I am gushing a bit about Netlify, so it is worth noting that I do not work for them, have not been asked to write this, nor am I being compensated in any way for this post. This is a service that I legitimately love because it has enabled me to run my events site, blog and more for years.\n\n## Environment Variables\n\nHonestly, this is a simple one, but since I wasn't doing anything fancy before the only environment variable I had set was my Hugo version. [Environment variables](https://www.netlify.com/docs/continuous-deployment/#environment-variables) are a good place to keep things like API keys that you don't want to include in your repository.\n\nThere are two ways to define environment variables, one is via the `netlify.toml` file in your project. This is useful if you are using environment variables for something other than an API key however, since it will be checked in with your repository. The other way is to set them in the UI. You can set site specific environment variables by going to Settings > Build & Deploy > Environment.\n\n![Environment variables](/images/posts/netlify/environment_variables.png)\n\n## Branch Deploys\n\nNetlify gives you a lot of options for [previewing potential changes to your site](https://www.netlify.com/docs/continuous-deployment/#branches-deploys), from allowing you to view a pull request or merge request to previewing a branch. This is a feature I had turned on since day one but never taken advantage of. In this case, though, I was doing a significant redesign of my site and working via a branch was the obvious direction.\n\nDeploy previews for pull requests and branch deploys are turned on by default, but you can find the settings under Settings > Build & Deploy > Continuous Deployment > Deploy Contexts.\n\n![Branch Deploys](/images/posts/netlify/deploy_contexts.png)\n\nWhat does this mean? Well, in my case, my branch was called \"redesign\" so my branch was automatically deployed to `redesign.cfe.dev` based on my primary domain name. This not only allowed me to preview my work but even to share it publicly to test the redesign before I officially launched it for everyone.\n\n## Netlify Functions\n\nThe key difference between [JAMstack](https://jamstack.org/) and static sites is that JAMstack has static assets but the site itself can be dynamic by leveraging JavaScript and APIs. A key piece of this, from a Netlify perspective, are [functions](https://www.netlify.com/docs/functions/). Functions, which are built on AWS, essentially allow me to build chunks of server side code that allow my \"static site\" to do things a traditional static site is incapable of.\n\nI will admit to feeling some pain when getting started with functions. Part of this was that the tutorials I found relied upon the [netlify-lambda](https://github.com/netlify/netlify-lambda) tool for developing functions. This works but was a bit more complicated as it involved a build process whereas the newer method for developing functions using [Netlify Dev](https://www.netlify.com/products/dev/) is much more streamlined. (Just to note that Netlify Dev does a heck of a lot more than just functions.)\n\nI won't go into great detail on what I did, largely because my good friend Raymond Camden [already covered it](https://www.netlify.com/products/dev/). We had taken different approaches to this problem and, as it turned out, his was better. I made some adjustments to suit my use case, but the core stayed the same - it is a simple function that allowed me to subscribe people to Mailchimp without leaving my site. While this is a limited use of functions, it is definitely a feature that I plan to leverage more as I continue to develop this site.\n\n## Scheduling Deploys\n\nThe last feature that I want to discuss isn't really a built-in feature of Netlify per se. As my content is very date sensitive, I wanted to have the site continuously rebuilt so that the date information doesn't become stale (for example, an upcoming event may have text that says \"in 12 days\"). In addition, I have random items displayed in some spots on the home page, which also requires a rebuild since the random items are chosen at build time. So what I needed was to ensure that the site regularly rebuilds itself without requiring my direct intervention.\n\nLuckily, Netlify has pre-built integration with [Zapier](https://zapier.com). Zapier isn't free, but, for this sort of task, you're unlikely to hit their free account limits. It's a very simple two-step \"Zap\" that uses Zapier's Schedule to trigger a deploy every night at midnight (truthfully, the time doesn't matter that much from a Netlify standpoint since the build occurs in the background, but midnight made sense since the dates would change, thereby changing the date math).\n\n![Zapier](/images/posts/netlify/zapier.png)\n\n## Just Getting Started\n\nA more honest title for this post would have been \"Using Netlify to the Fuller\", but, on top of being grammatically incorrect, it isn't quite as catchy. It would be more accurate though in the sense that there are still a ton of features that I am not fully taking advantage of - things like split testing, identity, large media. But I have finally explored beyond just the simplicity of the build and deploy process and am excited to continue learning."},{"slug":"virtual-conference","category":"blog","title":"Tips For Running Your First Virtual Conference","description":"Some tips and things to think about when choosing to run a virtual developer conference based upon my recent experiences.","tags":["general"],"body":"\nIt can sometimes appear from the outside that running a virtual conference is easy. Just hook up Zoom to a streaming service and you're done. About a month ago, I ran [my first virtual conference](https://thejam.dev). Suffice it to say that this isn't the case, even with four years of experience running virtual meetups and trainings via [cfe.dev](https://cfe.dev).\n\n![Stephanie Eckles speaking at TheJam.dev](/images/posts/stephanie_eckles.png)\n\nI wasn't alone (thank God!) as I partnered with [FITC](https://fitc.ca) to help but, as many folks are looking to run one, I thought I's share some thoughts based upon my experience.\n\n## The Details\n\nEvery event is different, so my advice may have limited mileage if you are running a very different type of event. So, let me start by setting some of the parameters of how we chose to run this event.\n\n* This was a paid event. The cost was far less than an equivalent in-person event ($79 at full price) but it wasn't free. Registered attendees got access to the live event as well as exclusive access to the recordings for a period of 3 months after. We'll discuss this model in a moment.\n* The event was broadcast via Crowdcast using a paid account that allowed up to 5 hours for a single session.\n* The streaming used a combination of Zoom and Skype. I don't know the technical details as the video person from FITC handled it.\n\n## Get Help to Get the Production Quality Right\n\n![Flor Antara speaking at TheJam.dev](/images/posts/florantara.png)\n\nThis was critical. My original plan was to run this all by myself, but it turns out that there is a lot to manage. It can be done, but if you plan to charge or have sponsors or both as we were, you'll really need to enure that the quality is high. This will make your sponsors happy, your attendees happy and your speakers happy.\n\nHowever, there's just a lot to manage for a single individual and it wasn't all just on the day of the event. Here are some things to consider:\n\n* You'll want to meet with every speaker beforehand to test the techical setup. Be sure to test audio and video quality as well as screen sharing. For some speakers who don't have a reliable connection, pre-recording the talk may be preferable. Also share with speakers what to expect on the day of.\n* You'll likely want to create high quality graphics to use during the event. We had a frame that would change to include speaker info, sponsor info and more.\n* You'll want to create a detailed timeline for the event detailing exactly when things should occur, down to the minute. This ended up being a huge help to keep everything on time and to align live streams with recorded video and more.\n* The day of the event, you'll have a lot to handle. We had someone handling speaker intake (in our case this was done via Zoom). Someone handling the stream, ensuring the right video and audio was being broadcast and keeping everything on schedule. Someone manning the Q&A and chat. Someone as emcee (me, in our case) and managing the live Q&A (if you have one, which, as you'll see later, you should). Keep in mind that you may also have people dealing with technical issues connecting or other logistical questions from attendees that come in via email, Twitter or elsewhere. Having someone to handle that as well was very helpful.\n\nThe point is that, even though this is virtual, it is *a lot*. You'll likely need some help. It's worth assigning resonsibilities beforehand as well.\n\n## Think About Your Business Model\n\nThe economics of independent virtual events can be difficult. First, so many companies are running free events that it can make paid events a difficult sell. Plus, let's be honest, a virtual event doesn't *feel* as valuable as an in-person event. This is partly because it can be diffucult for attendees to get away from work or personal responsibilities for a virtual event.\n\nAs mentioned before, we went with a paid ticket for all attendees as well as sponsorships, of course. The full price ticket started at $79 for 2 days of event. While nowhere near as expensive as an in-person event, it's still tough to compete against free. Obviously, the up-front costs of a virtual event are much, much lower than an in-person one. The lack of food, venue and travel costs makes the risk much lower, but there are still quite a few costs - especially if you take my advice and get some professional A/V and production help.\n\nLooking back, I might consider moving to a free to attend live/pay for recording access model that many other conference organizers seem to be moving to. We did fine on attendees but this model may have brought many more, which makes sponsors and speakers happy. We might have given up money on the ticket sales, but the larger attendee base could make sponsorships more valuable. Perhaps it would have been the same financially, but more attendees is always better for a virtual event, where capacity is generally not an issue.\n\n## Take Advantage of Being Virtual\n\n![Obinna Ekwuno at TheJam.dev](/images/posts/obinnaekwuno.png)\n\nOne of the hardest things to do is to think about the event in ways that don't just try to replicate an IRL event virtually. This is important because, in my opinion, simply trying to replicate an IRL virtually simply highlights the areas that virtual events are weakest rather than where they offer some unique opportunities. I won't say we got this right, but I do think some things worked better than others.\n\n### Live vs. Recorded Sessions\n\nWe had a mix of recorded and live sessions. For a full session speaker, they had the option to record or present live. I think about half the speakers chose to record. However, every full session included a 15 minute live Q&A after. All questions during the session were held for this Q&A period.\n\nI don't feel that there was necessarily anything lost by recording the sessions. It actually can remove the potential for technical issues. However, the live Q&A was really critical. It allowed attendees to interact with the speakers in a way that often doesn't happen at IRL events (or happens awkwardly). The questions were all asked by the emcee, but there was a lot of back and forth via the chat and attendees seemed the most engaged during this period.\n\n### Mix Up the Format\n\nSitting in front of a screen all day for a virtual event can be slightly tedious. You can fight this somewhat by changing up the session format throughout the day in ways that aren't always as easy for an IRL event.\n\nWe had three types of sessions: standard sessions that were 30 minutes with 15 minute live Q&A; 10 minute lightning talks that had no live Q&A; and fireside chats that were approximately 40 minutes. I felt that changing up the format kept the event from feeling tedious or stale. The lightning talks, in particular, were a lot of fun, kept things moving quickly and worked well for a change of pace. Lightning talk speakers did not have live Q&A but were asked to participate in the chat during their talk, which kept the chat lively during these as well.\n\n### Fireside Chats Can Work\n\nI will admit that I was skeptical of having the two keynotes as fireside chats. I worried that it wouldn't offer as much value as a traditional session. I have changed my mind after the event. The fireside chats offered a unique opportunity for attendees to interact with the keynote speakers in a way that would be very difficult at an IRL event. We had some questions that I prepared as emcee to get the conversation rolling but encouraged questions from the audience. We ended up with a ton of audience participation for both of our fireside chat keynotes and attendees seemed to really enjoy the unique opportunity to interact with the speakers that this gave them. Honestly, these were my favorite parts of the event.\n\n## Virtual Events Are Here to Stay\n\nHopefully we can get back to IRL events soon. I miss the direct interaction you get with other attendees. I usually learned as much in the hallway as in the session rooms. Still, it seems pretty clear that, even as things return to normal, virtual conferences or hybrid virtual/IRL events will continue to play a larger role than they did pre-COVID. I think this is great. It gives many people access to a conference that otherwise would not have had access due to the costs or difficulties of travel. And, we're getting better at running them and making them more fun and valuable in ways that take advantage of the benefits being virtual offers."},{"slug":"web-developers-hostile-to-audio","category":"blog","title":"Why are Web Developers Hostile to Audio?","description":"Web developers refuse to integrate audio in their applications. Why?","tags":["web development"],"body":"\nI like to talk and write about Web Audio. It can be a fun topic. However, most talks and demos fail to touch on anything useful. Sure, we can build drum machines and sequencers to our heart's content, but how does this apply to 90% of the web? It doesn't. Thus, when I speak or write about web audio it seems to draw a niche audience.\n\nHowever, recently I have been on a mission to talk and write about how web developers can use [web audio to enhance their applications in practical and useful ways](http://developer.telerik.com/featured/practical-web-audio/). The frequent response I get is like the one below:\n\n![I hate audio on the web](/images/posts/webaudio_comment.jpg)\n\nYou gotta love social media because not only did this person make it clear he never bothered to read the article, but 5 people (which on Google Plus is like everyone) gave it a plus one. However, leaving aside those issues, why are web developers so outright hostile and dismissive to even the suggestion of using audio on the web that they aren't even willing to discuss it or hear arguments as to how it could be useful?\n\nLet's recap:\n\n* Audio in game UI equals totally expected;\n* Audio in mobile app UI equals acceptable;\n* Audio in desktop app UI equals legitimate, within reason;\n* Audio in web apps equals ARE YOU INSANE?!?!\n\nI have a theory as to why.\n\n### The Legacy of Years of Misuse\n\nI expressed this In the early days of the web, we didn't have the web audio API. What we had was site's that got clever and used MIDI or, even worse, had some obnoxious \"Hamster Dance\" like audio.\n\n![Hamster Dance](/images/posts/hampster_dance.gif)\n\nThen came years of Flash Intros and more useless audio. It became ingrained in web developers' heads that audio on the web was purely a gimmick. It is such a widely accepted \"faux pas\" to include audio, that even the mention of carefully considering audio brings strong reactions.\n\n### It's Time to Let It Go\n\nBut do we have to be held back today by the misdeeds of years ago? Sure, the web audio API can be misused. Sure, so far, we've mostly shown how it can be used for things like [8 bit video game music](http://modernweb.com/2013/09/09/retro-game-music-using-web-audio-and-band-js/) (guilty as charged) and web-based drum machines. (Not that those things are useful, even purely as excercises in having some fun with your programming skills, they are beneficial.) The point is, though, this doesn't negate there being useful and practical ways to integrate audio into your web application. If it's ok for every other type of application, why not the web?\n\nUnlike the commenter above, perhaps you'll give my [full article a read](http://developer.telerik.com/featured/practical-web-audio/). I'd love to hear your thoughts on the topic."},{"slug":"web-history-is-important","category":"blog","title":"Knowing the Web's History is Critical to Its Present and Future","description":"Understanding the history of the web will help guide you to its future.","tags":["general","web development"],"body":"\nI've always believed in the importance of understanding history. In college, I was not a Computer Science major, but a history major. History is about much more than understanding the past, it explains where we are today, without which we cannot know where we are going. Imagine you suddenly wake up with no memory of anything prior. You are told that the only safe path is to continue forward, but what is forward if you don't know where you've been?\n\nIn technology and development, we focus on the idea of progress. The web platform of today, for instance, is better than the web platform of a few years ago and far better than the web platform of 20 years ago. Defining progress requires an understanding the historical context.\n\n## But Why Does History Matter for Front-End Development?\n\nHistory is uniquely important to the web because the web is a platform where we've committed to essentially full backwards compatibility. This backwards compatibility can sometimes extend beyond the platform itself to even the tools developers use to build on it. Let's take a relatively recent example.\n\nRemember \"smooshgate\"? This was the controversy that grew over the suggestion of slightly ridiculous sounding method name suggestion of `Array.smoosh()` to flatten an array. Why was this even an issue? Well, because way back when there was a tool called MooTools that was quite popular, and it used JavaScript's prototypal inheritance to extend an array with the `flatten()` method. Thus, adding `Array.flatten()` would have broken any existing site that still ran on MooTools. Jay Hoffman, author of the excellent [History of the Web newsletter](https://thehistoryoftheweb.com/) has a [great, in depth overview](https://css-tricks.com/yet-another-javascript-framework/) of this.\n\nAnother example revolves around Flash and its impact on the development not just of HTML5 but of many of the tools and frameworks that followed its slow demise. As I talked about in [What the Web Owes Flash](https://dev.to/remotesynth/what-the-web-owes-flash), the web platform spent some time playing catch up to the capabilities of Flash. For example, the 3D visualizations and games that are now possible on the web through things like WebGL and [GLSL shaders](https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders) were possible 8 years ago in Flash using Stage3D. What was done in Flash has greatly influenced how the web platform has evolved to today.\n\n## Understanding the History Makes You a Better Developer\n\nUnderstanding the history improves the depth of your understanding of the web platform. It takes you a long way from just understanding how a feature works to why it works the way it does. Going back to my analogy at the beginning, it also orients you to what direction is forward. Understanding how we got here and why is the best guide to understanding how we can progress.\n\n---\n\nThe importance of the history of the web is why I created [Flashback Conference](https://flashback.dev), which is dedicated to covering new features, tools and frameworks on the web platform while also understanding the history behind them.\n\n[![Flashback Conference](/images/posts/flashback.jpg)](https://flashback.dev)\n\nThe conference will be in Orlando (my hometown) on February 10-11, 2020. I really think this will be an amazing and fun event, and I've already got some fantastic speakers and sponsors lined up and ticket are already on sale. I really hope you'll join us.\n\nAlso, if you love this topic as much as I do, I highly recommend Jay Hoffman's [History of the Web newsletter](https://thehistoryoftheweb.com/) (and Jay will also be speaking at Flashback Conference)."},{"slug":"what-happened-to-ssgs","category":"blog","title":"When an SSG Isn't Just an SSG, What Is It?","description":"Many tools we still call SSGs don't produce static-only content.","tags":["Jamstack"],"body":"\nSometimes the technology that a term refers to evolves beyond the literal meaning of the term. This post is about just such a case.\n\nAs most of you know, SSG stands for static site generator. It's a term that has been around a long time. Back when I first got into using SSGs around 2013, it referred to tools like Jekyll, Middleman and Hugo, among others. While each had a different approach, they all essentially worked the same.\n\nAn SSG would take markup (usually a combination Markdown and HTML), a template (something like Liquid but there are many), data files (YAML, TOML, JSON) and perhaps things like Sass for CSS and CoffeeScript (gasp! but it was 2013) for JavaScript. It would run a build step and produce static HTML, CSS and JavaScript. Here's a diagram I used to use to illustrate what an SSG did.\n\n![old skool SSG](/images/posts/ssg.png)\n\n## The Times They Are A-Changin'\n\nThat definition of an SSG stood for many years until about 2019 with the introduction of [Next.js 9](https://nextjs.org/blog/next-9#automatic-static-optimization). Prior to Next 9, Next.js did support static export, but it was an all or nothing affair, meaning that you had to choose to build your site entirely as server-side rendered or entirely as static. This already stretched the definition of a _static_ site generator, but, to be fair, Next.js never called itself that and started its existence as SSR-only.\n\nNext 9 introduced \"automatic static optimization\" whereby a page could be statically rendered if Next.js determined the page did not have blocking data requirements within `getInitialProps`. Later versions introduced new methods like `getStaticProps` and `getServerSideProps` to allow developers to specify if a page should be server rendered or statically generated.\n\nFor quite some time Next.js was alone in this innovation. Many of us lumped Next.js into the SSG category because it shared many capabilities of SSGs and likely also because you could ultimately deloy it to many of the same services that you'd deploy your SSG-based site.\n\n## A Change Would Do You Good\n\nThe success of Next.js and the demands of developers spurred other tools within the loose SSG umbrella to adopt a similar \"not just static\" set of rendering options. Here are a few significant examples:\n\n- Gatsby added server-side rendering as an option starting with Gatsby 4 which was [released last October](https://www.gatsbyjs.com/blog/whats-new-in-gatsby-4/).\n- Nuxt added the ability to specify [specific routes to prerender](https://v3.nuxtjs.org/guide/deploy/static-hosting/#advanced) in Nuxt 3 which went beta in October 2021 and released a [release candidate in April](https://nuxtjs.org/announcements/nuxt3-rc).\n- Astro, a new tool that began as exclusively static rendering, added support for SSR [in April](https://astro.build/blog/experimental-server-side-rendering/).\n- Eleventy added the [serverless plugin](https://www.11ty.dev/docs/plugins/serverless/) as of version 1.0, which had it's [stable release in January](https://www.11ty.dev/blog/eleventy-one-point-oh/).\n\nAs you can see, the ground shifted quite a bit in the past year alone. It was one thing to lump a tool like Next.js into the SSG umbrella as an outlier (yes, Nuxt did previously support an all-or-nothing SSR/static generation option too), but now tools that were traditionally pure SSGs like Gatsby and Eleventy suddenly allowed non-static routes.\n\n## Don't You Forget About Me\n\nThere still exists a still popular set of tools that stay true to the SSG definition like Hugo and Jekyll, but it's clear that most of the tools are moving on from purely static output.\n\nIs it fair to lump a tool that supports SSR and even perhaps [other types of rendering](https://bejamas.io/blog/understanding-rendering-in-the-jamstack/) in with tools that export purely static output under the umbrella of static site generators? Probably not.\n\nHas anyone come up with a better term? I don't think so. At least, not yet anyway.\n\nSo we keep using the SSG name even if it's a misnomer. At some point, though, we'll have to reckon with a very ill-fitting name for these tools, because naming is important in the end. A misleadingly named set of tools can lead to confusion which hurts adoption, muddles the message and leaves an opening for folks who, for whatever reason, don't like these particular tools.\n\nSo what's a better name? It's not easy since these aren't exactly frameworks though they may be based on frameworks (Next.js is often referred to as a metaframework) but tools like Eleventy and Astro aren't based on frameworks either. Maybe dynamic site generator. Or dynamic web application generator. Or dynamic web application builder. Maybe just web application builder.\n\nIdeas? Share them with me [on Twitter](https://twitter.com/remotesynth).\n"},{"slug":"what-is-linkbait","category":"blog","title":"What is Linkbait?","description":"A term that has become overloaded.","tags":["general"],"body":"\nI've see the term linkbait thrown around quite a bit (I've been accused of it myself). However, I think it's worth taking a look at the term to decide what it really means.<!--more-->\n\n## It's Not About the Title\n\nLinkbait accusations often have to do with the title. It's true that one characteristic of linkbait is a very catchy title of some sort - so much so that it has become a bit of a parody to include something along the lines of \"...and You Won't Believe What Happened Next?\" in an article title.\n\nBut, here's the first thing you need to know about catchy titles (even cheesy ones like that): _they work!_ If you are a writer, you want to put thought into how you can write the headline/title of your article in a way that would draw the most potential readership. People who write want readers, and as many as they can get - a good title is one of the most effective ways to get more readers.\n\nBut catchy titles are are often a warning sign of linkbait. We see examples (often in sponsored headlines) on sites as popular as ESPN (below):\n\n![ESPN Linkbait](/images/posts/linkbait_espn.jpg)\n\nWhich one of these is really linkbait? Perhaps all of them, \"sponsored headlines\" is usually a giveaway, but not a guarantee. Or, let's look at example from Mashable:\n\n![Mashable Linkbait](/images/posts/linkbait_mashable.jpg)\n\nIs that linkbait? I read Mashable, and generally trust its content, but that's also no guarantee.\n\nThe problem is that, while certain types of titles can be indicative of linkbait, *it's not about the title*. If you clicked on one of those links, it's at least in part because the title was a good and effective one. I've clicked on plent of them myself.\n\n## It's About the Content\n\nIf you were disappointed when you clicked one of those links, it's because you learned that the title was either partially or entirely misleading. What turns a post into linkbait is that it intentionally doesn't deliver on the promise of its headline.\n\nPerhaps it was a bait-and-switch, where the content was not or barely relevant to the title. Often, it is \"barely-there content\" with minimal content but maximum advertising. Most of the time, these articles are optimized for clicks - forcing you to click through multiple pages of ad-laden content to finally figure out you've been misled. **This is why true linkbait can be both effective and so frustrating - you'can't tell until it's too late**. The publisher has reaped whatever benefit of your click and you feel cheated.\n\nHowever, an article that has a catchy title but content that I disagree with is _not_ linkbait. I may even believe it is a terrible article, but that does not make it linkbait if it was not intentionally misleading you with the some ulterior motive - generally ads but sometimes more malicious.\n\n## Conclusion\n\nIt's important to be clear on what is and what isn't linkbait. Calling an article I disagree with linkbait can be dismissive but also create a false equality between legitimate content and intentionally deceptive content."},{"slug":"what-the-web-owes-flash","category":"blog","title":"What the Web Owes Flash","description":"Flash helped make the web what it is today.","tags":["web development"],"body":"\nThe tech world seemed caught by surprise by [Adobe's announcement](https://blogs.adobe.com/conversations/2017/07/adobe-flash-update.html) that, as of 2020, they will no longer support Flash in any capacity. You'd be forgiven if you were mostly surprised that Flash was still alive.\n\nThe truth is, we all knew Flash had issues, even before the infamous (or just famous depending on your perspective) [Thoughts on Flash](https://www.apple.com/hotnews/thoughts-on-flash/) letter in April 2010. (I have more thoughts on our collective misremembrance of that letter later.) Immediately following what could be viewed as a terminal diagnosis, Flash fought hard for its existence. It added impressive new features like Stage3D for hardware accelerated 3D rendering - which was far and above anything the browser could do at the time. Flex seemed to be becoming a legitimate cross-platform mobile app platform. Despite the diagnosis, Flash seemed healthy, arguably resurgent, for a little while.\n\nThe \"death\" (I'm sorry...open sourcing) of Flex was one of the signs that all was not well in the Flash development community. Flash continued, with a far diminished commitment from Adobe but still effectively alive, but the announcement in December 2016 that Chrome would effectively [disable Flash Player](https://blog.chromium.org/2016/12/roll-out-plan-for-html5-by-default.html) was the equivalent of putting Flash in hospice.\n\nFor most people, none of this mattered all that much. Between the lack of Flash on their phone and the decreasing usage on web sites, people were becoming used to a world without Flash. But this relatively quick death has masked some of the innovation that the web owes to Flash - innovation that came not just from the software itself, but from the developer community that used it.\n\n## My History with Flash\n\nMy career in web development more or less started with Flash. I was a total noob back in 2007/2008 when I finally picked up a computer and started messing around with web development. I had no CS degree and no formal background in programming - I hadn't even owned a computer in college and my minimal experience on the \"web\" was via the text-based terminal they had in the college lab. Yes, I am that old.\n\nFor reasons that I no longer recall, I picked up a copy of Dreamweaver Ultradev and Flash - after messing around with Front Page for a while, I was ready to get serious. Flash was a ton of fun and had so much potential but it also had serious limitations. For example, there were no variables back then. If you wanted to do something like, say, keep score, you had to create a timeline with numbers and forward to the correct spot in the timeline. In the end, a buddy of mine convinced me to take a ColdFusion training course, which led to a job in web development and thus Flash was left behind for a time.\n\nMy return to Flash was via Flex when I worked at Sun Life Financial. I was excited to learn Flex and, at the time, these \"rich internet applications\" seemed like the real future of the web. CSS was still in its infancy and, honestly, most web UIs were either all images or just plain sucked (or both).\n\nBefore long, I'd organized the Flex Camp Boston conference, which quickly sold out. This became RIA Unleashed which expanded to multiple tracks and covered both Flex and Flash (and other related topics). (This conference technically still exists now as Web Unleashed in Toronto run by FITC.) This led to a job at Adobe as the Flash and Flex Community Manager. My timing could have been better though - this was immediately post-Thoughts-on-Flash.\n\nLess than a year after joining Adobe, I was reorged out of Flash and Flex entirely and moved to focusing on web standards and web development (running what was at the time called the Adobe Developer Connection).\n\nSuffice it to say, my own career owes a ton to Flash, both from its beginning and in the way it helped me expand beyond my purely coder roots into more community management and developer relations. Sure, the software had nothing to do with that specifically, but Flash somehow channeled areas of my creativity that helped me develop in my own career.\n\n## Where Flash Pushed the Web\n\nAdobe touches on the ways in which Flash pushed the web a bit in their own post.\n\n> Where a format didn’t exist, we invented one – such as with Flash and Shockwave. And over time, as the web evolved, these new formats were adopted by the community, in some cases formed the basis for open standards, and became an essential part of the web.\n\nHowever, it can be tough for many of us to remember much beyond the useless Flash intros or annoying Flash advertisements. But the truth is, the web before Flash was a bore.\n\nIn middle school and high school, I fell in love with programming until one day in 9th grade my teacher shot down my dreams. I was a boy in love with Sierra games and dreaming of being a game developer when he told me that computers were not for games - they were for business applications (I quit programming, not to return until after college). At the time, he was right, though.\n\nBack in the days before Flash, the web was just for text and information - and perhaps some static images. The web was not for games. The web was not for video. The web was not for interactive applications - even for business. If you wanted a rich, interactive application for business, you used Powerbuilder to build for the desktop.\n\nFlash changed that. Animation became so ubiquitous that it became obnoxious (i.e. the Flash intro). Video and streaming was in Flash - would YouTube have existed at the time without it? (for better or worse 😉) 2D and later 3D gaming on the web grew largely on the back of Flash. Back in about 2003, Flash introduced the idea of \"Flash Remoting\" and thus pushed the concept of rich applications on the web, that loaded data and content asynchronously.\n\nSure, pretty much all of this is now in the browser, and it may seem like, \"what's the big deal?\" The big deal, to me, is that Flash helped redefine what the web was about. It was like the 9th grade me telling my computer teacher, \"Screw you, computers are for gaming!\" instead of giving up on programming. Even where web standards didn't end up replicating Flash, it forged a path that opened up our ideas about what the web could be.\n\n## Flash Developers and the Early Post-Flash Era\n\nI want to take things a step further though and argue for the incredible influence Flash developers had on the web. The Flash and Flex developer community was always amazing. Every year I'd go to events like 360Flex and leave feeling empowered - both amazed at what some people were able to create but also by the close knit group of developers.\n\nHowever, what I want to focus on is the immediate years in the early post-Flash era starting in about 2011/2012. During these years, so many ActionScript developers jumped headlong into JavaScript. In trying to find paths into what they had become accustomed to, they began testing the limits of the language and the web platform. Many of them created frameworks and libraries that played a big role in how JavaScript development evolved.\n\nI recall in those days while following the JavaScript and web development community as part of my role at Adobe, when I came across a new library that did some crazy interactivity with video or audio or gaming or even pushed the language away from the jQuery-style DOM scripting towards a more traditional coding style, it was very often a former Flash developer behind it.\n\nThat influx of talent from the Flash community in 2011-2014 changed the web and pushed it forward. It was the often silent continuing influence of Flash that generally went unacknowledged. (At the time, Flash-bashing was so strong that many Flash developers rarely talked about their background.) Flash grew a strong community of developers whose influence still continues today.\n\n## Conclusion\n\nMany of the Flash post-mortems I've read in the past day have focused on Steve Jobs and his Thoughts on Flash as a turning point that was designed to push the web platform forward into the future. This is false. I discussed it a little in this thread on Twitter:\n\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">I have great memories of Flash from glory days. It was a great tool (AS3 a fun language) to use. Best part, developer community was awesome.</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/889946025850437632\">July 25, 2017</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nSuffice it to say, Thoughts on Flash was a self-serving defense of the App Store ecosystem - the very ecosystem the web is often pushing back against to this day. It was not a push for a more open and interactive web.\n\nNonetheless, it was a turning point. It was the moment we began to realize that Flash's days were numbered and we were either going to have a web that incorporated many of its features or we were going to live entirely within a closed app ecosystem.\n\nOur misremembrance of Thoughts on Flash is important though. It focuses our mental energy on how Flash was eventually torn down rather than how it was built and what it created. Despite it's ultimate, eventual failure, it was Flash along with the developer community it fostered that helped define what the web could be and pushed the web to where it is today."},{"slug":"whats-wrong-with-tech-interviews","category":"blog","title":"What's Wrong with the Tech Interview Process?","description":"There is widespread belief that the tech interview process is broken but little in the way of movement to change it.","tags":["general"],"body":"\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nThere seems to be a growing consensus that the interview process often adopted at tech companies for hiring technical staff, in particular developers, is broken. Almost a year ago, I featured it as a major problem in a [post discussing the issues facing tech today](https://dev.to/remotesynth/is-today-the-best-time-to-be-a-developer-nobut-were-getting-better-5ik) and, suffice it to say, it hasn't been fixed in the time since.\n\nOne need not even look far to find it being discussed on Twitter or Hacker News of across a variety of blogs. The issues seem to boil down to three things:\n\n1. Coding tests are arbitrary, needlessly difficult and disconnected from the skills actually required for the job.\n2. The number of rounds and the time demands of interviewing are difficult to manage.\n3. Hiring decisions often seem arbitrary and communication about why someone failed a stage are often poorly communicated, when they are communicated at all.\n\nLet's take a closer look at each of these.\n\n## Coding Tests and Whiteboards\n\nLet's start with coding tests and whiteboarding since it is probably the most common frustration that developers cite.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Sweet - but still be ready to pass an obscure code test for Google that has little to nothing to do with your actual work. <br><br>(OK OK Ray shut up about the damn test you failed...) <a href=\"https://t.co/kHUsDdb29C\">https://t.co/kHUsDdb29C</a></p>&mdash; Raymond Camden 🥑 (@raymondcamden) <a href=\"https://twitter.com/raymondcamden/status/1032620254650937344?ref_src=twsrc%5Etfw\">August 23, 2018</a></blockquote> \n\nThe primary frustration developers express around coding tests have to do with them being needlessly difficult and frequently arbitrary. Many people describe being asked about complex computer science concepts and algorithms that they may have studied in college (assuming they were a CS major) but haven't had the need to reference since (or if they did, they just look it up).\n\n> I shouldn’t have to rely on an algorithm question lottery to demonstrate my skills and abilities during an interview. Luck and chance should not be part of the tech interview process... It’s like testing your dentist’s skills based on their ability to balance a redox equation using the oxidation number method from their undergraduate chemistry studies.\n> \n>  - Sahat Yalkabov, [F*** You, I Quit — Hiring Is Broken](https://medium.com/@evnowandforever/f-you-i-quit-hiring-is-broken-bb8f3a48d324)\n\nPart of the problem with the code test or whiteboarding is that it doesn't seem to be relevant to the job it is designed to screen for and often seems included as a way of gatekeeping.\n\n> And just how have these folks determined this definitive fact that I am not technically strong enough? Care to guess? If you said, \"a live coding test with a random brain-teaser type problem you'd find on codewars.com,\" you'd be right. Now don't get me wrong, I have also passed interviews with these sorts of tests. Hmm.. Isn't that odd?\n> \n> - Ambrose Little [Technical Interviewing is Broken, But We Can Fix It](https://dev.to/ambroselittle/technical-interviewing-is-broken-but-we-can-fix-it-4964)\n\nTo me, there are two major issues with coding tests. The first is the disconnect between these coding tests and the supposed goal for which they were designed, which is to determine the skill and knowledge of the interviewee. It seems to me that a body of work - whether it be their education, work at a company, contributions to open source or side projects - is more illustrative of someone's technical skills than a random code challenge brought completely out of context. There is nothing especially unique about the job of being a developer that requires answering random technical trivia, but it seems to be a practice that is unique to this role.\n\nMore importantly, the second problem is that the practice prioritizes random technical knowledge (something that can relatively easily be learned) over other aspects like personality fit, ability to work with others, work ethic, eagerness to learn (things that cannot be easily learned). You can be a brilliant coder and a crappy person but I can tell you which part of that equation will have more impact your success in a developer job.\n\n## Extensive Time Demands\n\nTech interviews are often marathons. Many roles require extensive rounds of interviews in addition to time-consuming \"homework\" assignments. \n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I’ve been rejected from many job interviews in my life. My most recent I had 5+ interview rounds, a full day of onsite coding interviews and I made it to the final stage before I got rejected. There is no shame in a job rejection. Don’t beat yourself up. We all get rejected ❤️</p>&mdash; Emma Wedekind 🐞 (@EmmaWedekind) <a href=\"https://twitter.com/EmmaWedekind/status/1172390425073577990?ref_src=twsrc%5Etfw\">September 13, 2019</a></blockquote>\n\nThis doesn't seem to be exclusive to the large, household-name tech companies. Across the board you hear stories of tech companies treating the process as if it is designed to weed out candidates who simply cannot make it to the end of a grueling race.\n\n> More and more employers are adopting pointless, expensive and time-consuming extra processes to make their recruiting pipelines even slower and more off-putting to candidates.\n> \n> - Liz Ryan, [No, You're Not Crazy -- The Hiring Process Is Broken](https://www.forbes.com/sites/lizryan/2018/04/12/no-youre-not-crazy-the-hiring-process-is-broken/#1109c2db4751)\n\nThis is compounded by a slow or completely broken communication process.\n\n> I've gone through half-day to full-day interviews called \"running the gauntlet\" only to wait a month for them to say no or nothing at all. It's a part of the process and we all get over it. (shrug) Still, it's frustrating when you have to use precious vacation time to go on interviews that lead nowhere.\n> \n> - Milecia McG, [The Crazy Job Search Process](https://dev.to/flippedcoding/the-crazy-job-search-process-om6)\n\nOften the communication breakdown seems to break down for a candidate who isn't continuing in the process, which is certainly unfair to the candidate left hanging. However, not infrequently, the communication is poor or nonexistent even for candidates who are moving to the next stage but are often left to wait weeks before that is communicated.\n\nThis seems entirely self-defeating for companies who are hiring in at least two ways. The first is that it pointlessly limits your potential candidates to those whose finances and/or job allow them to survive the countless missed hours and days required. Second, it misses out on candidates who drop out of the process because they either get frustrated with the lack of communication and length of the process and the other are, of course, people who simply find a different job during a process that need not be this protracted.\n\n## Arbitrary Hiring Decisions\n\nThe biggest issue seems to flow from the prior two, which is that rejections can seem completely arbitrary - so much so that there is [a site dedicated to sharing rejection stories](https://rejected.us/) filled with recognizable names in the developer community.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I was rejected for a job by <a href=\"https://twitter.com/TwitterEng?ref_src=twsrc%5Etfw\">@TwitterEng</a> years ago, even tho I knew several people on the team who liked me &amp; wanted me to join. I was later told by HR that one of the interviewers said I &quot;didn&#39;t know JS&quot; very well. That was part of the motivation for <a href=\"https://twitter.com/YDKJS?ref_src=twsrc%5Etfw\">@YDKJS</a>. <a href=\"https://twitter.com/hashtag/ShareYourRejections?src=hash&amp;ref_src=twsrc%5Etfw\">#ShareYourRejections</a></p>&mdash; getify (@getify) <a href=\"https://twitter.com/getify/status/1032445705204449281?ref_src=twsrc%5Etfw\">August 23, 2018</a></blockquote>\n\nEven many people involved in the hiring process seem to recognize that it is flawed.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">... we had a group called &quot;Bar Raisers&quot; who mainly torpedoed candidates that lacked &quot;CS Fundamentals&quot;. We passed on so many good people.</p>&mdash; Trek Glowacki (@trek) <a href=\"https://twitter.com/trek/status/692118907184902151?ref_src=twsrc%5Etfw\">January 26, 2016</a></blockquote>\n\nPart of the problem stems from the screening process (something the stories on [rejected.us](https://rejected.us) frequently validate), which, according to the study cited below looking at Y Combinator hiring, accounted for nearly half of applicant rejections. \n\n> Most companies reject a high percentage of applicants during a recruiter call (or resume screen). Across the 25 companies we interviewed, an average of 47% of applicants were rejected in this way (the rate at individual companies went as high as 80%, and as low as 0%). The recruiters doing this rejecting are non technical. All they can do is reject candidates who don’t match the profile they’ve been taught to look for. \n>\n> - Ammon Bartram,  [Who Y Combinator Companies Want](https://data.triplebyte.com/who-y-combinator-companies-want-c1880a08ac88#.8dspa9u3p)\n\nAs the study notes, in many cases, this is because the screener generally isn't technical and therefore must rely on profile information they have been supplied. That's not to say that the screener should be technical, I believe there is a ton of merit in including people trained in and focused on recruiting, but it means we need to do a better job of making sure they understand the profile and are supplied with the information they need to properly evaluate folks.\n\nThe other problem is back to the coding tests. Their seeming trivia-like nature seems to lead to unpredictable results. Basically, good candidates fail a good percentage of the time, as noted in the following research.\n\n> Roughly 25% of interviewees are consistent in their performance, and the rest are all over the place...\n>\n> To me, looking at this data and then pretending that I had to make a hiring decision based on one interview outcome felt a lot like peering into some beautiful, lavishly appointed parlor through a keyhole. Sometimes you see a piece of art on the wall, sometimes you see the liquor selection, and sometimes you just see the back of the couch.\n>\n> - Aline Lerner, [Technical interview performance is kind of arbitrary. Here’s the data.](http://blog.interviewing.io/technical-interview-performance-is-kind-of-arbitrary-heres-the-data/)\n\nThe combination of screening, testing and time can mean companies hiring processes are not necessarily optimized for finding the best candidates.\n\n## This Isn't an Easy Problem to Solve\n\n> Look, I get it. It takes time and effort to interview someone, and most of you just want to get back to building stuff. Coming up with a standard question lets you get away with doing more with less effort, and gives you a modicum of an ability for comparison across different candidates.\n>\n> But really take a long look at whether this selects the right candidates.\n> \n> - Zach Holman, [Startup Interviewing is F****d](http://zachholman.com/posts/startup-interviewing-is-fucked/)\n\nAs Zach notes, this is a difficult problem to solve, which may explain why the system seems to be currently supported by a combination of \"that's the way we've always done it\" and \"that's the way everyone else is doing it.\" This reasoning gives companies the excuses they need to avoid taking a hard look at their processes to see if they are actually achieving the goals they are supposedly designed to achieve. Most companies seem to believe that, at worst, this system gives them a ton of false negatives but not false positives.\n\nIt seems that companies would benefit from asking themselves:\n\n* Does our code test or whiteboarding exercise really improve our ability to identify good candidates? Or are there more relevant exercises (a reasonable homework assignment related to the day-to-day job requirements) or criteria (project experience or open source work that can be judged en lieu of a quiz or homework) that might be more useful?\n* Do we really need full day interview marathons or 5+ stages of the interview process? Are there stages we can cut out and still be equally effective? Are we losing good candidates just because they cannot afford to complete our process?\n* Are our screeners given the information they need to properly screen people or are we potentially losing highly qualified candidates? Are our criteria too specific (ex. looking specifically for Angular when JavaScript or JavaScript framework experience would suffice)? Does our process seem to result in a high degree of false negatives?\n\nThese aren't easy questions to answer, for sure, and, obviously, lots of good candidates still manage to make it through. But I think of it this way: As developers, we've developed system of unit testing to help prevent us from deploying buggy code. These tests don't always check for issues that would cause the whole application to break down. Some might cause the software to work improperly some significant percent of the time or for some significant percentage of users depending on specific criteria. However, we wouldn't allow our developers to deploy code that failed these tests just because the application might work for some users some percentage of the time. Our interview and hiring system is currently failing a ton of unit tests. Let's fix it."},{"slug":"which-free-code-editor-is-right-for-you","category":"blog","title":"Which Free Code Editor Is Right For You?","description":"What's the current state of free code editors?","tags":["web development"],"body":"\nWe live in a day and age as web developers where our biggest complaint seems to be a overabundance of free tools. In the case of code editors, there are a few prominent free ones: [Atom](http://atom.io), [Brackets](http://brackets.io/) and, most recently, [Visual Studio Code](https://code.visualstudio.com/). Each editor has its own set of strengths and weaknesses. Each is backed by a large corporation - GitHub for Atom, Adobe for Brackets and Microsoft for Visual Studio Code - so obviously they will be geared towards the target audience of each respective company.\n\nNonetheless, they are all good editors. So which one should you choose?\n\nWell, [it depends](http://developer.telerik.com/featured/battle-of-the-free-code-editors/). You knew I was going to say that!\n\nIn my latest article, [Battle of the Free Code Editors](http://developer.telerik.com/featured/battle-of-the-free-code-editors/), I go into the distinguishing features of each editor and what type of developer it is best suited for.\n\nPlease, [check out the article](http://developer.telerik.com/featured/battle-of-the-free-code-editors/) and feel free to share your thoughts.\n\n### A Note on Sublime\n\nI was asked numerous times after writing this article, why did I not include [Sublime](http://www.sublimetext.com/)? After all, Sublime is, for all intents and purposes, the market leader for lightweight code editors. The article compared _free_ editors. However, _Sublime is not free!_\n\nYes, you can try it for free and, as many responses noted, use it forever without paying if you are willing to live with dismissing the prompt to buy regularly. One person even noted to me that if the author didn't want people to use it for free forever, they'd have a different license method.\n\nI'm sorry, that's not how this works. The author clearly states:\n\n> Sublime Text may be downloaded and evaluated for free, however a license must be purchased for continued use.\n\nAs I said on Twitter...\n\n<blockquote class=\"twitter-tweet\" lang=\"en\"><p lang=\"en\" dir=\"ltr\">It surprises me how many people seem to advocate using Sublime for free. If you think the software is great, why not pay what they ask?</p>&mdash; Brian Rinaldi (@remotesynth) <a href=\"https://twitter.com/remotesynth/status/644542401911083008\">September 17, 2015</a></blockquote>\n<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"},{"slug":"which-static-site-generator-should-i-use","category":"blog","title":"Which Static Site Generator Should You Choose?","description":"Which static site generator do I recommend? The simple answer is easy.","tags":["web development","Jamstack"],"body":"\nAs part of the process of writing my [Static Site Generators ebook](http://www.oreilly.com/web-platform/free/static-site-generators.csp) for O'Reilly and maintaining my [Static Site Samples project](https://github.com/remotesynth/Static-Site-Samples) on GitHub, I've used a good number of static site generators including: Jekyll, Middleman, Hugo, Wintersmith, Metalsmith, Harp, Hexo, DocPad and Roots.\n\nYou'd think 9 static site generators is a lot, but that's out of a [list of 423](https://staticsitegenerators.net/) (as of this writing anyway). Still, it includes many of the leading projects and more than any normal person would want to try before choosing one. Because of this I am often asked (and often present on) which static site generator I recommend (based upon the ones I've used).\n\nLet me give you the simple answer first, then the more nuanced answer second.<!--more-->\n\n## The Simple Answer\n\nThe simple answer is [Jekyll](http://jekyllrb.com/).\n\nWhy? Here are some reasons.\n\n- Jekyll is the most mature solution out there. This means you are very unlikely to encounter quirky issues, growing pains or drastic, breaking changes.\n- Jekyll has some of the best documentation of any of the options. It's not perfect (which documentation ever is?) but I've found it covers most typical use cases.\n- Jekyll's community is the largest (afaik). This means that if there are questions that aren't answered in the docs, you'll likely find answers to them. And it also means that the list of available [plugins](https://jekyllrb.com/docs/plugins/) and templates for Jekyll is very large - you'll rarely find yourself having to solve a problem yourself.\n- While Jekyll is built in Ruby, you probably don't even need to care. Jekyll does a good job of shielding you from ever having to dig into Ruby to solve your problems. The available functionality within Jekyll itself usually solves the problem or, if not, the array of available plugins likely will.\n- Liquid is a solid templating solution. Sure, you can change from Liquid, but having used a ton of templating options for the various generators, I can tell you that Liquid offers more out-of-the-box than most (and Jekyll even enhances the built-in offerings).\n- There are a growing number of tools that support Jekyll. From GitHub Pages to CloudCannon to Netlify to [Forestry.io](http://forestry.io), the list of solutions that support Jekyll is growing. Sure, many of these support other solutions, but every one supports Jekyll.\n\nMy only significant criticism of Jekyll would be its [lack of official support for Windows](https://jekyllrb.com/docs/windows/). While the [suggested workaround](http://jekyll-windows.juthilo.com/) appears to work fine (I've personally tested it on Windows 8 and 10), the fact that a workaround is required for a significant portion of potential users to install Jekyll is suboptimal, in my opinion.\n\nThere was an old saying (which may no longer be true) that \"No one ever got fired for choosing IBM.\" When it comes to a static site generator, I'd say \"No one ever got fired for choosing Jekyll.\" It is a great solution and by far the safest bet of the 423 options.\n\n## The Nuanced Answer\n\nThe more nuanced answer would take into account your specific needs.\n\nIf you are building a large site, with a lot of pages, build times cane be a concern. Solutions like Netlify, for example, allow you to avoid the local build-and-push scenario that can be slow and tedious as your site grows. But if you are concerned that build times could be a major concern for you going forward, it may be worth evaluating [Hugo](http://www.gohugo.io/). Hugo (built in Go) had by far the fastest build times of any of the solutions I tried. You can't completely avoid learning Go to use it, which can increase the learning curve, but it is also very well documented.\n\nSome people _really, really, really_ want a solution built in JavaScript (of which, there are currently 90 and counting). In fact, this was the basis of my recent presentation at the Fluent conference in San Francisco (embedded below).\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/sMLs0o-LqQY\" frameborder=\"0\" allowfullscreen></iframe>\n\nIf you watched the whole thing, you know I actually recommend not using any of the JavaScript options that I have tried so far. But if you are determined to do so, I recommend [Wintersmith](http://wintersmith.io/). Sure, it's written in CoffeeScript (which you may hate) and it is very sparsely documented (outside of a short quick start guide), but it does have a lot of plugins and a very solid [list of example sites](https://github.com/jnordberg/wintersmith/wiki/Showcase) (many with source available) to help. Plus, though I don't advocate using a project's source as documentation, in the absence of documentation, the source of Wintersmith is pretty readable (plus, the lack of documentation plagues every JavaScript-based option I have tried). So, I'm actually not recommending you choose it, but if you are dead-set on a JavaScript option, it's the best I've tried.\n\n## Conclusion\n\nTo sum up... Use Jekyll unless you have a specific, legitimate reason not to do so. At the very least, start your evaluation with Jekyll. If you want to evaluate several options, of the ones I've tried go with Jekyll, Hugo and [Middleman](https://middlemanapp.com/) (also built in Ruby). Obviously, there are 414 other solutions out there that I have not evaluated (and I keep trying to get to more of them), but, in reality, one of those three solutions should suit your needs, whatever they may be."},{"slug":"working-the-writing-muscle","category":"blog","title":"Working the Writing Muscle","description":"Ignore it and you lose it!","tags":["personal"],"body":"\nWriting is tough. Even for someone who has enjoyed writing his whole life (like me), it can be difficult. Even worse, the less you do it the harder it gets. Just like an excercise routine, the best way to make it easier is just to keep doing it. Not using it, you risk losing it.\n\nAs you can see, however, my writing - on this blog in particular - has waned. However, I'm hoping to change that by writing something, ever day of the work week. It may be tech or code related - it may not be. Just write.<!--more-->\n\n## Losing Your Love of Writing\n\nI've always loved writing. In college, I took a number of creative writing courses and enjoyed writing short stories or even, occassionally, poetry. After I finished school, however, I rarely wrote until I decided to write an article for the ColdFusion Developer's Journal some 12+ years ago.\n\nIn January of 2005, I started this blog (though that content no longer exists anymore). Here it is from 2005, in all it's glory!\n\n![](/images/posts/myblog_2004.jpg)\n\nThe thing is, back then, I didn't care that anyone was reading the blog. In fact, I started it under the assumption that no one was, in fact, reading it. It was a place for me to write and enjoy writing. It wasn't until I showed up at a ColdFusion conference in 2006 that I learned that people actually read it...and even knew who I was.\n\nThat was great. However, when you start writing _for_ other people, you lose something. That something is perhaps the joy of writing without an ego. Of not being afraid to put yourself out there, to risk your reputation and share openly - if only because you don't realize anyone is paying attention.\n\nEventually, you start thinking how a post will play before writing it. Or how much traffic it might get. Or who might attack you in the comments. And, at least for me, this eats away at your love of writing...it becomes a chore.\n\n## Finding a Voice Again\n\nI'm hoping that simply forcing myself to write, and do so in a way more similar to how I started - without care of whether anyone reads it at all - will help me find my love of writing again. So, here goes."},{"slug":"working-with-static-site-generators","category":"blog","title":"Working with Static Site Generators","description":"A full book from O'Reilly devoted to building static sites.","tags":["Jamstack"],"body":"\nI've talked a lot about static sites. I've written a lot about static sites. I'm obviously a huge fan of static sites. So is my good friend [Raymond Camden](https://raymondcamden.com). So, we decided (quite some time ago) to join forces and write a book about static sites. I'd already written a [free report on static site generators](http://www.oreilly.com/web-platform/free/static-site-generators.csp) for O'Reilly, so we proposed a full book. The book, creatively called \"[Working with Static Site Generators](http://shop.oreilly.com/product/0636920051879.do)\" is complete, though still awaiting final edits. However, you can already purchase and download it as an [early release ebook](http://shop.oreilly.com/product/0636920051879.do#).\n\nThe final, print version of the book should be available very soon, but, as I said, it is fully written, so feel free to grab an early copy if you like. If you have any comments on it, please feel free to share (especially since any edits can still make it into the final version)."},{"slug":"writing-for-tech-audience","category":"blog","title":"Tips for Writing for a Tech Audience","description":"What makes a good article for a developer audience?","tags":["content strategy"],"body":"\nI've been writing articles and blog posts about web development and technology for a long time. The original version of this blog started in 2004, but by that time I'd already written a couple articles for the ultra-prestigious ColdFusion Developer's Journal (it's ok to feel jealous).\n\nHowever, I've also been editing articles and blog posts about web development and technology for a while too. It started when I was at Adobe helping to run the Adobe Developer Connection a few years ago and continued when I launched my own site (Flippin' Awesome which is now Modern Web and not run by me anymore). I still do this on an almost daily basis running the [Telerik Developer Network](developer.telerik.com).\n\nAll of this experience has taught me some things that I think help to make a really good (and potentially really popular) article or blog post for a developer or technology audience. In this post I'll share my recommendations, though I should note that I'm not an expert at always following my own guidelines all the time.<!--more-->\n\n## Have a Style\n\nIt's important to keep in mind that you aren't writing API docs. API docs are generally dry, boring and simply stick to the facts. That's their goal. However, an article or blog post should allow some of your personality to shine through. This helps to make the content both more relatable and more enjoyable to read.\n\nKeep in mind that your goal is both to educate and to entertain, to some degree. Some developers revert to a litany of code and explanation. It's better to have a voice and have a story.\n\nSome things that can help:\n\n* Explain *why* you are trying to do something, not just what you are trying to do and how you are doing it.\n* What made you get interested in doing this?\n* Did you have a struggles along the way? There's no shame in admitting that you found something difficult - your readers will likely relate to the experience.\n* Have fun with the demo! Perhaps pick something you are interested in that isn't technical. For example. I often choose to use some cartoons I enjoy as subject matter for my demos.\n\n## Know Your Audience\n\nWhile you should have a voice and a style, it's important to know when it's ok to be more or less casual in your voice. If I am writing something for my blog, I am often much more casual than if I am writing for the Telerik Developer Network or Sitepoint.\n\nIf I am writing for my blog, proper grammar, punctuation and spelling are less important. If I am writing for a professional site, these become the difference between seeming like an amateur and not. You'd be surprised how people are affected by these things, even if they do not recognize it themselves. Some sites have editors who help with this, but others don't - so don't rely on them to correct your mistakes.\n\nTry to always have a friend you trust read through the article first - this isn't critical for a personal blog post but even those can benefit. Even the best writers need a second opinion and there is nothing than can make your content better than a good, critical opinion.\n\n## Stay on Track\n\nSo many developers tend to think that every little detail is pertinent. So, they get sidetracked. Instead of traveling straight down a path, they don't just point out the detours, but take you down them.\n\nAs a rule, if the information doesn't apply to *most* situations, don't spend time on it. These are the kind of scenarios like, if you are running an old version of X operating system and want to perform special action Y, you'll need to do this a different way - let's walk through it. Another example is getting lost in caveats, detailing every minor exception that in all likelihood doesn't apply to the reader.\n\nThe best strategy in these cases is to simply point to the \"detour\" as an aside and link to the best resource to follow. Or note that there are exceptions but don't go detailed into the full list of caveats.\n\nYou may feel as though you are being somehow incomplete in your coverage, but you are less likely to lose the 90% of the readers to whom the straightforward path applies by not catering your post to the 10%.\n\n## Avoid the Wall of Text\n\nThere is nothing harder to read than a post that has no headers and is filled with overly long paragraphs. Adding section headers and even subheaders for long sections not only makes your article easier to read, but also makes it easier to scan - which can help the reader determine it's value to them.\n\nShorter paragraphs also make your content more readable and scannable. Plus, a wall of unbroken text can seem intimidating to a reader. Break up large paragraphs and, whenever possible, place key ideas into lists, which I've found can help drive home key points and improve retention.\n\n## What Are Your Ideas?\n\nHopefully you've found these ideas helpful. Do you have any strategies you use to improve your writing? Please share."},{"slug":"writing-technical-posts","category":"blog","title":"3 Tips for Writing Great Tech Posts","description":"Some broad guidelines for writing technical or code-focused blog posts and articles","tags":["content strategy"],"body":"\nWriting can be difficult. Writing about technical topics and code presents unique challenges. For instance, while code may be engaging to write, it isn't naturally engaging to read. Trying to write solid technical blog posts and make them interesting is not an easy skill.\n\nIn this article, I want to go over a few things that I have learned that may be helpful to you when writing a technical blog post or article. Just to give you a quick background, I wrote my first published article in 2004 (for the ColdFusion Developers Journal, which, at the time, was a _print_ journal). I started blogging at the start of 2005, and since then I've written [a lot of articles](https://remotesynthesis.com/publications/), but also managed developer content at Adobe, Telerik and now Progress. In the process, I've written, edited and read a ton of technical posts, and these tips are some of what I've found to be most effective based on those experiences.\n\n> I first wrote about this topic [4 years ago](https://remotesynthesis.com/blog/writing-for-tech-audience) but thought it worth revisiting.\n\n> NOTE: As I was preparing to post this, I found that [Wade Christensen posted on the same topic](https://dev.to/astuteape/a-guide-to-better-technical-writing-1mdg) but with slightly different angles. I think he offers some excellent advice and that our advice doesn't really overlap to any great degree. So read his post as well!\n\n## Make Your Intentions Clear\n\nAs a reader, there are multiple decision points for choosing to read or comlete a post. The intial one is typically, \"Does the title make the article sound interesting?\" If the title interests a reader, they'll typically read the intro and decide, \"Is it worth my time reading the whole thing?\" A common mistake I see in a lot of technical posts is either too much introduction or, alternatively, far too little. In both cases, the problem is that the intention of the article can be unclear for the reader, who may abandon the post early.\n\nThe case of too little introduction is usually one where the writer jumps too quickly into the code without much in the way of setting the stage. Unless the title and the content are inherently self-explanatory, a little bit of intro is necessary to not leave the reader disoriented.\n\nIn other cases, there are numerous long paragraphs of introduction, often before the author states the actual intention of the post - if they state it at all. In these cases, the reader often is looking ot understand the scope of the post and make their decision about whether it is worth reading, but the author is making them work too hard for it.\n\nHere are my tips to make your intentions clear:\n\n* Keep your title crisp and descriptive. In my opinion, catchy titles aren't \"click-bait\" as long as they are accurate - so you can still feel free to be creative.\n* Keep your introduction to no more than a couple paragraphs if possible. If a lot of background information is necessary, often what works is to have a quick paragraph intro laying just the goals of the post and then put the remaining background information into a seperate section immediately following the brief intro.\n* Have a sentence in your intro that clearly states what the goals of the post are. Something along the lines of \"In this article, I plan to...\" or \"In this post, we'll discuss...\" This can both help to clarify your intent to the reader and refine your writing to not stray from your intended goals.\n\n## Break the Wall of Text (or Code)\n\nA wall of text can be visually intimidating to a reader. I know, I am a master at the wall of text - if it can be said in 3 words, I can easily manage to turn it into 3 paragraphs. So this is advice that I admittedly fail on from time to time.\n\nHowever, the wall of text can be easily be made less intimidating and appear much more visually appealing through the use of visual elements that break it up. The easiest is to simply place section subheadings throughout your post. This not only breaks up the wall of text visually, but it also helps the reader scan the content in order to find the information they are looking for or even when deciding if it is worth reading in its entirety. In a similar fashion, lists can also break up the visual monotony and improve scannability.\n\nWherever relevant, use images and/or video liberally. This makes posts seem much more visually appealing and engaging, while also reinforcing or enhancing concepts. If you are able, including live code demos using tools like [CodePen](https://codepen.io/) or [jsFiddle](https://jsfiddle.net/) are also excellent.\n\nHere are tips for breaking up the wall of text/code:\n\n* Use subheadings to break the article into multiple sections. If a section gets too long, feel free to break that into further subsections.\n* Use images, video, memes, gifs wherever relevant to make your content more visually interesting.\n* Wherever possible, use tools to embed runnable code into your post. This not only makes it more interactive, but also can break up huge blocks of code into a more compact embed.\n\n## Be Yourself, But Know Your Audience\n\nDepending on where you are publishing, there are varying levels of formality. If you are publishing to dev.to or your own blog (or both 👍), the formality around language, grammar and punctuation is especially casual. However, if you are writing for a technical journal or magazine, you may need to adopt a more formal voice. This doesn't mean you can't have your own voice and style (in fact, you should!), but it does mean you may need to adopt a less casual voice and tone down on the emoji or memes, for instance.\n\nThe other important thing to note is the audience that you are writing for. If you are writing for a technical beginner, you should either avoid jargon (which is generally a good idea anyway) or be sure to clearly define it. However, if you are writing for a tech journal that serves a more business audience, you may need to ensure you clearly explain some technical assumptions you may typically make about a developer audience (not saying anyone is dumb here, just that they may not be as familiar with some of the tools and jargon that developers take for granted).\n\nThat being said, not every post needs to get bogged down in explanation. It is fine to refer to other external resources for additional information should your article require some degree of prerequisite knowledge.\n\nHere are some tips for being yourself and knowing your audience:\n\n* Feel free to have a writing style and voice that is unique and represents you - this is what can make an article interesting. Some editors can inadvertently wash away that voice, but you should defend it whenever possible.\n* Adapt for the audience you are targeting. That means you may need to adopt a more formal voice (without burying your style) in some cases, but it also means you may need to understand the technical skill level of the audience you are trying to reach. Try to avoid jargon or, when jargon is necessary, ensure that you define it or include a link to a definition.\n* Don't let concern for your audience push you to over-explain. It is fine to rely on external resources for prerequisite knowledge or tangential information that may distract from the goal of your post.\n\n## What are your suggestions?\n\nAs I noted in the intro, Wade Christensen has an [outstanding post on this topic](https://dev.to/astuteape/a-guide-to-better-technical-writing-1mdg) as well that has some really good suggestions that delves deeper into topics around grammar and language. How about you? Do you have any suggestions based on your experiences about how to write better technical content?"}]